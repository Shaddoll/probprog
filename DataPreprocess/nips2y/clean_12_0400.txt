abstract sami bengio idiap cp rue du simplon martigni switzerland bengiooidiap ch curs dimension sever model high dimension discret data number possibl combin variabl explod exponenti paper propos new architectur model high dimension data requir resourc paramet comput grow squar number variabl use multi layer neural network repres joint distribut variabl product condit distribut neural network interpret graphic model without hidden random variabl condit distribut tie hidden unit connect neural network prune use depend test variabl experi model distribut sever discret data set show statist signific improv method naiv bay compar bayesian network show signific improv obtain prune network introduct curs dimension hit particularli hard model high dimension discret data mani possibl combin valu variabl possibl observ data set even larg data set common datamin applic paper deal particular multivari discret data one tri build model distribut data use exampl detect anomal case data mine applic use model class condit distribut observ variabl order build classifi simpl multinomi maximum likelihood model would give zero probabl combin encount train set would like give zero probabl sampl test case smooth model assign non zero probabl unobserv case would satisfactori either would provid much gener train set could obtain use multivari multinomi model whose paramet estim maximum posteriori map principl greatest probabl given train data use diffus prior dirichlet paramet graphic model bayesian network repres joint distribut random variabl zn zn zilearentsi part work done cirano montreal qc canada model high dimension discret data neural network parent set random variabl call parent variabl graphic model directli condit zi arrow drawn graphic model zi parent fulli connect left right graphic model illustr figur left correspond model zi zn zilzl zi figur left fulli connect qeft right graphic model right architectur neural network simul fulli connect left right graphic model observ valu zi zi encod correspond input unit group hi group hidden unit li group output unit depend zi repres paramet distribut zi condit probabl ziiz zi multipli obtain joint distribut note represent depend order variabl previou variabl order taken parent call combin valu parentsi context exact model full tabl possibl context order equival approxim use differ predict could made differ model assum differ order graphic model curs dimension show represent condit distribut lparentsi zi mani parent zj parent take rtj valu ij rtj differ context occur one would like estim distribut zi seriou problem address past two type approach sometim combin model depend variabl approach mainli taken graphic model bay network set independ assum use priori human expert knowledg learn data see also set parentsi restrict one element chosen maxim correl approxim mathemat form joint distribut form take account depend lower order take account possibl depend rademach walsh expans multi binomi low order polynomi approxim full joint binomi distribut use experi report paper approach put forward paper mostli second categori although use simpl non parametr statist depend pair variabl reduc number requir paramet multi binomi model joint distribut set binari variabl approxim polynomi wherea exact represent zn zn function zn polynomi degre rt approxim lower bengio bengio degre polynomi approxim easili comput use rademacherwalsh expans similar expans bahadur lazarsfeld expans therefor instead paramet approxim model zn requir paramet typic order use model propos also requir paramet allow model depend tupl variabl variabl time previou relat work frey fulli connect graphic model use see figur left condit distribut repres logist take account first order depend variabl zi zi exp wjzj paper basic extend frey idea use neural network hidden layer particular architectur allow multinomi continu variabl propos prune network weight frey name model logist autoregress bayesian network larc argu prior varianc logist weight correspond invers weight decay chosen invers proport number condit variabl number input particular output neuron model test task learn classifi digit binari pixel imag model differ order variabl compar yield signific differ perform averag predict probabl differ model obtain consid differ random order frey obtain small improv likelihood classif model perform better equival model test cart naiv bay nearest neighbor variou bayesian model hidden variabl helmholtz machin result impress take account simplic larc model propos architectur propos architectur neural network implement graphic model variabl observ train set hidden unit play signific role share paramet across differ condit distribut figur right illustr model simpler case fulli connect left right graphic model figur left neural network repres parametr function fo zl zn log po zl zn zn approxim joint distribut variabl paramet weight neural network architectur three layer layer organ group associ variabl log probabl comput sum condit log probabl fo zl zn log zi zi gi zi gi zi vector valu output th group output unit give valu paramet distribut zi zi zi exampl ordinari discret case gi may vector probabl associ possibl valu multinomi random variabl zi case exampl softmax output th group may use forc paramet posit sum egi gi model high dimension discret data neural network linear combin hidden unit output rang number element paramet vector associ distribut zi fix valu zi guarante function gi zl zi depend zl zi zi zn connect strutur hidden unit must constrain follow arc bias arc weight output layer hj output th unit raj unit th group hidden layer node may bc comput follow nk hj tanh cj vj zk bias weight hidden layer zk th element vectori input represent valu exampl binari case zi use one input node zi binomi zi zi multinomi case use one hot encod zi zi zi otherwis input layer group valu zn zn use input hidden layer also group correspond variabl sinc zx repres uncondit first output group correspond group need hidden unit input bias discuss number free paramet model maxi mj maximum number hidden unit per hidden group associ one variabl basic quadrat number variabl like multi binomi approxim use polynomi expans joint distribut howev increas represent theorem neural network suggest abl approxim arbitrari precis true joint distribut cours true limit factor amount data tune accord amount data experi use cross valid choos valu mj hidden group sens neural network represent zn polynomi expans multi binomi ordinari multilay neural network function approxim polynomi function approxim allow captur high order depend number hidden unit control mani depend captur data choos actual depend use maxim likelihood unlik bayesian network hidden random variabl learn propos architectur simpl even condit independ optim paramet simpli use gradient base optim method either use conjug stochast line gradient maxim total log likelihood sum valu eq train exampl prior paramet incorpor cost function map estim obtain easili maxim total log likelihood plu log prior paramet experi use weight decay penalti inspir analysi frey penalti proport number weight incom neuron bengio bengio howev clear distribut could gener margin except sum possibl mani combin valu variabl integr anoth relat question whether one could deal miss valu total number valu miss variabl take reason small one sum valu order obtain margin probabl maxim probabl variabl systemat miss valu put end variabl order case easi comput margin distribut take product output probabl miss variabl similarli one easili comput predict distribut last variabl given first variabl framework easili extend hybrid model involv continu discret variabl case continu variabl one choos parametr form distribut continu variabl parent condit context fix exampl one could use normal log normal mixtur normal instead softmax output th output group would comput paramet continu distribut mean log varianc anoth type extens allow build condit distribut model znlx xm one add extra input unit repres valu condit variabl xm final architectur extens implement allow direct input tooutput connect still follow rule order allow depend zi zi therefor case number hidden unit obtain larc model propos frey choic topolog anoth type extens model found use experi allow user choos topolog fulli connect left right experi use non parametr test heurist elimin connect network one could also use expert prior knowledg regular graphic model order cut number free paramet experi use pairwis test statist depend kolmogorov smirnov statist work continu discret variabl statist variabl sup xi yi xi yi number exampl empir distribut obtain count train data rank pair accord valu statist chosen pair valu statist threshold valu chosen cross valid pair zi zj chosen part model assum without loss gener pair connect kept network addit th hidden group th output group hidden group output group input group hidden group everi zj pair experi experi compar follow model naiv bay likelihood obtain product multinomi one per variabl multinomi smooth dirichlet prior multi binomi use rademach walsh expans order sinc handl case binari data appli dna data set simpl graphic model pair variabl variabl order select neural network condit distribut model model high dimension discret data neural network separ multinomi condit context work number condit variabl small mushroom audiolog soybean experi reduc number condit variabl follow order given test multinomi also smooth dirichlet prior neural network architectur describ without hidden unit larc without prune fold cross valid use select number hidden unit per hidden group weight decay neural network larc cross valid also use choos amount prune neural network larc amount smooth dirichlet prior multinomi naiv bay model simpl graphic model result four data set obtain web uc machin learn statlog databas meant classif task instead ignor classif use data learn probabilist model input featur dna statlog binari featur case use train cross valid test mushroom uci discret featur take valu case use train cross valid test audiolog uci discret featur take valu case use train test origin train test partit concaten split data obtain signific test figur soybean uci discret featur take valu case use train test tabl clearli show propos model yield promis result sinc prune neural network superior model case pairwis differ model statist signific case except audiolog differ network without hidden unit larc signific conclus paper propos new applic multi layer neural network model high dimension distribut particular discret data model could also appli continu mix discret continu data like polynomi expans previous propos handl high dimension distribut model approxim joint distribut reason number free paramet unlik allow captur high order depend even number paramet small model also seen extens previous propos auto regress logist bayesian network use hidden unit captur high order depend experiment result four data set mani discret variabl encourag comparison made naiv bay model multi binomi expans larc model simpl graphic model show neural network significantli better term sampl log likelihood case approach prune neural network use experi base pairwis statist depend test highli heurist better result might obtain use approach take account higher order depend select condit variabl method base prune fulli connect network weight elimin penalti also tri also tri optim bengio bengio dna mushroom mean stdev valu mean stdev valu naiv bay le multi binomi order le ordinari graph model le le larc le prune larc le le full conn neural net le le prune neural network audiolog soybean mean stdev valu mean stdev valu naiv bay le le multi binomi order ordinari graph model le larc le prune larc le full conn neural net le le prune neural network tabl averag sampl neg log likelihood obtain variou model four data set standard deviat averag parenthesi valu test null hypothes model true gener error prune neural network prune neural network better model case pair wise differ alway statist signific except respect prune larc audiolog order variabl combin differ network obtain differ order like refer bahadur represent joint distribut respons dichotom item ed solomon editor studi item analysi predictdion page stanford univers press california chow recognit method use neighbor depend ire tran elec comp ec octob duda hart pattern classif scene analysi wiley new york frey graphic model machin learn digit commun mit press steffen lauritzen em algorithm graphic associ model miss data comput statist data analysi judea pearl probabilist reason intellig system network plausibl infer morgan kaufmann