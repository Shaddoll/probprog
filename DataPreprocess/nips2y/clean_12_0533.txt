abstract present class approxim infer algorithm graphic model qmr dt type give converg rate algorithm jaakkola jordan algorithm verifi theoret predict empir also present empir result difficult qmr dt network problem obtain perform new algorithm roughli compar jaakkola jordan algorithm introduct graphic model formal provid appeal framework design analysi network base learn infer system formal endow graph joint probabl distribut interpret queri interest margin condit probabl joint fix model one gener interest condit probabl output given input predict input condit output diagnosi control learn focu usual likelihood margin probabl condit probabl unobserv node given observ node em gradient base algorithm condit probabl paramet given observ data bayesian set case key comput oper margin sever method avail comput margin probabl graphic model involv form messag pass graph exact method viabl mani interest case involv spars graph infeas dens graph consid current paper number approxim method evolv treat case includ search base method loopi propag stochast sampl variat method variat method focu current paper appli success number larg scale infer problem particular jaakkola jordan develop variat infer method qmr dt network benchmark network involv node see variat method provid accur approxim posterior probabl within second comput time difficult ng dordan infer problem exact method entir infeas see loopi propag converg correct posterior murphi weiss jordan stochast sampl method slow unreli jaakkola jordan signific step forward understand variat infer made kearn saul use larg deviat techniqu analyz converg rate simplifi variat infer algorithm impos condit magnitud weight network establish log rate converg error algorithm fan current paper util techniqu similar kearn saul deriv new set variat infer algorithm rate faster log techniqu also allow us analyz converg rate jaakkola jordan algorithm test algorithm ideal problem verifi analysi correctli predict rate converg appli algorithm difficult qmr dt network problem background qmr dt network qmr dt quick medic refer decis theoret network bipartit graph approxim top level node di repres diseas approxim lower level node repres find observ symptom node binaryvalu diseas given prior probabl di obtain archiv data find parameter noisi model ri set parent diseas find fi paramet ij obtain assess medic expert see shwe et al let zi oio je oi follow express likelihoodl sum sum across approxim configur diseas note second product product neg find factor across diseas ds factor absorb prior signific effect complex infer posit find coupl diseas prevent sum distribut across product gener exact algorithm junction tree algorithm scale exponenti size maxim cliqu moral triangul graph jaakkola jordan found cliqu node qmr dt rule junction tree algorithm heckerman discov factor specif qmr dt reduc complex substanti howev result algorithm still scale exponenti number posit find feasibl small subset benchmark case express factor dj probabl associ parent less diseas node factor probabl child find node observ posit state factor probabl neg find result product joint probabl margin obtain likelihood approxim infer algorithm two layer bayesian network jaakkola jordan algorithm jaakkola jordan propos variat algorithm approxim infer qmr dt set briefli approach make use follow variat inequ zl izi ci ci determinist function inequ hold arbitrari valu free variat paramet ai substitut variat upper bound probabl posit find eq one obtain factoriz upper bound likelihood factoriz sum across diseas distribut across joint probabl yield product sum rather sum product one minim result express respect variat paramet obtain tightest possibl variat bound kearn saul ks algorithm simplifi variat algorithm propos kearn saul whose main goal theoret analysi rate converg variat algorithm approach local condit probabl find fi approxim valu point small distanc depend whether upper lower bound desir mean input zi yield variat algorithm valu variat paramet optim assumpt weight oij bound magnitud constant number parent diseas node kearn saul show error likelihood algorithm converg rate log algorithm base local expans inspir kearn saul describ design approxim algorithm qmr dt obtain expans around mean input find node rather use point approxim kearn saul ks algorithm make use taylor expans see also plefka barber van de laar perturb techniqu consid gener qmr dt architectur noisi model replac gener function uniformli bound deriv defin zk zi fl zi fl likelihood written zl zk also defin zi oio ej oop dj simpl mean field like approxim obtain evalu mean valu refer approxim mf expand function second order defin ci zi fil cixq fili il qt zili il ia ng dordan subscript repres deriv drop remaind term bring expect insid mf approxim fili il gener obtain mf approxim carri taylor expans th order analysi section give two theorem establish converg rate mf famili algorithm jaakkola jordan algorithm kearn saul result obtain assumpt weight magnitud recal number diseas node larg assumpt weak interact impli zi close mean valu high probabl law larg number therebi give justif use local expans probabl find due space constraint detail proof theorem given section defer long version paper instead sketch intuit proof theorem let number offind fix suppos ioijl fix constant absolut error mf approxim odd even proof intuit first consid case odd sinc ioijl quantiti ei zi oij dj dj like averag random variabl henc standard deviat order fl sinc mf match th order deriv find take taylor expans mf error lead non zero term ei standard st order term contain quantiti deviat order unsurpris order give error mf odd even lead non zero term taylor expans error st order think ei converg via central limit term quantiti theorem effect symmetr distribut sinc symmetr distribut small odd central moment would small mean even may look order term error lead mf big error mf note also consist mf mf alway give estim henc absolut error theorem may also prove converg rate jaakkola jordan jj algorithm simplic state noisi network close relat result also hold sigmoid network suitabl modifi assumpt see full paper theorem let fix suppos noisi function suppos oij fix constant gmin fix gmin absolut error jj approxim note case jj appli log concav noisi network incident weight non neg approxim infer algorithm two layer bayesian network condit gmi lowerbound zi ensur find unlik hold suffici bia leak node network weight bound away zero proof intuit neglect neg find discuss need handl variat result prove simplifi version jj algorithm alway choos variat paramet exponenti upperbound zi tangent zi zi normal version jj error wors simplifi one take taylor expans approxim error find sinc upperbound match zeroth first deriv error discuss mf proof outlin second order term quantiti quantiti expect order henc jj error summar result use case find mf converg rate mf mf rate jj converg rate simul result artifici network carri set simul intend verifi theoret result present previou section use bipartit noisi network full connect layer weight oij chosen uniformli number top level diseas node rang prior diseas node chosen uniformli result shown figur one five posit find similar result obtain addit posit find diseas lo lff diseas figur absolut error likelihood averag mani randomli gener network function number diseas node variou algorithm short dash line ks upper lower bound curv overlap left panel long dash line jj algorithm solid line mf mf mf latter two curv overlap right panel result entir consist theoret analysi show nearli exactli expect slope loglog plot moreov asymptot result anomal behavior ks lower bound second panel due fact algorithm gener find vacuou lower bound case yield error essenti constant function number diseas ng jordan also predict overal perform mf mf algorithm perform best case mf jj roughli equival ks least accur qmr dt network present result qmr dt network particular four benchmark cpc case studi jaakkola jordan case fewer posit find thu possibl run heckerman quickscor algorithm obtain true likelihood case case exactli treat find exactli treat find figur result cpc case differ number exactli treat find horizont line true likelihood dash line jj estim lower solid line mf estim case case exactli treat find exactli treat find figur result cpc case legend jaakkola jordan hybrid methodolog propos portion find treat approxim exact method use treat remain find use hybrid methodolog figur show result run jj mf four case experi run use version jj algorithm optim variat paramet without find treat exactli use fix valu paramet thereaft order find chosen treat exactli base jj estim describ jaakkola jordan miss point graph case approxim infer algorithm two layer bayesian network result show mf algorithm yield result compar jj algorithm conclus extens multilay network paper present class approxim infer algorithm graphic model qmr dt type suppli theoret analysi converg rate verifi rate empir present promis empir result difficult qmr dt problem although focu paper two layer network mf famili algorithm also extend multilay network exampl consid layer network node bi parent node di parent node fi approxim pr use say mf first write pr expect function zi approxim function via second order taylor expans calcul expect taylor approxim need calcul term expans di didj di parent quantiti easili deriv term diseas prior probabl instead depend joint distribut di dj use two layer version mf appli first two bi di layer network approxim import futur work care studi perform algorithm multilay set acknowledg wish acknowledg help advic tommi jaakkola michael kearn kevin murphi larri saul refer barber van de laar variat cumul expans intract distribut journal artifici intellig research heckerman tractabl infer algorithm diagnos multipl diseas proceed fifth confer uncertainti artifici intellig jaakkola jordan variat probabilist infer qmr dt network journal artifici intellig research jordan ghahramani jaakkola saul introduct variat method graphic model learn graphic model cambridg mit press keam saul larg deviat method approxim probabilist infer rate converg cooper moral ed proceed fourteenth confer uncertainti artifici intellig san mateo ca morgan kaufmann murphi weiss jordan loopi belief propag approxim infer empir studi proceed fifteenth confer uncertainti artifici intellig plefka converg condit tap equat infinit rang ise spin glass model phi math gen shwe middleton heckerman henrion horvitz lehman cooper probabilist diagnosi use reformul internist qmr knowledg base probabilist model infer algorithm method oflnform medicin correspond run implement quickscor algorithm encount numer problem