abstract discuss inform theoret approach categor model dynam process approach learn compact inform statist summar past state predict futur observ furthermor uncertainti predict character nonparametr joint densiti learn statist present observ discuss applic techniqu nois driven dynam system random process sampl densiti condit past first case show result dynam random walk statist drive nois captur second case present result summar statist learn noisi random telegraph wave differ depend past state case algorithm yield principl approach discrimin process differ dynam depend method ground idea inform theori nonparametr statist introduct noisi dynam process abound world human speech frequenc sun spot stock market common exampl process difficult model categor current observ depend past complex way classic model come two sort assum dynam linear nois gaussian weiner etc assum dynam discret hmm approach wildli popular tractabl well understood unfortun mani process underli theoret assumpt model fals exampl may wish analyz system linear dynam non gaussian nois may wish model system unknown number discret state present inform theoret approach analyz stochast dynam process model simpl process like mention retain flexibl model wider rang complex process key insight often learn simplifi inform statist past sampl use nonparametr estim entropi mutual inform within tyamework predict futur state equal import character uncertainti accompani learn inform statist nonparametr approach predict non parametr model flexibl enough describ uncertainti complex second order statist contrast techniqu use squar predict error drive learn focus mode distribut take exampl financi forecast like sequenc price event interest one would also like know accompani distribut price valu even like outcom appreci price asset knowledg lower insignific probabl depreci also valuabl toward end describ approach allow us simultan learn depend process past well uncertainti futur state approach novel fold concept inform theori nonparametr statist learn two type stochast process consid challeng summar past effici way absenc known dynam probabilist model learn inform statist ideal suffici statist past minim uncertainti futur state classic linear state space approach uncertainti character mean squar error mse implicitli assum gaussian statist howev linear system interest behavior due non gaussian statist violat assumpt underli mse also nonlinear system pure probabilist process exhibit complex behavior poorli character mean squar error assumpt gaussian nois approach applic type process base nonparametr statist character uncertainti predict gener way densiti possibl futur state consequ result system captur dynam system parameter statist drive nois nonparametr model model use classifi new signal make predict futur learn stationari process paper consid two relat type stochast process depict figur process differ current observ relat past first type process describ follow set equat discret time dynam possibl nonlinear system xk xk wg xk xk zk state process time function previou state present valu gener sequenc xk stationari strict sens howev fairli mild condit name sequenc random variabl alway assum true sequenc ek xk xk stationari often term innov sequenc purpos stationar suffic lead predict framework estim dynam paramet system adjoin nonparametr character uncertainti second type process consid describ condit probabl densiti xk xkll xk case condit statist xk concern definit constant learn inform statist nonparametr estim propos determin system paramet minim entropi error residu system type parametr entropi optim approach fisher iii ihler ola xk qp xa xk max figur two relat system dynam system driven stationari nois probabilist system depend finit past dot box indic sourc stochast process solid box indic learn algorithm propos novelti approach howev estim entropi nonparametr bg argmin fp logp de jj al ek differenti entropi integr approxim use function parzen kernel densiti estim experi use gaussian kernel shown minim entropi error residu equival maxim likelihood light propos criterion seek maximum likelihood estim system paramet use nonparametr descript nois densiti consequ solv system paramet nois densiti jointli explicit dynam system second system type assum condit statist observ sequenc constant worst slowli chang line learn algorithm case desir minim uncertainti predict futur sampl summar inform past challeng effici via function recent sampl ideal would like find suffici statist past howev without explicit descript densiti opt instead inform statist inform statist simpli mean one reduc condit entropi futur sampl statist suffici mutual inform reach maximum previou case propos find statist maxim nonparametr mutual inform defin wf wf argmin xk wf xk argmin xk xklf equat equival optim joint margin entropi practic equat minim condit entropi previous present two relat method incorpor kernel base densiti estim inform theoret learn framework chose method provid exact gradient approxim entropi importantli convert implicit error function therebi reduc comput cost learn inform statist nonparametr approach distinguish random walk exampl random walk feedback function xk xk nois assum independ ident distribut although sequenc xk non stationari increment xk xk stationari context estim statist residu allow discrimin two random walk process differ nois densiti furthermor demonstr empir even one process driven gaussian nois implicit assumpt mmse criterion knowledg may suffici distinguish one process anoth figur show two random walk realiz associ nois densiti solid line one driven gaussian nois lk driven bi modal mixtur gaussian note densiti zero mean unit varianc learn process model fifth order auto regress ar one hundr sampl drawn realiz type ar paramet estim use standard mmse approach approach describ regard paramet estim method expect yield essenti paramet first coeffici near uniti remain coeffici near zero interest abil distinguish one process anoth mention current approach jointli estim paramet system well densiti nois nonparametr estim shown figur dot line estim use comput accumul averag log likelihood ek ogp xi residu sequenc rl known learn densiti figur strike surpris hi modal mixtur gaussian model dash line top differ significantli gaussian driven increment process solid line top explan follow fact lim llp true densiti ofe bi modal assum densiti likelihood test unit varianc gaussian kullback leibler diverg case lp rel small true less entropi unit varianc gaussian fix varianc gaussian densiti maximum entropi consequ likelihood test gaussian assumpt reliabl distinguish two process likelihood test bi modal densiti nonparametr estim figur bottom distinguish two method describ limit linear dynam model certainli use nonlinear model long dynam well approxim differenti function exampl multi layer perceptron describ learn structur noisi random telegraph wave noisi random telegraph wave rtw describ figur goal demonstr analyz random telegraph wave rather robustli learn inform statist past process defin noisi random telegraph wave sequenc ltk binomi distribut zl lak gaussian process interest paramet random function nonlinear combin set xk depend valu observ differ switch dynam figur show exampl signal fisher iii ihler iqola laudelan vl learn denait bi modal adom lk hi model leemeal den figur random walk exampl left comparison known learn densiti right known ou model known bi mod model lelrro model bi model stit islio figur ek known model left compar learn model right left right rapid switch dynam possibl signal period longer durat figur noisi random telegraph wave left right experi learn suffici statist form xk past wf hyperbol tangent function one layer perceptron note multi layer perceptron could also use experi train sampl noisi rtw rtw learn statist type process use test situat depth specifi specifi well perfectli learn inform statist nonparametr approach rtw ld ener hesi oo figur comparison wiener filter top nonparametr approach bottom synthesi figur inform statist noisi random telegraph wave train equal left right specifi denot fn xk statist train rtwuv process memori depth sinc implicitli learn joint densiti xk fn xk synthesi possibl sampl densiti figur compar synthesi use describ method bottom wiener filter top estim data result use inform theoret approach bottom preserv structur rtw wiener filter result achiev collaps inform past sampl singl statist avoid high dimens densiti estim figur show joint densiti fn xk see estim densiti separ virtu fact learn statist convey inform futur figur show result mont carlo trial case depth statist match process plot show accumul condit log likelihood ei glb xilf underthelearnedstatisticwitherror bar figur show similar result vari memori depth statist figur illustr robust choic memori depth say memori depth matter must inform exploit empir result indic use inform extract conclus describ nonparametr approach find inform statist approach novel learn deriv nonparametr estim entropi mutual inform allow mean effici summar past predict futur character uncertainti predict beyond second order statist futhermor accomplish without strong assumpt accompani parametr approach fisher iii ihler ola tm vs rocelm lell room figur condit ek solid line indic rtw dash line indic rtw thick line indic averag mont carlo run thin line indic standard deviat left plot use statist train rtw right plot use statist train rtw tmst ro ee figur repeat figur case obviou break indic new set trial also present empir result illustr util approach exampl random walk serv simpl illustr learn dynam system spite specif ar model importantli demonstr abil learn dynam statist underli nois process inform later use distinguish realiz nonparametr densiti someth possibl use mmse error predict even compel result experi noisi random telegraph wave demonstr algorithm abil learn compact statist effici summar past process identif method exhibit robust number paramet learn statist exampl despit overspecifi depend memori three case use statist still found convers despit memori statist underspecifi three experi use inform avail past extract opinion method provid altern tradit connectionist approach time seri analysi use nonparametr estim add flexibl class densiti model place less constraint exact form summar statist refer cover thoma element inform theori john wiley son new york viola et al emprici entropi manipul real world problem mozer touretski hasselmo editor advanc neural inform process system page fisher princip methodolog inform theoret featur extract stuberud editor proc ieee nt joint conf neural network page kapur kesavan entropi optim principl applic academ press new york parzen estim probabl densiti function mode ann math stat