abstract recent year bayesian network becom highli success tool diagnosi analysi decis make real world domain present effici algorithm learn bay network data approach construct bayesian network first identifi node markov blanket connect node maxim consist way contrast major work typic use hill climb approach may produc dens causal incorrect net approach yield much compact causal network heed independ data compact causal network facilit fast infer also easier understand prove mild assumpt approach requir time polynomi size data number node random variant also present yield compar result much higher speed introduct great number scientif field today benefit abl automat estim probabl certain quantiti interest may difficult expens observ directli exampl doctor may interest estim probabl heart diseas indic high blood pressur directli measur quantiti comput vision system may benefit probabl distribut build base indic horizont vertic straight line probabl densiti prolifer scienc today advanc estim like wide impact mani differ field bayesian network succinct effici way repres joint probabl distribut among set variabl appli field mention herskovit agosta besid abil densiti estim semant lend sometim loos refer causal discoveri name direct relationship among quantiti involv wide accept parsimoni represent bayesian net one close repres causal independ relationship may exist reason great interest automat induc structur bayesian net automat data prefer also preserv independ relationship process two research approach emerg first employ independ properti underli network produc data order discov part structur approach mainli exemplifi sg pc algorithm spirt well margar thrun figur left exampl markov blanket variabl shown member blanket shown shade right exampl reconstruct rectangular net branch factor algorithm present paper use sampl indic dot line direction error restrict class tree chow polytre reban second approach concern data predict disregard independ data typic identifi greedi hill climb best first beam search space legal structur employ score function form data likelihood sometim penal network complex result local maximum score network structur repres data one popular techniqu use today paper present approach belong first categori address two main shortcom prior work believ prevent use becom widespread two disadvantag exponenti execut time prone error depend test use former problem address paper two way one identifi local neighborhood variabl bayesian net preprocess step order facilit recoveri local structur around variabl polynomi time assumpt bound neighborhood size second random version goe one step employ user specifi number random test constant logarithm order ascertain result high probabl second disadvantag research approach name prone error also address random version use multipl data set avail bayesian accumul evid grow shrink markov blanket algorithm concept markov blanket variabl set variabl central paper concept new exampl see pearl surpris howev littl attent attract fundament properti bayesian net new paper introduct explicit use idea effect limit unnecessari comput well simpl algorithm comput definit markov blanket follow denot set variabl xs condit depend given set markov blanket set variabl bl bl word bl complet shield variabl variabl notion minim markov blanket call markov boundari also introduc pearl uniqu shown certain condit markov boundari uniqu certain patholog situat equal two variabl follow discuss assum condit necessari exist uniqu satisfi identifi markov blanket markov boundari use notat blanket variabl also illumin mention bayesian net framework markov blanket node easili identifi graph consist parent children parent children exampl markov blanket shown fig note node say depend given bayesian network induct via local neighborhood os grow phase shrink phase figur basic markov blanket algorithm algorithm recoveri markov blanket shown fig idea behind step simpl long markov blanket properti violat ie exist variabl depend add current set variabl process howev may variabl ad realli outsid blanket variabl would render independ later point interven node underli bayesian net ad observ necessit step identifi remov variabl algorithm effici requir condit test make run time idi ivi set exampl detail deriv bound well formal proof correct see margar practic one may tri minim number test step heurist order variabl loop step exampl ascend mutual inform probabl depend comput use test see section grow shrink gs algorithm bayesian net induct recoveri local structur around node greatli facilit knowledg node markov blanket would normal daunt task employ depend test condit exponenti number subset larg set variabl even though member may irrelev focus markov blanket node involv make structur discoveri much faster reliabl present plain version gs algorithm util blanket inform induc structur bayesian net later point paper present robust random version potenti faster reliabl well abl oper anytim manner follow repres direct neighbor comput markov blanket comput markov blanket comput graph structur determin direct neighbor depend given smaller orient edg orient exist variabl depend given smaller remov cycl follow exist cycl graph comput set edg part cycl remov edg part greatest number cycl put margar thrun revers edg insert edg graph revers propag direct neither execut follow rule longer appli exist direct path orient algorithm descript step determin member blanket node actual direct neighbor parent children assum without loss gener smaller set test success separ make independ algorithm determin direct connect would happen condit set includ parent common children interest note motiv behind select smaller set condit stem comput effici reliabl well condit set caus data set split partit smaller condit set caus data set split larger partit make depend test reliabl step exploit fact two variabl common descend becom depend condit set includ descend sinc direct neighbor known step determin whether direct neighbor parent exist anoth node coincident also parent attempt separ condit subset blanket includ fail assum smaller direction inde subset sinc condit perman depend path creat would case child straightforward show algorithm requir rib condit independ test maxx ib assumpt bound constant algorithm number condit independ test worthwhil note time comput condit independ test pass data set id vl analysi formal proof correct algorithm present margar discuss main advantag algorithm come use markov blanket restrict size condit set markov blanket may usual wrong side includ mani node repres disjunct test valu condit set data emphas import direct neighbor step remov node incorrectli ad markov blanket comput step admit variabl whose depend shown high confid larg number differ test also possibl edg direct wrongli determin step due nonrepres noisi data may lead direct cycl result graph therefor necessari remov cycl identifi minimum set edg need revers cycl disappear problem close relat margar minimum feedback arc set problem concern identifi minimum set edg need remov graph possibl contain direct cycl order cycl disappear unfortun problem np complet gener jtinger introduc reason heurist solut base number cycl edg part cycl involv edg direct determin last two step exampl node singl parent multi parent node call collid whose parent directli connect appli step step concern alreadi direct edg step attempt amelior orient edg way introduc bayesian network induct via local neighborhood cycl revers direct necessarili obviou exampl direct produc cycl otherwis acycl graph opposit direct also howev case proof see margar algorithm similar sg algorithm present spirt differ number way main differ lie use markov blanket dramat improv perform mani case bound blanket size assumpt hold structur similar sg stabil frequent refer robust follow discuss argument present spirt appli increas reliabl stem use smaller condit set lead greater number exampl per test pc algorithm also spirt differ gs algorithm involv linear probe separ set make unnecessarili ineffici random version gs algorithm gs algorithm present appropri situat maximum markov blanket set variabl small reason assum mani real life problem high level variabl involv may case problem bayesian imag retriev comput vision may employ finer represent case variabl use may depend direct manner mani other exampl may choos use variabl character local textur differ part imag resolut map textur variabl increasingli fine direct depend among variabl may plenti therefor maximum markov blanket size may signific anoth problem plagu independ test base algorithm bayesian net structur induct gener decis base singl test hard decis make prone error due nois data also appli gs algorithm would therefor advantag employ multipl test decid direct neighbor direct edg random version gs algorithm address two problem tackl random test bayesian evid accumul problem exponenti run time maximum blanket size step plain algorithm overcom replac seri test whose number may specifi user member condit set chosen randomli smallest blanket two variabl test provid evid direct connect two variabl appropri weight probabl circumst caus event occur due fact connected conjunct elementari event version algorithm shown detail due space restrict oper follow close one plain gs version main differ lie usag bayesian updat posterior probabl direct link depend collid pair variabl use condit depend test take account independ evid posterior probabl pi link execut depend test dj pi di pi pi ldi pi di lti factor take valu interv interpret un import truth test di smaller use accumul evid guid decis hypothesi feel confid besid abl time manner due user specifi number test also note approach also address robust problem mention use multipl weight test leav end hard decis involv threshold ie compar posterior probabl threshold case margar thrun edg error versu number sampl plain bn random gsbn hill climb score data likelihood hill climb score bic kl diverg versu number sampl plain gsi random gsbn hill climb score data likelihood hill climb score bic number sampl direct error versu number sampl plain bn random gsbn hill climb score data likelihood hill climb score bic number sampl number sampl figur result rectangular net branch factor direct blanket size function number sampl top kl diverg depict plain gs random gs hill climb algorithm bottom percentag edg direct error shown note certain edg error rate hill climb algorithm exceed result throughout algorithm present paper employ standard chi squar condit depend test done also spirt order compar histogram test give us probabl error assum two variabl depend fact type ii error depend test easili deriv probabl depend implicit confid threshold involv depend test indic certain wish correct test without unduli reject depend pair someth alway possibl realiti due presenc nois experi use correspond confid test test effect algorithm follow procedur gener random rectangular net specifi dimens branch factor number exampl drawn net use logic sampl use input algorithm test result net compar origin one along dimens kl diverg differ edg edg direction kldiverg estim use mont carlo procedur exampl reconstruct shown begin paper fig fig show kl diverg origin reconstruct net well edg omiss fals addit revers function number sampl use demonstr two fact first typic kl diverg gs hill climb algorithm low hill climb slightli lower show good perform applic predict prime concern second number incorrect edg error direction edg present much higher hill climb algorithm make unsuit accur bayesian net reconstruct fig show effect increas markov blanket increas branch factor expect see dramat exponenti increas execut time plain bayesian network induct via local neighborhood loo lo edg direct error versu branch factor edg error plain gsbn edg error random gsbn direct error plain gsbn direct error random gsbn branch factor execut time versu branch factor plair gsbn branch factor figur result rectangular net sampl gener use reconstruct versu increas branch factor left error slowli increas expect compar plain random version gs algorithm right correspond execut time shown gs algorithm though mild increas random version latter use constant condit test per decis execut time increas attribut quadrat increas number decis note error percentag plain random version remain rel close number direct error gs algorithm actual decreas due larger number parent node structur allow greater number opportun recov direction edg use increas number test discuss paper present effici algorithm comput markov blanket node use two version gs algorithm plain random exploit properti markov blanket facilit fast reconstruct local neighborhood around node assumpt bound neighborhood size also present random variant advantag faster execut speed ad reconstruct robust due multipl test bayesian accumul evid simul result demonstr reconstruct accuraci advantag algorithm present hill climb method addit result also show random version dramat execut speed benefit plain one case assumpt bound neighborhood hold without significantli affect reconstruct error rate refer chow herskovit spirt pearl reban verma agosta cheng margar jqnger chow liu approxim discret probabl distribut depend tree ieee transact inform theori herskovit cooper kutat entropi driven system construct probabilist expert system databas uai spirt glymour schein causat predict search springer pearl probabilist reason intellig system morgan kaufmann reban pearl recoveri causal poli tree statist data uai verma pearl equival synthesi causal model uai agosta structur bay network visual recognit uai cheng bell liu algorithm bayesian network construct data ai statist margar thrun bayesian network induct via local neighborhood tr cmu cs forthcom jqnger polyhedr combinator acycl subdigraph problem heldermann