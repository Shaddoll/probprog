abstract paper introduc new class imag model call dynam tree dt dynam tree model specifi prior larg number tree one tree structur belief net tsbn experi show dt capabl gener imag less blocki model better translat invari properti fix balanc tsbn also show simul anneal effect find tree high posterior probabl introduct paper introduc new class imag model call dynam tree dt dynam tree model specifi prior larg number tree one tree structur belief net tsbn aim retain advantag tree structur belief network name hierarch structur model part effici infer algorithm avoid blocki artifact deriv singl fix tsbn structur one use dt prior model label imag segment problem section paper give theori dt experi describ section theori two essenti compon make dynam tree network tree architectur ii node condit probabl tabl cpt given tree consid architectur question first dt dynam tree oooooooooooooooo figur nake node balanc tree architectur sampl prior data gener tree consid number node arrang layer figur wish construct tree structur child node particular layer connect parent layer also allow null parent layer child connect becom new root technic construct forest rather tree exampl structur gener use method shown figur number way specifi prior tree denot zi indic vector show parent node belong tree structur specifi matrix whose column individu zi vector one node scheme investig far set zi work specifi zi follow child node consid natur parent parent balanc structur shown figur node parent layer assign affin child node natur parent highest affin denot affin node parent layer ate choos zi ek pa aj posit constant ek unit vector posit note null parent includ sum affin anul associ affect rel probabl orphan name prior full time node employ prior node particip creation tree structur degre specifi prior architectur need translat tsbn unit tree taken class multinomi random variabl layer structur associ prior probabl vector rt cpt mr given particular matrix specifi forest structur probabl particular instanti random variabl simpli product probabl tree appropri root probabl cpt pick rt mr sampl gener tree structur figur shown figur william adam intuit dt may use imag model base idea pixel imag deriv singl object think object describ root tree scale object determin level tree root occur interpret cpt probabl mass diagon given data bottom layer unit form posterior tree structur node instanti layer rather like obtain set pars number sentenc use context free grammar dt model describ differ exampl explain differ tree import differ usual prior belief network use bayesian averag model structur also usual case model averag normal restrict tsbn structur tie paramet rt mr differ structur infer dt consid problem infer dt obtain posterior xhixv denot tree structur xv visibl unit imag clamp lowest level xh hidden unit fact shall concentr obtain posterior margin zixv obtain sampl xnlxv use standard techniqu tsbn larg number possibl structur fact set node creat balanc tree branch factor depth top level index rli possibl forest structur object obtain maximum posteriori map state posterior zixv xvlz use simul anneal possibl two compon xv readili evalu xv comput yir xr xr xr xr pearl style vector root forest altern sampl posterior xnlxv use approxim infer one possibl use mean field type approxim posterior form qz qn zoubin ghahramani person commun compar dt imag model fix structur tsbn use number author model imag bouman shapiro luettgen willski attract multi scale structur suffer problem due fix tree structur lead blocki segment markov random field mrf model also popular imag model howev one main limit infer mrf np hard also lack hierarch structur hand stationar process defin easili ensur cfg algorithm infer map pars howev algorithm depend crucial one dimension order input believ possibl cross link dt architectur mean kind algorithm applic dt case also dt model appli imag algorithm applic also possibl sampl posterior use gibb sampl dt dynam tree case fix structur tsbn one strategi overcom fix structur tsbn break away tree structur use belief network cross connect dayan et al howev mean lose linear time belief propag algorithm use tree pearl use approxim algorithm true infer dt also np hard retain clean semant base fact expect pixel belong one object may lead use approxim scheme experi section describ two experi conduct dt model first design compar translat perform dt balanc tsbn structur describ section section gener imag dt model find map dynam tree imag contrast perform rel balanc tsbn compar dt balanc tsbn consid layer binari tree leaf node shown figur node tree binari variabl take valu white black rt mt affin set equal layer valu use refer white valu diagon offdiagon affin set natur parent nearest neighbour natur parent non nearest neighbour black node black node figur plot unnormalis log posterior vs posit input pattern black node pattern black node pattern illustr effect translat taken stimulu made bar five black pixel move across imag unnormalis log posterior particular configur logp logp xv comput balanc tsbn architectur compar highest valu found conduct search result plot figur axi denot posit left hand end bar run ath affin defin addit arbitrari constant qlliam adam axi show posterior probabl note due symmetri realiti fewer distinct configur figur show clearli balanc tsbn poor model stimulu much better interpret found use dt even though natur parent idea ensur log alway larger balanc tree notic also balanc tsbn display greater sensit log posterior respect posit dt model figur show optim log posterior found hand use intuit best tree map model discov simul anneal anneal conduct start temperatur exponenti decreas factor temperatur propos could made although transit next temperatur would occur accept step run deem converg five success temperatur step made without accept singl step also show log posterior tree found gibb sampl report best configur found four separ run differ random start posit run sweep node figur shown log posterior stimulu made four black node case balanc tsbn even sensit stimulu locat four black node fit exactli one sub tree posit contrast dynam tree less sensit align although retain prefer configur favour balanc tsbn due concept natur parent built current architectur see section discuss clearli result somewhat sensit set paramet one import paramet diagon entri cpt control rel desir disconnect transit tree involv colour chang exampl diagon entri cpt reduc gap optim balanc tree figur decreas experi cpt entri otherwis need explor paramet space obtain result shown gener prior find map tree turn attent imag consid layer quad tree node arrang give total leaf node pixel imag structur plot tree gener prior shown figur sub plot slice tree show node success level box repres singl node current level shade indic tree belong node parent layer superimpos circl line eman show connect black circl smaller white circl insid use indic root node thu exampl see forest consist five tree four whose root lie level account black imag figur root node level respons background paramet except level set encourag disconnect level dt dynam tree figur plot map dynam tree accompani imag broadli speak paramet dt set similar tree previou section except disconnect affin set favour disconnect higher tree valu leaf level leaf disconnect probabl tend zero practic result leav connect parent node desir believ singl pixel object unlik fi valu increas tree depth lower level node choos parent tighter neighbourhood rt mt valu unchang consid binari valu node suit imag creat sampl dt prior gener imag figur show exampl imag gener dt seen blocki exhibit balanc tsbn present figur comparison map dt log posterior quad tree imag tree gener part time node employ prior william adam map dynam tree imag found simul anneal use exponenti strategi describ earlier log posterior compar balanc tsbn plot line denot boundari equal log posterior locat point clearli show everi case map tree found higher posterior discuss demonstr dt model greater translat invari exhibit blocki balanc tsbn model also see simul anneal method success find tree high posterior probabl discuss extens model work kept balanc tree arrang node howev could relax give rise roughli equal number node variou level cf stationari wavelet would use provid better translat invari avoid slight shortag hidden unit occur pattern misalign wrt balanc tree present case prior would need adjust ensur high proport tree like structur gener layer conting state unit layer devis prior natur call part timeemploy prior node decid whether wish employ tree structur remain redund inact exampl tree gener prior shown figur plan explor direct go research research direct includ learn paramet network use em introduct addit inform node exampl one might use real valu variabl addit multinomi variabl consid addit variabl might use encod inform concern instanti paramet object acknowledg work stem convers cw zoubin gharahmani isaac newton institut octob thank zoubin ghahramani geoff hinton peter dayan help convers isaac newton institut mathemat scienc cambridg uk hospit neural network machin learn programm nja support epsrc research studentship work cw partial support epsrc grant gr combin patial distribut predict neural network refer bouman shapiro multiscal random field model bayesian imag segment ieee transact imag process dayan hinton neal zemel helmholtz machin neural comput luettgen willski likelihood calcul class multiscal stocahst model applic textur discrimin ieee tran imag process pearl probabilist reason intellig system network plausibl infer san mateo ca morgan kaufmann