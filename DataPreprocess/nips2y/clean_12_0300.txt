abstract known decis tree learn view form boost howev exist boost theorem decis tree learn allow binari branch tree gener multi branch tree immedi practic decis tree algorithm cart implement trade number branch improv tree qualiti measur index function give boost justif particular quantit trade curv main theorem state essenc requir improv proport log number branch top greedi construct decis tree remain effect boost algorithm introduct decis tree prove popular tool experiment machin learn popular stem two basic featur construct quickli seem achiev low error rate practic case time requir tree growth scale linearli sampl size effici tree construct allow larg data set hand although known theoret handicap decis tree represent seem practic achiev accuraci compar learn paradigm neural network decis tree learn algorithm popular practic seem hard quantifi success theoret model fairli easi see even target function describ use small decis tree tree learn algorithm may fail find good approxim kearn mansour use weak learn hypothesi show standard tree learn algorithm perform boost provid theoret justif decis tree learn similar boost multi way branch decis tree justif given variou boost algorithm adaboost decis tree learn algorithm use top growth process given current tree algorithm select leaf node extend intern node assign branch function ad leaf possibl output valu branch function set branch function may differ one algorithm anoth algorithm use practic tri keep set branch function fairli simpl exampl branch function depend singl attribut categor attribut branch accord attribut valu continu attribut perform comparison attribut constant cours top tree growth fit data easi construct larg tree whose error rate train data zero howev class split function finit vc dimens possibl prove high confid choic train data tree true error rate bound error rate train sampl iti number leav rn size train sampl fit avoid requir top tree growth produc small tree practic usual done construct larg tree prune away node take slightli differ approach assum given target tree size consid problem construct tree iti small possibl avoid fit select small target valu tree size fundament question top tree growth select branch function grow given leaf think target size budget four way branch spend tree size budget two way branch four way branch increas tree size roughli amount two twoway branch suffici larg branch would spend entir tree size budget singl step branch spend tree size budget requir achiev progress branch spend less budget naiv one would expect improv requir roughli linear number new leav introduc one get return proport expens howev weak learn assumpt target tree size defin nontrivi game learner adversari learner make move select branch function adversari make move present option consist weak learn hypothesi prove learner achiev better valu game select branch get return consider smaller naiv linear return main theorem state essenc return need proport log number branch preliminari assum set instanc unknown target function map assum given train set set pair form let set potenti branch function function finit set rh allow differ function differ rang requir rhl tree mansour mcallest tree intern node label branch function children correspond element set rh defin number leaf node let set leaf node given tree leaf node sampl write st denot subset sampl reach leaf defin dr fraction sampl reach leaf st defin fraction pair fix st train error denot tel ldt min weak learn hypothesi boost view top decis tree learn form boost boost describ gener class iter algorithm base weak learn hypothesi classic weak learn hypothesi appli class boolean function let subset branch function rh classic weak learn hypothesi state distribut exist prt fix algorithm design exploit particular hypothesi class boolean function prove quit use practic kearn mansour show key use weak learn hypothesi decis tree learn use index function min defin note condit impli sampl let qw fraction pair let ta decis tree consist singl intern node branch function plu leaf member iral let iw ta denot valu ta measur respect sampl let denot qw iw th quantiti reduct index sampl achiev introduc singl branch also note dta reduct leaf replac branch kearn mansour prove follow lemma lemma kearn mansour assum weak learn hypothesi take sampl exist qw lemma motiv follow definit definit say satisfi weak tree growth hypothesi sampl exist qw lemma state essenc classic weak learn hypothesi impli weak tree growth hypothesi index function empir howev weak tree growth hypothesi seem hold varieti index function alreadi use tree growth prior work kearn mansour ginni index use cart entropi qlog log use long empir observ possibl make steadi progress reduc choic difficult make steadi progress reduc defin simpl binari branch procedur given train set target tree size algorithm grow tree iti algorithm boost multi way branch decis tree denot trivial tree whose root leaf node tt denot result replac leaf branch function new leaf element rh iti argmax argmax end ff defin quantiti ii note ii zia inn theorem kearn mansour yt satisfi weak tree growth hypothesi binari branch procedur produc tree lti proof proof induct number iter procedur initi tree immedi satisfi condit assum condit satisfi begin iter prove remain satisfi tt end iter sinc leaf select procedur sti qt weak tree growth assumpt function select procedur properti st yi tt ta st btyi qt impli iti statement main theorem construct tree growth algorithm select multi way branch function mani weak learn hypothes weak tree growth hypothesi view defin game learner adversari given tree adversari select set branch function allow leaf tree subject constraint leaf adversari must provid binari branch function yi learner select leaf branch function replac tt adversari select new set option leaf subject weak tree growth hypothesi proof theorem impli even adversari reassign option everi move exist learner strategi binari branch procedur guarante achiev final error rate iti cours optim play adversari game provid singl binari option leaf howev practic adversari make mistak provid option learner exploit achiev even lower error rate object construct strategi learner exploit multi way branch provid adversari first say branch function accept tree target size mansour mcallest either iral iti irad ra also defin quantiti note also note nk henc nk small nk henc defin follow multi branch tree growth procedur argmax argmaxa accept tt end run multi branch tree growth procedur call boost iter branch function select properti st iral qt weak tree growth hypothesi impli lahl qt therefor weak tree growth hypothesi impli everi run multi branch growth procedur boots run boots exploit mutli way branch even weak tree growth hypothesi fail follow main theorem paper theorem produc boost run multi branch tree growth procedur lt proof theorem prove main theorem need concept visit weight tree vwtree short vw tree tree node rn assign ration weight integ visit count defin follow vw tree growth procedur procedur tree consist singl root node weight visit count tree tt ok result insert new leav leaf ith new leaf weight wi new leav visit count ration number number step repeat follow argmaxt vl vl option tt ov wv vt wt first prove analog theorem procedur vw tree defin iti lsi vt defin tsi vt wt lemma vw procedur maintain invari iti proof proof induct number iter algorithm result immedi initi tree sinc assum iti start iter show remain true end iter boost multi way branch decis tree associ leaf vt subleav weight vt wt vt iti total number subleav total weight subleav therefor must exist subleaf whose weight least henc must exist leaf satisfi vt wt vt iti therefor relat must hold leaf select procedur let tree result increment vt vt wt vt wt vt wt vt wt vt wt iti final procedur grow new leav increas remain henc invari maintain intern node tree let denot set node children vw tree call local well form everi intern node ic ic vw tree call global safe maxt vt wt vt minm vt wt vt denot set intern node lemma local well form global safe vw tree possibl output vw growth procedur therefor lti proof sinc local well form use templat make nondeterminist choic vw growth procedur process guarante produc provid growth procedur never forc visit node correspond leaf global safeti condit guarante unfinish intern node weight least larg leaf node give way map tree vw tree specif tree defin vw result assign node weight qm intern node visit count equal number children leaf node visit count equal follow lemma lemma grown boost run multi branch procedur vw local well form proof note children intern node deriv select branch function node sinc run boost irhl qt therefor th irl impli th multipli transform result weight tree vw give desir result follow lemma suffic theorem lemma grown boost run multi branch procedur vw global safe proof first note follow invari boost run multi branch procedur max wt min wt vw vw mansour mcallest proof simpl induct boost tree growth use fact procedur alway expand leaf node maxim weight must show everi intern node everi leaf wl number children note reduc wl follow invari assum without loss gener also sinc suffic show wt let intern node children let tree time rn select expans let wt maximum weight leaf final tree definit accept condit last iter perform binari branch binari expans reduc index least time weight select node sinc sequenc node select multi branch procedur non increas weight iter weight select node least wt sinc least binari expans expans reduc least wl accept condit written kit yield wl klt yield wl desir refer leo breiman jerom friedman richard olshen charl stone classif regress tree wadsworth intern group tom dietterich michael kearn yishay mansour learn framework understand improv learn appli weak proc machin yoav freund boost weak learn algorithm major inform comput yoav freund robert schapir decis theoret gener line learn applic boost comput learn theori second european confer eurocolt page springerverlag yoav freund robert schapir experi new boost algorithm machin learn proceed thirteenth intern confer page michael kearn yishay mansour boost abil top decis tree learn proceed twenti eighth cm symposium theori comput page ross quinlan program machin learn morgan kaufmann robert schapir strength weak learnabl machin learn