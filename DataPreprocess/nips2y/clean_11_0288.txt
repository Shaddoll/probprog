abstract margin cumul train margin distribut adaboost versu direct optim margin doom algorithm dark curv adaboost light curv doom doom sacrific signific train error improv test error horizont mark margin line introduct mani learn algorithm pattern classif minim cost function train data aim minim error probabl misclassifi exampl one exampl cost function simpli classifi error train data recent result examin altern cost function provid better error estim case exampl result bar show error sigmoid network classifi sampl averag cost function sgn yy take valu yy otherwis plu complex penalti term scale ilwl label train exampl iwii sum magnitud output node weight quantiti yf margin real valu function reflect extent agre label minim squar error neural network learn algorithm implicitli maxim margin may explain good gener perform recent schapir et al sfbl shown similar result convex combin classifi produc boost algorithm show direct optim margin improv gener high probabl random exampl everi convex combin classifi finit class error satisfi logmloglh pr yf es sgn yf log es denot averag sampl one way think result techniqu adjust effect complex function class adjust larg valu correspond low complex small valu high complex learn algorithm optim parametr cost function essgn yf larg valu would abl make fine distinct differ function class effect complex class would reduc second term error bound regular term involv complex paramet size base hypothesi class would correspondingli reduc neural network boost set learn algorithm directli minim cost function use differ valu complex paramet cost function explain gener perform paper address question suitabl cost function convex combin classifi next section give gener condit parametr famili cost function ensur use give error bound convex combin classifi remaind paper investig learn algorithm choos convex coeffici combin classifi minim suitabl famili piecewis linear cost function use gradient descent even base hypothes chosen adaboost algorithm use new cost function adjust convex coeffici obtain improv test error adaboost one uc irvin data set use margin distribut plot show mani case algorithm achiev lower error sacrif train error interest reduc new cost function theori section deriv error bound gener result convex combin classifi describ previou section result involv famili margin cost function function map interv index integ valu complex paramet measur resolut examin margin follow definit give condit margin cost function relat complex amount margin cost function larger function sgn yf particular form definit import particular function use analysi section concern us later paper definit famili margin cost function admiss interv length function satisfi sgn ez qn cn ez qn denot expect chosen randomli zi zi pr zi exampl let sgn constant admiss famili margin cost function suitabl larg mason bartlett baxter exhibit function sgn proof involv chernoff bound clearli larger valu cost function cn closer threshold function sgn inequ impli follow theorem theorem co set convex combin function similar proof give result vcdim replac theorem admiss famili cn margin cost function finit hypothesi class distribut probabl least random sampl label exampl chosen accord everi everi co satisfi pr yf es cn yf nlnihl ln proof fix co suppos oqhi hi defin con hj hj notic icon ih proof sfbl show use probabilist method function con close approxim let distribut con correspond averag independ draw hi accord distribut let qn distribut given definit fix pair chosen accord distribut yg qn yf fix function impli admiss condit definit admiss eg er yg epez qn epsgn yf yf similarli cn yf eg yg henc pr yf es un yf en yg es yg en thu pr pr yf es cn yf pr con ep yg yg en hi exp last inequ follow union bound hoeffd inequ set probabl solv en sum valu complet proof sinc ne best bound want satisfi ez qn sgn ct differ ez sgn small possibl one approach would minim expect differ ct chosen uniformli howev yield non monoton solut ct figur la illustr exampl monoton admiss famili show cost function cn ez ct sgn og algorithm consid select convex coeffici wl wt sequenc classifi ht combin classifi wtht small error experi use hypothes provid adaboost aim investig use error estim provid cost function previou section take theorem face valu ignor log term best error bound obtain weight wl wr complex chosen minim direct optim margin improv gener figur margin cost function cn compar function sgn larger valu correspond closer approxim sgn piecewis linear upper bound function cn ct function sgn ct civ yif xi nv ff constant famili admiss cost function although theorem provid express constant practic problem almost certainli overestim penalti even moder complex model great solv problem instead optim averag cost margin plu penalti term valu paramet estim optim valu use cross valid set fix valu discret fairli dens set select weight optim averag cost co yif xi chose solut smallest error independ cross valid set consid use cost function plot figur la exist fiat region caus difficulti gradient descent approach instead adopt piecewis linear famili cost function co linear interv pass point number chosen ensur co upper bound cost function figur la see figur lb note play role complex paramet except case smaller valu correspond higher complex class even restrict piecewis linear cost function problem optimizi ing co yif xi still hard fortun natur cost function make possibl find success heurist chose algorithm devis optim co famili cost function call direct optim margin doom pseudo code algorithm given full version mbb doom basic form gradient descent two complic take account fact cost function differenti ensur weight vector lie unit ball order avoid problem local minima actual allow weight vector lie within ball throughout optim rather ball weight vector reach surfac ball updat direct point ball project back surfac ball observ gradient co yif xi constant function weight wt provid exampl xi yi cross one discontinu provid margin yif xi cross henc central oper doom step neg gradient direct exampl margin hit one discontinu project necessari ensur weight vector lie within ball point gradient vector becom multi valu gener two valu possibl gradient direct test take small step direct mason bartlett baxter random subset gradient direct chosen mani none direct lead decreas cost exampl whose margin lie discontinu cost function ad constraint set subsequ iter step procedur follow except direct step modifi ensur exampl move remain discontinu point weight vector move within subspac defin exampl progress made iter constraint set reset zero still progress made procedur termin experi use follow two class problem uc irvin databas cbm cleveland heart diseas credit applic german glass ionospher king rook vs king pawn pima indian diabet sonar tic tac toe wisconsin breast cancer sake simplic consid multi class problem data set randomli separ train test valid set test valid set equal size repeat time independ result averag adaboost test error figur rel improv doom adaboost examin dataset experi consist follow step first adaboost run train data produc sequenc base classifi correspond weight experi base classifi axi orthogon hyperplan also known decis stump choic ensur complex class base classifi constant boost halt ad new classifi fail decreas error valid set doom run classifi produc adaboost larg rang valu random initi weight vector valu weight vector valu minimum misclassif valid set chosen final solut case train set reduc size make overfit like complex regular doom could effect detail given full version mbb three dataset credit applic wisconsin breast cancer pima indian diabet adaboost gain advantag use singl classifi dataset number classifi chosen valid error reason stabl comparison test error gener adaboost doom shown figur one data set doom produc classifi perform wors adaboost term test error data sbt doom test error signific improv adaboost figur show cumul train margin distribut graph four dataset adaboost doom optim chosen cross valid given margin valu curv correspond proport train exampl margin mor valu test error algorithm also shown comparison short horizont line vertic axi margin distribut show valu minimum train margin real impact gener perform see also bre gs direct optim margin improv gener wiscons breast cancer mar iono margin ioo ioo credit applic margin margin figur cumul train margin distribut four dataset dark curv adaboost light curv doom select cross valid test error algorithm mark vertic axi margin seen figur credit applic sonar data set gener perform combin classifi produc doom good better classifi produc adaboost despit dramat wors minimum train margin convers figur ionospher data set show improv gener perform associ improv minimum margin margin distribut also show balanc found train error complex measur doom will sacrific train error order reduc complex therebi obtain better margin distribut instanc figur sonar data set doom train error adaboost doom test error less adaboost reason success seen figur illustr chang cost function train error test error function optim complex data set low correspond larg optim case reduct complex import gener error reduct train error conclus paper address question suitabl cost function convex combin base hypothes gener famili cost function function margin sampl prove theorem error convex combin sampl averag cost function plu regular term involv complex cost function size base hypothesi class construct piecewis linear famili cost function satisfi condit theorem present heurist algorithm doom optim sampl mason bartlett baxter figur sonar data set left plot cost co yif xi adaboost doom right plot train test error averag cost ran experi sever dataset uc irvin databas adaboost use gener set base classifi doom use find optim convex combin classifi one case convex combin gener doom lower test error adaboost combin margin distribut plot show mani case doom achiev lower test error sacrif train error interest reduc new cost function margin plot also show size minimum margin relev gener perform acknowledg thank yoav freund wee sun lee rob schapir help comment suggest research support part grant australian research council jonathan baxter support australian research council fellowship llew mason support australian postgradu award refer bar bre cbm gs mbb sfbl bartlett sampl complex pattern classif neural network size weight import size network ieee transact inform theori breiman predict game arc algorithm technic report depart statist univers california berkeley keogh blake merz uci repositori machin learn databas http www ic uci edu mlearn mlrepositori html grove schuurman boost limit maxim margin learn ensembl proceed fifteenth nation confer artifici intellig page mason bartlett baxter improv gener explicit optim margin technic report depart system engin australian nation univers avail http syseng anu edu au lsg schapir freund bartlett lee boost margin new explan effect vote method annal statist appear