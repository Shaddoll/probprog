abstract propos novel strategi train neural network use sequenti sampl import resampl algorithm global optimis strategi allow us learn probabl distribut network weight sequenti framework well suit applic involv line nonlinear non gaussian non stationari signal process introduct paper address sequenti train neural network use power sampl techniqu sequenti techniqu import mani applic neural network involv reai time signal process data arriv inher sequenti furthermor one might wish adopt sequenti train strategi deal non stationar signal inform recent past lent credenc inform distant past one way sequenti estim neural network model use state space formul extend kaiman filter singhal wu de freita niranjan gee involv local linearis output equat easili perform sinc need deriv output respect unknown paramet approach employ sever author includ global optimis neural network model via sequenti sampl howev local linearis lead ekf algorithm gross simplif probabl densiti involv nonlinear output model induc multimod result distribut gaussian approxim densiti loos import detail approach adopt paper one sampl particular discuss use sampl import resampl sequenti import sampl algorithm also known particl filter gordon salmond smith pitt shephard train multi layer neural network state space neural network model start state space represent model neural network evolut time transit equat describ evolut network weight measur equat describ nonlinear relat input output particular physic process follow wk wk dk yk wk xk vk yk denot output measur xk input measur wk rm neural network weight measur nonlinear map approxim multi layer perceptton mlp measur assum corrupt nois vk sequenti mont carlo framework probabl distribut nois specifi user exampl shall choos zero mean gaussian distribut covari measur nois assum uncorrel network weight initi condit model evolut network weight assum depend previou valu wk stochast compon dk process nois dk may repres uncertainti paramet evolv model error unknown input assum process nois zero mean gaussian process covari howev distribut also adopt choic distribut network weight requir research process nois also assum uncorrel network weight posterior densiti yk wk constitut complet solut sequenti estim problem mani applic track interest estim one margin name filter densiti wklyk comput filter densiti recursir need keep track complet histori weight thu storag point view filter densiti turn parsimoni full posterior densiti function know filter densiti network weight easili deriv variou estim network weight includ centfold mode median confid interv sequenti import sampl sequenti import sampl optimis framework set repres sampl use describ posterior densiti function network paramet sampl consist complet set network paramet specif make use follow mont carlo approxim iv de freita niranjan doucet gee repres sampl use describ posterior densiti denot dirac delta function consequ expect form ly dw may approxim follow estim sampl drawn posterior densiti function typic one cannot draw sampl directli posterior densiti yet draw sampl propos densiti function wn iyn transform expect wnlyn expect wn yn follow fa wa fa wa wali walya dwa dw variabl known unnormalis import ratio yn lwn wn wn iyn henc draw sampl propos function approxim expect interest follow estim normalis import ratio given difficult show de freita niranjan gee doucet assum hidden markov process initi densiti transit densiti wklwk variou recurs algorithm deriv one algorithm hysir deriv de freita niranjan gee doucet shown perform well neural network train extend algorithm deal multipl nois level pseudo code hysir algorithm ekf updat followsx made avail softwar implement hysir algorithm follow web site http svr mm eng cam ac uk jfgf soft html global optimis neural network model via sequenti sampl initialisenet rkweight sampl stage predict via dynam equat wk sampl dk af updat sampl ekf equat case evalu import ratio yk wk ki af xk rk wk normalis import ratio qk resampl stage neff threshold els resampl new index discret set lw known kalman gain matrix imm denot ident matrix size two tune paramet whose role explain detail de freita niranjan gee repres jacobjan matrix strictli speak approxim covari matrix network weight resampl stage use elimin sampl low probabl multipli sampl high probabl variou author describ effici algorithm accomplish task oper pitt shephard carpent clifford fearnhead doucet de freita niranjan doucet gee expeki assess abil hybrid algorithm estim time vari hidden paramet gener input output data logist function follow linear scale displac shown figur simpl model equival mlp one hidden neuron output linear neuron appli two gaussian input sequenc model corrupt weight output valu gaussian nois respect train second model structur use input output figur logist function linear scale displac use experi weight chosen follow wx sin ws ws data gener first model chose sampl trajectori set initi weight varianc process nois paramet set three level shown plot figur time zero train sampl figur nois level estim hysip algorithm phase time step allow model weight vari time phase hysip algorithm use track input output train data estim latent model weight addit assum three possibl nois varianc level begin train session th time step fix valu weight gener anoth input output data test set origin model input test data fed train model use weight valu estim th time step subsequ global optimis neural network model via sequenti sampl output predict train model compar output data origin model assess generalis perform train process shown figur nois level trajectori converg true valu addit possibl track network weight obtain accur output predict shown figur output predict output predict figur one step ahead predict train phase left stationari predict test phase right loo time irt figur weight track perform hysir algorithm indic histogram algorithm perform global search paramet space de freita niranjan doucet gee conclus paper present sequenti mont carlo approach train neural network bayesian set particular propos algorithm hysir make use gradient sampl inform hysir interpret gaussian mixtur filter sampl trajectori need employ yet number trajectori increas comput requir increas linearli therefor method also suitabl sampl strategi approxim multi modal distribut avenu research includ design algorithm adapt nois covari studi effect differ nois model network weight improv comput effici algorithm acknowl ement jof fg de freita financi support two univers witwatersrand merit scholarship foundat research develop scholarship south africa or award triniti colleg extern studentship cambridg refer carpent clifford fearnhead improv particl filter non linear problem technic report depart statist oxford univers england avail http www stat ox ac uk clifford index htm de freita niranjan gee hierarchich bayesiankalman model regularis ard sequenti learn technic report cu infeng tr cambridg univers http svrwww eng cam ac uk fgf de freita niranjan gee regularis sequenti learn algorithm jordan kearn solla ed advanc neural inform processintl system vol mit press de freita niranjan gee doucet sequenti mont carlo method optimis neural network model technic report cu infeng tr cambridg univers http svrwww eng cam ac uk fgf doucet sequenti simul base method bayesian filter technic report cu infeng tr cambridg univers avail http www stat bri ac uk mcmc page list html gordon salmond smith novel approach nonlinear non gaussian bayesian state estim iee proceedinti pitt shephard filter via simul auxiliari particl filter technic report depart statist imperi colleg london england avail http www nuff ox ac uk econom paper singhal wu train multilay perceptton extend kalman algorithm touretzki ed advanc neural inform processintl system vol san mateo ca pp