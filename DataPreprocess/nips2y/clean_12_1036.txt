abstract problem develop good polici partial observ markov decis problem pomdp remain one challeng area research stochast plan one line research area involv use reinforc learn belief state probabl distribut underli model state promis method small problem applic limit intract comput repres full belief state larg problem recent work show mani set maintain approxim belief state fairli close true belief state particular great success shown approxim belief state margin correl state variabl paper investig two method full belief state reinforc learn one novel method reinforc learn use factor approxim belief state compar perform algorithm sever well known problem literatur result demonstr import approxim belief state represent larg problem introduct markov decis process mdp framework good way mathemat formal larg class sequenti decis problem involv agent interact environ gener mdp defin way agent complet knowledg underli state environ formul pose challeng research problem still optimist model assumpt rare realiz real world time agent must face uncertainti incomplet inform avail extens formal gener mdp deal uncertainti given partial observ markov decis process pomdp focu paper solv pomdp mean find optim behavior polici map agent avail knowledg environ belief state action usual done function assign valu belief state fulli observ mdp work present paper done first author stanford univers reinforc learn use approxim belief state case valu function comput effici reason size domain situat somewhat differ pomdp find optim polici pspacehard number underli state date best known exact algorithm solv pomdp tax problem dozen state sever gener approach approxim pomdp valu function use reinforc learn method space permit full review approach upon focu use belief state probabl distribut underli model state contrast method manipul augment state descript finit memori method work directli observ main advantag probabl distribut summar inform necessari make optim decis main disadvantag model requir comput belief state task repres updat belief state larg problem difficult paper address problem obtain model focu effect way use model even known model reinforc learn techniqu quit competit exact method solv pomdp henc focu extend model base reinforc learn approach larger problem use approxim belief state risk approach inaccuraci introduc belief state approxim could give agent hopelessli inaccur percept relationship environ recent work howev present approxim track approach provid theoret guarante result process cannot stray far exact belief state approach rather maintain exact belief state infeas realist larg problem maintain approxim belief state usual restrict class distribut approxim belief state updat due action observ continu project back restrict class specif use decompos belief state certain correl state variabl ignor paper present empir result compar three approach belief state reinforc learn direct approach use neural network one input element full belief state second spova method use function approxim design pomdp third use neural network approxim belief state input present result sever well known problem pomdp literatur demonstr belief state approxim ill suit problem effect mean attack larg problem basic framework algorithm pomdp defin tupl three set three function set state set action set observ transit function ii specifi action affect state world view si sj si probabl agent reach state current state si take action reward function determin immedi reward receiv agent observ model ii determin agent perceiv depend environ state action taken ola probabl agent observ state taken action rodriguez parr andd koller pomdp belief state belief state defin probabl distribut state repres probabl environ state take action observ belief state updat use bay rule es zs sj size exact belief state equal number state model larg problem maintain manipul exact belief state problemat even transit model compact represent exampl suppos state space describ via set random variabl xi take valu finit domain val xi particular defin valu val xi variabl xi full belief state represent exponenti use approxim method analyz boyen koller variabl partit set disjoint cluster ce belief function maintain variabl cluster time step comput exact belief state comput individu belief function margin inter cluster correl assign ci variabl ci obtain bi ci ey cl approxim origin full belief state reconstruct bi ci repres belief state product margin probabl project belief state reduc space full belief state represent state variabl would exponenti size decompos belief state represent exponenti size largest cluster addit number cluster process mix rapidli enough error introduc approxim stay bound time discuss boyen koller type decompos belief state particularli suitabl process factor repres dynam bayesian network case avoid ever repres exponenti size belief state howev approach fulli gener appli set state defin assign valu set state variabl valu function polici pomdp one think pomdp mdp defin belief state well known fix point equat mdp still hold specif discount factor defin next belief state optim polici determin maxim action belief state principl could use learn valu iter directli solv pomdp main difficulti lie fact uncount mani belief state make tabular represent valu function imposs exact method pomdp use fact finit horizon valu function piecewiselinear convex ensur finit represent finit represent grow exponenti horizon make exact approach impract set function approxim attract altern exact method implement function approxim use set parameter function reward go take action belief state valu function reconstruct function max updat rule transit reinforc learn use approxim belief state state action reward xw vwa function approxim architectur consid two type function approxim first two layer feedforward neural network sigmoid intern unit linear outermost layer use one network function full belief state reinforc learn use network input one compon belief state hidden node approxim belief state reinforc learn use network one input assign variabl cluster two cluster exampl binari variabl network would input kept number hidden node network squar root number input second function approxim spova soft max function design exploit piecewis linear structur pomdp valu function spova function maintain set weight vector wai evalu practic small valu usual adopt start learn make function smooth increas learn spova close approxim pwlc function usual maintain one spova function action assign vector function gave aii paramet spova full belief state neural network empir result present result sever problem pomdp literatur present extens known machin repair problem design highlight effect approxim belief state result present form perform graph valu current polici obtain take snapshot valu function measur discount sum reward obtain result polici simul use nn refer neural network train reinforc learner train full belief state term decompos nn refer neural network train approxim belief decompos product margin use simpl explor strategi start probabl act randomli decreas linearli due space limit abl describ model detail howev use publicli avail model descript file tabl show run time differ method gener much lower would requir solv problem use exact method grid world begin consid two grid world world state world world contain state natur decomposit state variabl compar spova full belief state neural network see http www cs brown edu research ai pomdp index html note file format specifi start distribut problem result report respect start distribut rodriguez parr koller figur grid world state maze experiment result averag train run simul per polici snapshot present figur show spova learn faster neural network network eventu catch state robot navig problem amen decompos belief state approxim sinc underli state space come product robot posit robot orient decompos belief state two cluster one contain posit state variabl contain orient state variabl figur lb show result spova domin decompos nn troubl problem effect posit orient valu function easili decoupl effect orient valu highli state depend meant decompos nn forc learn much complic function input function learn network use full belief state aircraft identif aircraft identif anoth problem studi cassandra thesi includ sens action identifi incom aircraft action attack threaten aircraft attack friendli aircraft penal failur intercept hostil aircraft challeng problem tension decid variou sensor better sensor tend make base visibl hostil aircraft stealthi sensor less accur sensor give inform aircraft type distanc base state space problem compris three main compon aircraft type either aircraft friend foe di tanc far aircraft current base discret adjust number distinct distanc visibl measur visibl base approach aircraft discret level chose gave problem state problem natur decomposit state variabl aircraft type distanc base visibl result three algorithm shown figur first problem start see advantag decompos belief state decompos nn use three separ cluster one variabl meant network input simpler network learn faster learn better polici overal believ illustr import point even though spova full belief state neural network may express decompos nn decompos nn abl search space function repres much effici due reduc number paramet reinforc learn use approxim belief state nn figur aircraft identif machin mainten machin mainten last problem machin mainten problem cassandra databas problem assum machin certain number compon qualiti part produc machin determin condit compon compon one four condit good compon good condit fair compon amount wear would benefit mainten bad part worn could use repair broken part broken must replac statu compon observ machin complet disassembl figur show perform result problem compon version problem state maximum size full belief state approach manag howev belief state problem decompos natur cluster describ statu machin creat decompos belief state four compon graph show domin simpl decomposit approach believ problem clearli demonstr advantag belief state decomposit decompos nn learn function input fraction time take full net spova learn lower qualiti function input run time tabl show run time differ problem present gener much less would requir solv problem exactli full nn spova roughli compar decompos neural network consider faster exploit problem structur approxim belief state comput time spent comput belief state actual larger decompos nn save come reduct number paramet use reduc number partial deriv comput expect save significantli substanti process repres factor way approxim belief state propag algorithm also take advantag addit structur conclud remark propos new approach belief state reinforc learn use approxim belief state use well known exampl pomdp literatur compar approxim belief state reinforc learn two method rodriguez parr andd koller problem spova nn decompos nn hallway min min min aircraft id min min min machin min tabl run time second minut hour differ algorithm use exact belief state result demonstr approxim belief state may ideal tightli coupl problem featur posit orient robot natur effect mean address larg problem even medium size problem show approxim bejief state reinforc learn outperform full belief state reinforc learn use fewer trial much less cpu time mani problem exact belief state method simpli impract approxim belief state provid tractabl altern acknowledg work support aro muri program integr approach intellig system onr contract darpa hpkb program generos powel foundat sloan foundat refer astrom optim control markov decis process incomplet state estim math anal applic bellman dynam program princeton univers press boutili dean hank decis theoret plan structur assumpt comput leverag journal artifici intellig research boyen koller tractabl infer complex stochast process proc uai cassandra exact approxim algorithm partial observ markov decis problem phd thesi comput scienc dept brown univ littman algorithm sequenti decis make phd thesi comput scienc dept brown univ littman cassandra kaelbl learn polici partial observ environ scale proc icml page loch singh use elig trace find best memoryless polici partial observ markov decis process proc icml morgan kaufmann andrew mccallurn overcom incomplet percept util distinct memori proc icml page ronald parr stuart russel approxim optim polici partial observ stochast domain proc ijcai smallwood sondik optim control partial observ markov process finit horizon oper research wier schmidhub hq learn discov markovian subgoal non markovian reinforc learn technic report istituo dall moll di studi sull intelligenza artificial