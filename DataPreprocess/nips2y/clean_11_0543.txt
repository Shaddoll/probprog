abstract luster import mani field il clude anufac ure biolog financ astronolni mixt ure model popular approach due st atist ical foundat ion em popular method find mixt ure model em howev requir mani access data thu di miss impract data mine enorm dat aset present new algorit hm base nmltiresolut ion cd tree dramat reduc cost em base cluster wit save rise linearli nmnber datapoint although present ed maxinmm likelihood est imat ion gaussian mixt ure model isalso applic non aussian model provid class densit i monoton mahalanobi dist anc mix categor nnmeric lust er bayesian met hod autoclass introduct aussian mixtur model assum hat datapoint xl gener indel el clel tli follow process ill turn natur begin ran lolnli pick class discret set lass nat ure draw dilnension gaussial whose mean tt ovariant del end th class thu denot paramet er mixt ure tile class probabl cj lass cent er itj class covari job mixt ure model learner find good est imat model expect ation maxim em also known fuzzi mean popular moor algorit hm th iter em begin estim model end improv estim write px ti ttx ell iter point cla ss combinaljon comput ea ch class datapoint xi extent xi own ownership simpli tt throughout paper use follow notat xi aijp ai ba es hule new valu centtold tt jt class new model simpli weight mean datapoint use valu wl tc weight similar weight procedur give new est imat lass probabl class covari sxx thu iter en visit mean evahl dimension gaussian arithmet oper per iter paper ailn mr ree multiresohlt tree introduc everi data point class pair need reduc cost develop binari tree node associ subset datapoint root node own datapoint non leaf node two children defin split dimens nd splitdim splitt ing valu nd splitval two children divid parent datapoint hem left child owe datapoint strictli less split valu split dirnens right child own remaind parent datapoint xi nd left xi nd splitdim nd splitval xi nd xi nd right xi nd plitdim nd splitval xi nd distinguish featur mrkd tree node contain follow nd numpoint number point own equival averag densi entaom centtold point own equival first toomen densiti nd nd ov covari oint own nd equiva lentli second lnoluent densiti nd nd hyperrect ound hyl er rectangl point elow nd construct mrkd tl ee top identifi botmd box current node split cen er wide dimens node declar leaf left unsl lit widest dimens bound box threshold mb ill aib zero leaf node denot singlet coincid point tree node requir memori care construct co air log practic set mb rang datapoint compon tree size construct thu cost fast em base mixtur model cluster use multiresolut kd tree consider less han bound ill dens region tim leaf node abl sulnmar dozen datal oint note cost tree build alnorl ize tree nmst built vet eni perform mani iter erforln erat em tile mckcl tree call function makestat describ root tree im st vr nd oul put tn valu sw sw swx swx swxx swxx swxx nd nd nd result lai estat oot provid suffici st atist construct sw ttj swxj sw swxx sw iltf lakestat call leaf node simpli conlput nd ntno item right hand equat easili coml ut ed return swj nd numpoint swxj nd numpoint swxxj nd numpoint nd ov reauon thi leaf node small littl variat point own node exampl tc ix experi use inv leaf node ensur accuraci makestat call non leaf node easili coml ut answer recursivelv call makestat two children retm ning sum two set answer gener exactli proceed end stori would lit le coml utat improv convent em one pass would fulli travers tree contain node work per node win ever spot intermedi node evalu node leaf without search descend without introduc signific error coml ut iol coml ute minimuxn maxinmm tt ij point insid node could procedur complex rase local weight regress wish coinpur tc mm ttj xxh le tcj lower otmd minx nd lt ij tcf upper bound maxx tci hard tt deterlnin mean covari jth class also cla ue exampl figm tt apl roxim would much larger ct fitrther left thinner ovari rememb tt ij defin term aij thu jl ttlt put bound clij rel easili simpli requir coml te closest furthest point within comlmt lhese point requir non trivial comput ation geometri covari matriceb necessarili axi align space detail moor maxim lminimizerofa maximi zer minim figur rectangl denot hyl errectangl mrkd tree small squar denot datapoint own node suppos two class given mean covari depict ellips small circl indic locat wkhin node would extrem nd hyperrect use mahalanobi distanc tlhd te short est ancl furthest squar distanc iihd ihd rr exp mhd ax lower boulkl minx nd cti similar deftnit ion ay tm write rain ij xt nd inc qualwlwr ollr lower bound similar definit iti proveel elelnenta rv algebra requir qual titi posit tl ex oft en tighten bound use procedur tirol exploit fact tt ij space perinit flirther discuss prtme tt tt max close criterion cloueness first idea hat spring mind prune vj wj bill simpl criterion suitabl class may accumul larg sum weight whilst other may accumul small sum larg sum weight cla es tolerat far looser bound small sum xveight class satisfactori prune criterion prune vj wtt total weight award class entir dataset sma constant sadli known advanc happili find lower bound total sofar nd numpoint mm total weight award class fa search kd tree algorithm describ far perform divid conquer xvith cutoff set datapoint addit possibl achiev extra accder mean divid onquer class center suppos class instead consid class node frequent possbl determin node tha maxthrum posibl weight class less miniscul fi action minimum posibl weight sme cla hu xv find hat nocl fi tfi class qi remov fi om consider fi om descend current node frequent thi mean near lree leav tini fi action class compet ownership dat apoint thi lead larg time save eri fast em base mixtur model cluster use multiresolut kd tree result subject approach numer mont arlo eml iric test report oll one set test creat tile follow methodolog randolnli genera mixtur gaussian dimension space defaldt number gaussian default au ian ha mean lie within unit hypercnb covari lnatrix ra ndomli gener diagon element default randoln non diagon element ensur symmet tic posit definit thu distanc gaussian center tandard deviat ion contour order magnitud ra ndomli gener dataset fi om mixtur model number point default fignr show typic gener set ganssian datapoint build mckd tree dataset record memori reqnir real time build pentlur mhz second run em data em begin entir differ set gaussian randomli gener use procedur xve run iter convent em algorithm new mrkdtree ha seal algorithm new algorit hn use default valu xve record real ime second iter algorithm also record mean log likelihood score logp model algorithm fignr show node visit dnring iter fast em lass tabl show detail result experiment paramet vari speedup vari froin fold fold fold speedup even wide non local ganssian experi similar result also obtain real dataset disobey gaussia assumpt find one two order magnitud comput advantag indistinguish statist behavior bett er wors compar convent em real data preliminari experi appli larg dataset encourag three dimensiolml galaxi cluster galaxi cluster tradit em need minut per iter mrkd tree requir second million galaxi radit em need minut mrkd tree reqnir second conclus tile use varia ble resolut structur cluster suggest mani place birch system particular popnlar databas commun birch howev nnabl identifi second moment featur clust er non axi align spread contribut use multi resolut approach associ comput benefit introdnct et cient algorithn leav statist aspect mixtnr model estim unchang growth recent data mine algorihm base st atist foundat freqent justifi follow statemerit use state art statist techniqu expens techniqn design handl larg dataset becom int ractabt million datapoint earlier work provid evid statement may moor effect number datapoint increas comput advantag essenti linearli tree build time second worst tini cost compar even one iter regular em second big dataset finalslowsec finalfastsec effect number dim nsion oo mani kd tree algorithm benefit declin dimension increas yet even dimens fold advantag finalslowsec finalfastsec effect number class convent em slow linearli num class fast em clearli sublinear oo fold speedup even class note oo tree size grow class mean oo uniform data distribut fewer data num er center point share tree leav finalslowsec finalfastsec effect tau larger will prune tree search thu faster search less accur mirror em statist behavior inde xvhen larg discrep tile log likelihood rel larg finalslowsec finalfastsec oo effect standard deviat even wide gaussian wide support still get larg save node prune case rare node one class own probabl tit instead node class uon zero littl vari probabl finalslowsec finalfastsec tabl result paramet held default valu except one vari shown graph graph show factor new em faster convent em graph time build mrkd tree second number node tree note although tree build cost includ speedup calcul neglig case especi consid one tree build need em iter approxim natur process result inferior cluster answer qualiti cluster indistinguish slow fast method measur log likelihood view visual fast em base mixtur model cluster use multiresolut kd tree figur typic set gaussian gener random procedur turn gener dataset upon compar perform old new implementatioi em figur ellips show model start em iter rectangl depict mrkdtree node prune observ larger rectangl larger save area less variat class probabl note mere abl prune data densiti low appli local weight regress bayesian network learn hope paper provid evid lso appli cluster refer cheeseman oldford electmg modeh data art fic al lntelhger ce arid tatzst cs iv ectur note statzst cs vol springer verlag multiresolut instanc base learn proceed ijcai deng moor morgan aufmann uda al hart patterrz ylass ficat sce analysz john gviley son ester kriegm xu databas ilkterrac cluster larg spatial databas proceed ng rst intern onf enc ix nowledg scoveci data aaai press moor schneider deng efficmnt local weight potynomml regress prechct on froher echtor proceedzn intern ach ae learrzzn onf enc morgan aufmann andrew moor lee cach suffi nent statist effiment maclam learn th larg dataset journal oj art ficmllatelhg ce research march omohundro effici algorithm th neural network bmmv journal complex sgstem omohundro burnpwe effici fireetlon constrmnt classif learn lippmann moodi touretzki editor advanc neural formatzon processzng system morgan kaufmann zhang ranmkrmhnan vni birch effici data cluster method ibr larg databas proceed fifteenth ausi igac sigmod igart symposium prgnc ple databas sgstem pod assn comput machineri