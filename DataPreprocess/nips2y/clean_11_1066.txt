abstract robot control applic commonplac preexist set control solv subtask perhap hand craft previous learn plan still face difficult problem choos switch among control solv overal task well possibl paper present framework base markov decis process semi markov decis process phrase problem basic theorem regard improv perform obtain switch flexibl given control exampl applic theorem particular show agent plan high level control use result plan find even better plan modifi exist control neglig addit cost plan one exampl complex problem reduc billion state action pair less million state control pair introduct mani applic solut part task known either handcraft peopl previous learn plan exampl robot applic may exist control move joint posit pick object control eye movement navig along hallway gener intellig system may avail sever tempor extend cours action choos case key challeng take full advantag exist tempor extend action choos switch among effect plan level rather level individu action recent sever research begun address challeng within framework reinforc learn markov decis process singh kaelbl dayan hinton thrun schwartz sutton dietterich parr russel mcgovern sutton fagg common much recent work model tempor extend action polici control condit termin togeth refer option sutton precup singh paper consid problem effect combin given option one overal polici gener prior work kaelbl section introduc framework new result section improv switch among tempor abstract action reinforc learn mdp framework markov decis process mdp agent interact environ discret lowest level time scale time step agent perceiv state environ st basi choos aprimit action respons action environ produc one step later numer reward rt next state st one step model environ consist one step statetransit probabl one step expect reward tq st pss pr st st agent object learn optim markov polici map state probabl take avail primit action maxim expect discount futur reward state rt ffrt st ep aea probabl polici choos action state discount rate paramet call valu state polici call state valu function optim state valu function give valu state optim polici max max given optim polici easili form choos state action achiev maximum equat parallel set valu function denot bellman equat defin state action pair rather state plan reinforc learn refer use model environ comput valu function therebi optim improv polici option use term option gener primit action includ tempor extend cours action let ht st rt st rt st histori sequenc time time let denot set possibl histori given mdp option consist three compon initi set polici termin condit option taken state taken state st next action select accord environ make transit st termin probabl ht els continu determin accord ht transit state st termin probabl etc call gener option defin semi markov depend histori sequenc markov option depend current state semi markov option allow timeout termin period time elaps extens cannot handl markov option initi set termin condit option togeth limit state option polici must defin exampl craft polici mobil robot dock batteri charger might defin state batteri charger within sight termin condit would defin outsid robot successfu lli dock defin polici option let set option avail state denot os set option denot js os initi state st markov polici option select option ost accord probabl distribut la option taken st determin action termin st point new option select accord way polici option determin non stationari polici action fiat polici defin valu state gener flat polici expect return sutton singh precup ravindran polici start vrr de rt rt denot event initi time valu state gener polici polici option defin valu state correspond flat polici de vf analog definit use option valu function semi markov option use defin expect discount futur reward follow option histori smdp plan option close relat action special kind decis problem known semi markov decis process smdp puterman see also singh bradtk duff mahadevan et al parr russel fact mdp fix set option smdp accordingli theori smdp provid import basi theori option section review standard smdp framework plan provid basi extens plan option requir model consequ form model given prior work smdp reward part model state total reward receiv along way rt rt rt denot event initi state time state predict part model oo pt ep probabl option termin step call kind model multi time model describ outcom option singl time potenti mani differ time appropri combin use multi time model write bellman equat gener polici option gener markov polici valu function satisfi equat ep ep ogo let us denot restrict set option set polici select option optim valu function given select vc maxo os es vc correspond optim polici denot polici achiev vc vc state vc model option known form choos proport among maxim option equat vc straightforward extend mdp plan method smdp exampl synchron valu iter option initi approxim valu function vo arbitrarili updat note algorithm reduc convent valu iter special case standard result smdp theori guarante process converg improv switch among tempor abstract action gener semi markov option limk vk vc polici found use tempor abstract option approxim sens achiev vc typic less maximum possibl interrupt option readi present main new insight result paper smdp method appli option treat opaqu indivis unit option select method requir polici follow option termin interest potenti power method possibl look insid option alter intern structur sutton precup singh particular suppos determin option valu function polici state option pair could encount follow function tell us well follow commit irrevoc option also use evalu commit step suppos time midst execut option markov compar valu continu st valu interrupt select new option accord vt qt latter highli valu interrupt allow switch new way behav inde better shown character new way behav follow polici tt origin one new option tri tt new option correspond old option except termin whenev switch seem better continu accord qt call att interrupt polici state gener theorem extend case describ option may semi markov instead markov interrupt option state could done latter extens lift requir qt complet known sinc interrupt restrict state inform avail theorem interrupt mdp set option markov polici defin new set option one one map two option set follow everi defin correspond tr except histori qt final state may choos set histori whose termin condit chang way call interrupt histori let polici correspond option correspond vt state non zero probabl encount interrupt histori upon initi proof idea show arbitrari start state execut option given termin improv polici follow polici thereaft wors alway follow polici word show follow inequ hold ztt ep vt vt ett ep vt true use expand left hand side repeatedli replac everi occurr vt left correspond tt rg limit left hand side becom prove sinc tri tt vs need show ep vt epss vt sutton singh precup ravindran let denot set interrupt histori eft left hand side written next state cumul reward number elaps step follow option hs histori st trajectori end encount histori hs never encount histori therefor also occur probabl expect reward upon execut option state therefor write right hand side kv prove ass qo hss note strict inequ hold hs vu least one histori end trajectori gener non zero probabl one applic result consid case ft optim polici given set markov option interrupt theorem give us way improv ft cost check time step better option exist neglig compar combinatori process comput vc kaelbl dietterich demonstr similar perform improv interrupt tempor extend action differ set illustr figur show simpl exampl gain obtain interrupt option task navig start locat goal locat within continu twodimension state space action movement length direct current state rather work low level action infinit number introduc seven landmark locat space landmark defin control take us landmark direct path control applic within limit rang state case within certain distanc correspond landmark control defin option circular region around controllet landmark option initi set control polici arriv target landmark termin condit denot set seven landmark option action within goal locat transit termin state reward transit make minimum time task one landmark coincid goal possibl reach goal pick optim polici within ii run landmark landmark shown thin line figur optim solut mdp defin inde best one pick option cours one better option follow way landmark trajectori shown thick line figur cut corner shorter interrupt polici respect smdp optim polici interrupt polici take step start goal good optim polici step much better smdp optim polici take step state valu function two polici also shown figur figur present complex mission plan task mission flight base observ mani given set site possibl return base without run fuel local weather site flip cloudi clear accord independ note proof would also appli switch option select improv continu result would gener closer convent polici improv prefer result given emphas primari applic improv switch among tempor abstract action trajectori space landmark interrupt solut step oo step smdp valu function loo oo oo oo llle valu interrupt figur use interrupt improv navig landmark direct control task left navig minimum time use option base control run one seven landmark black dot circl show region around landmark within control oper thin line show optim behavior use control run termin thick line show correspond interrupt behavior cut comer right panel show state valu function smdp optim interrupt polici poisson process sky given site cloudi plane get observ made reward sky clear plane get reward accord import site posit reward mean time two weather chang site given figur plane limit amount fuel consum one unit fuel time tick fuel run reach base plane crash receiv reward primit action tini movement direct inertia state system describ sever variabl current posit plane fuel level site observ far current weather remain site state action space approxim billion element assum discret level continu variabl intract normal dynam program method introduc option take plane site includ base posit state space result smdp element feasibl exactli determin vc site solut model es option determin qo pss option state whole space perform asynchron valu iter use option order comput optim option valu function use interrupt approach base valu comput polici obtain approach compar result static planner exhaust search best tour assum weather chang plan whenev weather chang graph figur show reward obtain method averag independ simul mission polici obtain interrupt perform significantli better smdp polici turn significantli better static planner close paper develop natur even obviou observ one better continu evalu one commit cours action one commit irrevoc contribut formul observ precis enough prove demonstr empir final exampl suggest techniqu use applic far larg solv level primit action note achiev use exact method without function approxim repres valu function function approxim reinforc learn techniqu possibl address problem substanti larger still preliminari experi also use interrupt crude learn estim perform interrupt solut close result report sutton singh precup ravindran reward mean time een weather chang option decis base expect reward per mission interrupt smdp static planner high fuel low fuel figur mission plan task perform polici construct smdp method interrupt smdp polici optim static planner take account possibl chang weather condit acknowledg author grate acknowledg substanti help receiv mani colleagu includ especi ami mcgovern andrew barto ron parr tom dietterich andrew fagg leo zelevinski manfr huber also thank paul cohen robbi moll manc harmon sascha engelbrecht ted perkin help reaction construct critic work support nsf grant ec grant afosr andrew barto richard sutton satind singh support nsf grant ii refer bradtk duff reinforc learn method continu time markov decis problem nip mit press dayan hinton feudal reinforc learn nip mit press dietterich maxq method hierarch reinforc learn proceed fifteenth intern confer machin learn morgan kaufmann kaelbl hierarch learn stochast domain preliminari result proceed tenth intern confer machin learn morgan kaufmann mahadevan marchallek da gosavi self improv factori simul use continu time averag reward reinforc learn proceed fourteenth intern confer machin learn morgan kaufmann mcgovern sutton fagg role macro action acceler reinforc learn grace hopper celebr women comput parr russel reinforc learn hierarchi machin nip mit press puterman markov decis process discret stochast dynam program wiley singh reinforc learn hierarchi abstract model proceed tenth nation confer artifici intellig mit aaai press sutton td model model world mixtur time scale proceed twelfth intern confer machin learn morgan kaufmann sutton precup singh intra option learn tempor abstract action proceed fifteenth intern confer machin learn morgan kaufman sutton precup singh mdp semi mdp learn plan repres knowledg multipl tempor scale tr depart comp sci univers massachusett amherst thmn schwartz find structur reinforc learn nip mit press