abstract describ new iter method paramet estim gaussian mixtur new method base framework develop kivinen warmuth supervis line learn contrast gradient descent em estim mixtur covari matric propos method estim invers covari matric furthermor new paramet estim procedur appli line batch set show experiment typic faster em usual requir half mani iter em introduct mixtur model particular mixtur gaussian popular tool densiti estim cluster un supervis learn wide rang applic see instanc refer therein mixtur model one use tool handl incomplet data particular hidden variabl gaussian mixtur hidden variabl indic data point index gaussian gener thu model specifi joint densiti observ hidden variabl common techniqu use estim paramet stochast sourc hidden variabl em algorithm paper describ new techniqu estim paramet gaussian mixtur new paramet estim method base framework develop kivinen warmuth supervis line learn framework success use larg number supervis un supervis problem see instanc goal find local minimum loss function case neg log likelihood induc mixtur gaussian howev rather minim paramet estim gaussian mixtur loss directli add term measur distanc new paramet old one distanc use iter paramet estim procedur purpos keep new paramet close old one method deriv iter paramet estim use batch set well line set paramet updat observ distanc use deriv paramet estim method paper rel entropi old new joint densiti observ hidden variabl breviti term new iter paramet estim method joint entropi je updat je updat share common characterist expect maxim algorithm first calcul expect howev replac maxim step differ updat paramet instanc updat invers covari matrix gaussian mixtur rather covari matric found experi je updat often requir half mani iter em also straightforward modifi propos paramet estim method line set paramet updat new observ demonstr experi digit recognit line version je updat especi use situat observ gener nonstationari stochast sourc notat preliminari let sequenc train exampl zn zi ddimension vector ir model distribut exampl use ddimension gaussian paramet th gaussian denot includ mean vector covari matrix xl oi xthe densiti function ith gaussian denot xl denot entir set paramet gaussian mixtur oi rr wi non neg vector mixtur coeffici wi denot xlo wip xl likelihood observ accord gaussian mixtur paramet let two gaussian distribut breviti denot ei ei expect random variabl respect let parametr function whose paramet constitut matrix aij denot oa matrix partial deriv respect element ij element oa oaij similarli let bij matrix whose element function scalar denot db dz matrix deriv element respect name ij element db dz dbi dz framework deriv updat kivinen warmuth introduc gener framework deriv line paramet updat section describ appli framework problem singer warrnuth paramet estim gaussian mixtur batch set later discuss simpl modif give line updat given set data point number goal find set gaussian minim loss data denot loss densiti estim natur loss function neg log likelihood data loss de sin best paramet minim loss cannot found analyt common approach use iter method em find local minim loss iter paramet estim framework given old set paramet need find set new paramet induc smaller loss framework introduc kivinen warmuth deviat common approach also requir new paramet vector stay close old set paramet incorpor learn previou iter distanc new paramet set old set measur non neg distanc function ot search new set paramet minim distanc sum loss multipli non neg number measur rel import distanc versu loss paramet becom leami ng rate updat formal updat found set arg min ut loss eii use lagrang multipli enforc constraint mixtur coeffici sum one choos apropri distanc function one show em becom updat distanc function learn rate minim function ut cannot found analyt distanc function log likelihood usual non linear instead expand log likelihood use first order taylor expans around old paramet set approxim degrad new paramet valu old one motiv use distanc function see also discuss seek new set paramet arg min rrt loss si oss slo voloss denot gradient loss use method eq deriv updat paper densiti estim natur use rel entropi new old densiti distanc paper use joint densiti observ data point hidden variabl indic gaussian motiv name joint entropi updat entropi base distanc function first consid rel entropi new old paramet paramet singl gaussian use notat introduc sec rel entropi two gaussian distribut denot paramet estim gaussian mixtur use standard though tediou algebra rewrit expect follow oi ic ltr ti rc rel entropi new old mixtur model follow xlo xlz lo ax xlz xl dx ideal would like use distanc function give us updat term howev close form express eq although rel entropi two gaussian convex function paramet rel entropi two gaussian mixtur non convex thu loss function may multipl minima make problem find arg min difficult order sidestep problem use log sum inequ obtain upper bound distanc function denot upper bound ln xlo dx ln xlo call new distanc function thejoint entropi distanc note distanc paramet wi coupl sens convex combin distanc particular function paramet remain constant paramet individu gaussian permut furthermor also suffici convex find minim possibl see updat readi deriv new paramet estim scheme done set partial deriv respect problem consist solv follow equat oa oinp sio oa oinp sio oa oinp sio ow ow use fact thu symmetr deriv defin eq eq respect ci oa ic ic tr singer warmuth simplifi notat throughout rest paper defin follow variabl der xloi def xlo partial deriv log likelihood comput similarli oinp slo owi olnp omp slo oc need decid order updat paramet class wi ci use order em use name wi final ci one pass three group start use order use order result simplifi set equat sever term eq cancel denot size sampl isi need sum deriv eq eq use fact lagrang multipli simpli assur new weight sum one set result zero get wi exp fli ws exp exe similarli sum eq eq set result zero get final ci sum eq eq use newli obtain cfx tq rc call new iter paramet estim procedur joint entropi je updat summar je updat compos follow altern step first calcul observ valu xl updat paramet given eq eq eq je updat em differ sever aspect first em use simpl updat mixtur ght second em use expect respect current paramet suffici statist ci find new set mean vector covari matric je use slightli differ weight averag observ addit add old paramet learn rate determin proport use sum old paramet newli estim paramet last em estim covari matric ci wherea new updat estim invers matric thu potenti stabl numer case covari matric small condit number obtain line procedur need updat paramet new observ time rather sum new observ xt updat paramet estim gaussian mixtur figur left comparison converg rate em je updat differ learn rate right exampl case em initi increas likelihood faster je updat paramet get new set paramet use current paramet new paramet use induc likelihood next observ xt line paramet estim procedur compos follow step set xt io paramet updat wiexp xt ejrn wjexp xt xt cf xt xt xt tc guarante converg line updat one use diminish learn rate motiv see experi conduct numer experi new updat due lack space describ two first experi compar je updat em batch set gener data gaussian mixtur distribut vari number compon dimens due lack space describ result obtain one set set tlxe exampl gener mixtur compon mean vector standard unit vector euclidean space set covari matric ident matrix gener exampl run em je updat differ learn rate make sure run end local maximum fist perform three em iter result shown left hand side figur set je updat high learn rate achiev much faster converg em would like note behavior mean esoter experi data yield similar result found differ behavior low dimension set right hand side figur show converg rate result mixtur contain two compon singl dimens gaussian mean two compon locat singer warmuth varianc thu signific overlap two gaussian constitut mixtur mixtur weight vector gener exampl accord distribut initi paramet follow see initi em increas likelihood much faster je updat eventu je updat converg faster em use small learn rate exampl appear figur set howev set je updat diverg learn rate larger use behavior underscor advantag method em use fix learn rate guarante converg local maximum likelihood condit typic hold mixtur gaussian je updat hand encompass learn rate mani set converg much faster em howev superior perform high dimension case demand price low dimension dens case name conserv learn rate hard tune need use case em better altern offer almost converg rate without need tune paramet acknowledg thank duncan her care proof read provid us interest data set refer bauer koller singer updat rule paramet estim bayesian network proc th annual conf uncertainti ai page bishop neural network pattern recognit oxford univ press thoma cover joy thoma element oflnform theori wiley dempster laird rubin maximum likelihood incomplet data via em algorithm journal royal statist societi duda hart pattern classif scene analysi wiley helmbold kivinen warmuth worst case loss bound sigmold neuron advanc neural inform process system page helmbold schapir singer warmuth comparison new old algorithm mixtur estim problem machin learn vol kivinen warmuth addit versu exponenti gradient updat linear predict inform comput januari kivinen warmuth rel loss bound multidimension regress problem advanc neural inform process system rednet walker mixtur densiti maximum likelihood em algorithm slam review titterington smith makov statisticalanalysi finit mixtur distribut wiley wu converg properti em algorithm annal ofstat