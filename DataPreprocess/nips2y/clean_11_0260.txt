abstract studi probabilist infer larg layer bayesian network repres direct acycl graph show intract exact infer network preclud effect use give algorithm approxim probabilist infer exploit averag phenomena occur node larg number parent show algorithm comput rigor lower upper bound margin probabl interest prove bound becom exact limit larg network provid rate converg introduct promis neural comput lie exploit inform process abil simpl comput element organ larg netq ork arguabl one import type inform process capac probabilist reason properti undirect probabilist model repres symmetr network studi extens use method statist mechan hertz et al detail analys model possibl exploit averag phenomena occur thermodynam limit larg network paper analyz limit larg multilay network probabilist model repres direct acycl graph model known bayesian network pearl neal differ probabilist semant symmetr neural network hopfield model boltzmann machin show intract exact infer multilay bayesian network infer multilay network via larg deviat bound preclud effect use work build earlier studi variat method jordan et al give algorithm approxim probabilist infer exploit averag phenomena occur node parent show algorithm comput rigor lower upper bound margin probabl interest prove bound becom exact limit oc provid rate converg definit preliminari bayesian network direct graphic probabilist model node repres random variabl link repres causal depend joint distribut model obtain compos local condit probabl distribut tabl pr child parent specifi node network network binari random variabl call transfer function provid conveni way parameter condit probabl tabl cpt transfer function map cx cx everywher differenti satisfi thu nondecreas ft say slope common exampl transfer function bound slope includ sigmoid fix cumul gaussian fix dt noisi valu transfer function bound interpret condit probabl binari random variabl take particular valu one use transfer function endow multilay network soft threshold comput element probabilist semant motiv follow definit definit transfer function layer probabilist network node repres binari variabl xit thu number layer layer contain node everi pair nqde xj xi adjac layer real val ted weight xi oij xj everi node xi first layer bia pi sometim refer node layer input node layer output layer probabilist network defin joint probabl distribut variabl follow input node independ set probabl pi probabl pi induct given binari valu xj xj node layer node xi set lx probabl lyij xj among use multilay network form studi hierarch generatir model sensori data hinton et al applic fundament comput problem known infer estim margin probabl evid number output node say first comput condit probabl diagnost queri reduc margin via bay rule precis one wish estim prix xl xk xi quantiti whose exact comput involv exponenti sum possibl set uninstanti node layer known comput intract cooper kearn saul larg deviat union bound one main weapon theori larg deviat first illustr theori consid input node xj independ set accord bias pj weight sum feed ith node second layer typic larg deviat bound kearn saul state er pj largest weight network make scale assumpt weight bound constant thu see probabl larg order deviat weight sum mean decay exponenti method also provid result weaker assumpt weight bound appli observ problem infer suppos interest margin probabl pr larg deviat bound tell us probabl least defin weight sum node within mean valu tti jpj thu probabl least assur pr least tti lui cours flip side larg deviat bound probabl weight sum may fall away tti case make guarante pr asid trivial lower upper bound combin eventu howev obtain overal bound lui pr lui equat base simpl two point approxim distribut weight sam input jxj approxim place one point weight either mean depend whether deriv upper lower bound point weight either valu depend choic particular becom smaller give weight point trade govern larg deviat bound regard weight given point throw away probabl sinc weight resort trivial bound margin probabl pr note simpl bound equat alreadi exhibit interest trade govern choic paramet name becom smaller throw away probabl becom larger term lui converg valu sinc overal bound involv product lui optim valu one balanc competit probabl explan evid improb deviat mean tradeoff reminisc encount energi entropi mean field approxim symmetr network hertz et al far consid margin probabl involv singl node second layer also comput bound margin probabl involv node layer without loss gener take node done consid probabl one weight sum enter node second layer deviat mean upper bound probabl appeal call union bound simpli state probabl union event bound sum individu probabl union bound allow us bound margin probabl involv multipl variabl exampl infer multilay network via larg deviat bound consid margin probabl prix combin larg deviat union bound find li pr ks number observ order first equat directli lead effici algorithm comput upper lower bound second although simplic consid deviat size node second layer method appli differ choic therefor node inde variat ei lead significantli tighter bound thu exploit freedom choos differ ei rest paper result exampl bound form si fi er reader invit studi small import differ lower bound one equat third argument lead bound margin probabl pr gener straightforward manner pattern evid besid instanc consid lower bound er xl xk xi arbitrari binari valu thu togeth larg deviat union bound provid mean comput upper lower bound margin probabl node second layer detail consequ bound special case two layer network given companion paper kearn saul interest howev challeng gener multilay network multilay network infer via induct extend idea previou section multilay network face problem node second layer unlik first independ still adopt induct strategi deriv bound margin probabl crucial observ condit valu incom weight sum node second layer variabl becom independ gener condit weight sum fall near mean event whose probabl quantifi last section node becom almost independ exactli near independ formal exploit induct comput bound multilay network first tool requir appropri gener larg deviat bound reli precis knowledg mean random variabl sum theorem let xj denot independ binari random variabl let irjl suppos mean bound xj pj aj aj pj aj lrjlaj rr lv xj pj kearn saul proof result omit due space consider induct consid node th layer network suppos told everi weight sum oij enter node lie mean interv tt choic node constrain lie interv ai pi simpli run leftmost rightmost allow valu incom weight sum transfer function defin interv around mean unit center around thu translat uncertainti incom weight sum layer condit uncertainti mean node layer complet cycl translat condit uncertainti incom weight sum layer particular condit origin interv tt probabl lie insid new interv order make guarante probabl set ijp condit suitic ensur assum new interv contain condit expect valu weight sum zjv new interv larg enough encompass incom uncertainti condit minim requir establish defin valid probabilist guarante shall say tt el nt set interv meet condit given valid set interv th layer follow theorem union bound weight sum enter node layer obey kl pr oijxj follow shall frequent make use fact weight sum zjn rt oijx bound interv tt motiv follow definit definit given valid set interv binari valu node th layer say st layer network satisfi oij xj st layer violat interv suppos given valid set interv sampl joint distribut defin probabilist network right hand side equat provid upper bound condit probabl st layer violat interv given th layer upper bound may vacuou larger let us denot whichev smaller right hand side equat word min sinc th layer probabl violat interv infer multilay network via larg deviat bound guarante probabl least layer satisfi interv convers guarante probabl layer violat interv le treat throw away probabl comput upper lower bound margin probabl involv node lth layer exactli case node second layer yield follow theorem theorem subset xp output probabilist fnetwork set xl xk valid set interv margin probabl partial evid output layer obey lui ei pr xil xl xp xk tt ep theorem gener earlier result margin probabl node second layer exampl compar equat equat upper lower bound effici comput common transfer function rate converg demonstr power theorem consid gap addit differ upper lower bound pr xl xk behav crude inform choic goal deriv rate upper lower bound converg valu examin larger larger network suppos choos interv induct defin set tt equat choic give upper bound probabl th layer violat interv moreov denot gap upper lower bound theorem shown ep let us briefli recal definit paramet right hand side equat maxim slope transfer function number node layer number node evid time largest weight network number layer paramet dispos first term bound essenti depend multipli damp factor might typic expect decay exponenti number output examin see simpli notic factor laj ej laj ej bound furthermor kearn saul sinc mean bound larg compar small factor fact bound valu thu first term equat bound constant time kv ln sinc natur expect margin probabl interest decreas exponenti desir natur behavior cours case larg behavior result overal bound domin second term equat situat howev consid larger valu possibl even order inde suffici larg first term scale like must necessarili overtak second one thu clear trade two term well optim valu set roughli magnitud gener speak fix larg observ differ upper lower bound er xl vanish ln algorithm fix multilay network conclud note specif choic made paramet ei section deriv rate converg may far optim choic fix network interest howev theorem directli suggest natur algorithm approxim probabilist infer particular regard upper lower bound er xl function optim bound standard numer method eor upper bound may perform gradient descent find local minimum lower bound may perform gradient ascent find local maximum compon gradient case easili comput commonli studi transfer function moreov constraint maintain valid interv enforc maintain floor interv one layer term previou one practic applic algorithm interest bayesian network studi futur work refer cooper comput complex probabilist infer use bayesian belief network artifici intellig hertz krogh palmer introduct theori neural comput addison wesley redwood citi ca hinton dayan frey neal wake sleep algorithm unsupervis neural network scienc jordan ghahramani jaakkola saul introduct variat method graphic model jordan ed learn graphic model kluwer academ kearn saul larg deviat method approxim probabilist infer proceed dth annual confer uncertainti artifici intellig neal connectionist learn belief network artifici intellig pearl probabilist reason intellig system network plausibl infer morgan kaufmann san mateo ca