abstract expect maxim em algorithm iter procedur maximum likelihood paramet estim data set miss hidden variabl appli system identif linear stochast state space model state variabl hidden observ state paramet model estim simultan present gener em algorithm paramet estim nonlinear dynam system expect step make use extend kalman smooth estim state maxim step estim paramet use uncertain state estim gener nonlinear maxim step di cult requir integr uncertainti state howev gaussian radial basi function rbf approxim use model nonlinear integr becom tractabl maxim step solv via system linear equat introduct stochast nonlinear dynam system examin infer learn discret time dynam system hidden state xt input ut output yt state evolv accord stationari nonlinear dynam driven input addit nois xt xt ut lowercas charact except indic denot vector matric repres uppercas charact ghahramani rowel zero mean gaussian nois covari output nonlinearli relat state input yt xt zero mean gaussian nois covari vector valu nonlinearlti assum differenti otherwis arbitrari model kind examin decad variou commun notabl nonlinear state space model form one cornerston modern system control engin paper examin model within framework probabilist graphic model deriv novel learn algorithm base em one except best knowledg first paper address learn stochast nonlinear dynam system kind describ within framework em algorithm classic approach system identif treat paramet hidden variabl appli extend kalman filter algorithm describ section nonlinear system state vector augment paramet approach inher line may import certain applic furthermor provid estim covari paramet time step contrast em algorithm present batch algorithm attempt estim covari paramet three import advantag em algorithm classic approach first em algorithm provid straightforward principl method hand miss input output second em gener readili complex model combin discret real valu hidden variabl exampl one formul em mixtur nonlinear dynam system third wherea often difficult prove analyz stabil within classic line approach em algorithm alway attempt maxim likelihood act lyapunov function stabl learn next section describ basic compon learn algorithm expect step algorithm infer condit distribut hidden state use extend kalman smooth section maxim step first discuss gener case section describ particular case nonlinear repres use gaussian radial basi function rbf network section extend kalman smooth given system describ equat need infer hidden state histori observ input output quantiti heart infer problem condit densiti xt ul ut yi yt captur fact system stochast therefor infer uncertain gaussian nois assumpt less restrict nonlinear system linear system sinc nonlinear use gener non gaussian state nois author becom awar briegel tresp volum appli em essenti model briegel tresp method use multilay perceptron mlp approxim nonlinear requir sampl hidden state fit mlp use gaussian radial basi function rbf model nonlinear fit analyt without sampl see section import confus use extend kalman algorithm simultan estim paramet hidden state use ek estim hidden state part step em learn nonlinear dynam use em linear dynam system gaussian state evolut observ nois condit densiti gaussian recurs algorithm comput mean covari known kalman smoothin kalman smooth directli analog forward backward algorithm comput condit hidden state distribut hidden markov model also special case belief propag algorithm nonlinear system condit densiti gener non gaussian fact quit complex multipl approach exist infer hidden state distribut nonlinear system includ sampl method variat approxim focu instead paper classic approach engin extend kalman smooth ek extend kalman smooth simpli appli kalman smooth local linear nonlinear system everi point space deriv vector valu function defin matric ag respect dynam linear st mean kalman filter state estim time xt ut xt output equat similarli linear prior distribut hidden state gaussian linear system condit distribut hidden state time given histori input output also gaussian thu kalman smooth use linear system infer condit distribut see figur left panel learn step em algorithm estim paramet given observ input output condit distribut hidden state model describ paramet defin nonlinear nois covari two complic aris step first may comput feasibl fulli estim exampl repres neural network regressor singl full step would lengthi train procedur use backpropag conjug gradient optim method altern one could use partial step exampl consist one gradient step second complic train use uncertain state estim output ek algorithm consid fit take input xt ut output xt condit densiti estim ek full covari gaussian xt xt space fit set data point instead mixtur full covari gaussian input output space gaussian cloud data integr type nois non trivial almost form one simpl ineffici approach bypass problem draw larg sampl gaussian cloud uncertain data fit sampl usual way similar situat occur next section show choos gaussian radial basi function model complic vanish forward part kalman smoother kalman filter ghahramani rowei fit radial basi function gaussian cloud present gener formul rbf network clear fit special form consid follow nonlinear map input vector output vector zhi pi ax bu zero mean gaussian nois variabl covari exampl one form repres use substitut xt ut xt anoth xt ut xt paramet coeffici rbf hi matric multipli input respect output bia vector rbf assum gaussian space center ci width given covari matrix si ci pi exp goal fit model data complic data set come form mixtur gaussian distribut show analyt integr mixtur distribut fit rbf model assum data set uj min ttafj uj uj dx dz jln rewrit slightli differ notat use angl bracket denot expect defin pi object written min jln iqi observ sampl variabl pair gaussian cloud data jvj gaussian mean uj covari matrix cj let ei hi pi ax bu set paramet hi log likelihood singl data point model const maximum likelihood rbf fit mixtur gaussian data obtain minim follow integr quadrat form learn nonlinear dynam use em take deriv respect premultipli set zero give linear equat tij solv zzt zt word given expect angl bracket optim paramet solv via set linear equat appendix show expect comput analyt deriv somewhat labori intuit simpl gaussian rbf multipli gaussian densiti form new unnorm gaussian space expect new gaussian easi comput fit algorithm illustr right panel figur xt gaussian evid xt gaussian evid xt gaussian evid om ut input output ume input dimens figur illustr step algorithm left panel show inform use extend kalman smooth ek infer hidden state distribut step right panel illustr regress techniqu employ step fit mixtur gaussian densiti requir gaussian rbf network use fit solv analyt dash line show regular rbf fit centr four gaussian densiti solid line show analyt rbf fit use covari inform dot line show support rbf kernel result test well algorithm could learn dynam nonlinear system observ input output system consist singl input state output variabl time relat state one time step next given tanh nonlinear sampl output system respons white nois shown figur left panel initi nonlinear model linear dynam model train em turn initi variant factor analysi model given rbf xt space uniformli space within rang automat determin densiti point xt space initi algorithm discov sigmoid nonlinear dynam within less iter em figur middl right panel experi need done determin practic method real domain ghahramani rowei figur left data set use train first half test rest consist time seri input output middl repres plot log likelihood vs iter em linear dynam system dash line nonlinear dynam system train describ paper solid line note actual likelihood nonlinear dynam system cannot gener comput analyt shown approxim likelihood comput ek kink solid curv come initi linear dynam end nonlinear start learn right mean gaussian posterior comput ek dot along sigmoid nonlinear dash line rbf nonlinear learn algorithm point algorithm actual observ pair infer input output current model paramet discuss paper bring togeth two classic algorithm one statist anoth system engin address learn stochast nonlinear dynam system shown pair extend kalman smooth algorithm state estim step radial basi function learn model permit analyt solut step em algorithm capabl learn nonlinear dynam model data side effect deriv algorithm train radial basi function network fit data form mixtur gaussian initi approach three potenti limit first step present modifi centr width rbf kernel possibl comput expect requir chang centr width requir resort partial step low dimension state space fill space pre fix kernel feasibl strategi need exponenti mani rbf high dimens second em train slow especi initi poorli understand differ hidden variabl model relat help devis sensibl initi heurist exampl model use nest initi first learn simpl linear dynam system turn initi variant factor analysi third method present learn batch data assum stationari dynam recent extend handl onlin learn nonstationari dynam belief network literatur recent domin two method approxim infer markov chain mont carlo variat approxim knowledg paper first instanc extend kalman smooth use perform approxim infer step em ek theoret guarante variat method simplic gain wide accept estim control literatur method infer nonlinear dynam system explor gener method learn nonlinear multilay belief network learn nonlinear dynam use em acknowledg zg would like acknowledg support cito ontario gatsbi charit fund str support part nsf center neuromorph system engin nserc canada award expect requir fit rbf expect need comput start easier one equat xx xz zz depend rbf kernel cj observ multipli gaussian rbf kernel pi equat jv get gaussian densiti mean covari ci cij extra constant due lack normal rio cl col exp sij ici ujc uj ci ui use fiij ij evalu expect pi fiij pi fii ui final pi pt exp cit cit itj ci ct itj itj refer briegel tresp fisher score mixtur mode approach approxim infer learn nonlinear state space model volum mit press dempster laird rubin maximum likelihood incomplet data via em algorithm royal statist societi seri jordan ghahramani jaakkola saul introduct variat method graphic model machin learn kalman buci new result linear filter predict journal basic engin asm ljung ssderstrsm theori practic recursir identif mit press cambridg moodi darken fast learn network local tune process unit neural comput neal probabilist infer use markov chain mont carlo method technic report crg tr rauch solut linear smooth problem ieee transact automat control shumway stoffer approach time seri smooth forecast use em algorithm time seri analysi