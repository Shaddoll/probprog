abstract wake sleep algorithm simpl learn rule model hidden variabl shown algorithm appli factor analysi model linear version helmholtz machin even factor analysi model gener converg prove theoret articl describ geometr understand algorithm contrast em expectationmaxim algorithm era algorithm result prove converg algorithm factor analysi model also show condit converg gener model introduct algorithm simpl hebbian learn algorithm neal dayan appli algorithm factor analysi model model seen linear version helmholtz machin mention converg algorithm prove theoret even simpl model similar em algorithm also empir result algorithm seem work factor analysi model essenti differ em algorithm articl show era algorithm inform geometr version em algorithm describ essenti differ result show cannot reli similar reason algorithm work howev even differ algorithm work factor analysi model prove theoret show proof also show condit algorithm work gener model ikeda amari nakahara factor analysi model algorithm factor analysi model singl factor defin follow gener model gener model yg xt xn dimension real valu visibl input singl invis factor vector factor load overal mean vector set zero articl nois diagon covari matrix diag helmholtz machin gener model accompani recognit model defin recognit model rtx vector recognit weight af nois data xt xn given want estim mle maximum likelihood estim algorithm appli learn model wake phase train set xs choos number randomli data gener accord recognit model rtrx st updat follow use small posit number slightli less gt gt gti xi gi ty denot averag chosen data sleep phase accord updat generar model ygt diag gener number updat rt rt st st rtrx iter phase tri find mle converg point follow discuss let us defin two probabl densiti densiti gener model recognit model let gener model give densiti function exp xr log log recognit model give distribut condit follow rl data xn defin defin rl rl rl exp xr rr fi log loglci log converg wake sleep algorithm em em algorithm factor analysi model mention algorithm similar em algorithm essenti differ section first show em algorithm also describ era algorithm give us inform geometr understand em algorithm result show differ em algorithm next section em algorithm consist follow two step step defin ot ep yl logp ac step updat ot argmax gt gt xt gt gt xt gt xt diag gt yt gt ep denot take averag probabl distribut iter two step converg give mle em algorithm use gener model era algorithm also use recognit model era algorithm consist ra step defin ra project two manifold manifold defin follow model manifold ac lo diag data manifold deal ir rn cx includ matrix defin data call data manifold figur inform geometr understand era algorithm figur schemat show era algorithm consist two step ra step step paramet recognit gener model updat respect ikeda amari nakahara step updat project ofp rh argmin kl rl ot gt st rt gt gt gt gt kl rl kullback leibler diverg defin kl rl eq logp ra step updat ra project ofq ot argmin kl rh urt diag gt lrtr gt st rt urt substitut rt st easili prove equival era em algorithm equival differ em algorithm wake phase correspond gradient flow step stochast sens sleep phase gradient flow step order see clear show detail phase section first show averag rt rt diag crt cr ad rt rt zt gt gt rt gt th div rg writt deriv diverg respect arc ff cr kl diag cr rrcr result rewrit wake phase converg wake sleep algorithm sinc posit definit matrix wake phase gradient flow step defin hand kl rl kl rl deriv diverg respect orkl rl ggt gte kl rl gtr rt ur therefor sleep phase bc rewritten rt rt st kl ot rh st st st st kl ot rlt also gradient flow asymmctr diverg arc differ linc version step essenti differ em algorithm therefor wc cannot prove converg algorithm base similar two algorithm klfi kl nlp figur wake sleep algorithm converg properti want prove converg properti algorithm find lyapnov function algorithm converg guarante find instead find lyapnov function take continu time see behavior paramet diverg ot kl rl function deriv respect given deriv respect rkl rl lg gt gt kl rl gt ikeda amari nakahara hand set flow follow updat due algorithm dt dt crt st rttcrt gt rttcrt wt grot rt ot gr fi st gtrt rtr wtrt these result dk rh ot dt dkl rtt ot oklda okldr dt og dt dt okl okl oe dt dt first term right side appar non posit th one clear okl st rtt wtrt dt gtrt zgt gt gt gtrt gt gt kl vt ot decreas stay trt rt gt gt follow equat hold two equival lot rt ot result flow decreas kl vt ot time converg alway decreas vt ot sinc converg satisfi independ final converg discuss factor analysi model special properti thatp ylx ylx rl equival follow condit satisfi gre gr lg properti minim kl rl kl rl respect lead point ep log kl rl ep log ylx ylx rl kl rl eq logp eq logp ylx includ second term right side hold two term therefor kl rl kl rl minim point converg wake sleep algorithm use result modifi algorithm factor analysi model tri wake sleep phase altern sleep well until converg find equival step era algorithm sinc wake phase gradient flow ra step procedur converg mle algorithm equival call gem gener em algorithm reason gem algorithm work ix realiz recognit model ylx recognit model realiz algorithm converg mle go show exampl conclud articl suppos case averag recognit model linear function come nonlinear function recognit model rtx function singl input output af nois case gener model realiz recognit model gener minim respect lead differ point minim kl rl minim satisfi ep tx tx ep yf tx ep yf rtx rtx kl rl minim satisfi atr la eq ae rl rrx rrx eq rrx xxr gre deriv linear function constant valu give differ gener studi factor analysi model show algorithm work model analysi could show reason algorithm work model gener model realiz recognit model also show algorithm converg mle gener model realiz simpl exampl acknowledg thank dr noboru murata use discuss work refer shun ichi amari differenti geometr method statist volum lectur note statist springer verlag berlin shun ichi amari inform geometri em em algorithm neural network neural network peter dayan geoffrey hinton radford neal helmholtz machin neural comput dempster laird rubin maximum likelihood incomplet data via em algorithm statist societi seri hinton dayan frey neal wake sleep algorithm unsupervis neural network scienc geoffrey mclachlan thriyambakam krishnan em algorithm extens wiley seri probabl statist john wiley son inc radford neal peter dayan factor analysi use delta rule wake sleep learn neural comput