abstract nonneg boltzmann machin nnbm recurr neural network model describ multimod nonneg data applic maximum likelihood estim model give learn rule analog binari boltzmann machin examin util mean field approxim nnbm describ mont carlo sampl techniqu use learn paramet reflect slice sampl particularli well suit distribut effici implement sampl distribut illustr learn nnbm translat invari distribut well gener model imag human face introduct multivari gaussian elementari distribut use model gener data repres maximum entropi distribut constraint mean covari matrix distribut match data case binari data maximum entropi distribut match first second order statist data given boltzmann machin probabl particular state boltzmann machin given exponenti form si exp siaidsj bisi ij interpret eq neural network paramet aid repres symmetr recurr weight differ unit network bi repres local bias unfortun paramet simpli relat observ mean covari nonneg boltzmann machin oo figur probabl densiti shade contour plot two dimension competit nnbm distribut energi function distribut contain saddl point two local minima gener observ multimod distribut data normal gaussian instead need adapt use iter learn rule involv difficult sampl binari distribut boltzmann machin also gener continu nonneg variabl case maximum entropi distribut nonneg data known first second order statist describ distribut previous call rectifi gaussian distribut exp ifzi vi energi fimction normal constant az exp properti nonneg boltzmann machin nnbm distribut differ quit substanti normal gaussian particular presenc nonneg constraint allow distribut multipl mode exampl fig show two dimension nnbm distribut two separ maxima locat rectifi axe multimod distribut would poorli model singl normal gaussian submiss discuss multimod nnbm distribut learn nonneg data show limit mean field approxim distribut illustr recent develop effici sampl techniqu continu belief network use tune weight network specif exampl learn demonstr translat invari distribut well gener model face imag maximum likelihood learn rule nnbm deriv maxim log likelihood observ data eq given set nonneg vector tt down mackay lee index differ exampl log likelihood zl gp ze gz tt take deriv ofeq respect paramet give xixj xixj oaij ol xi xi subscript denot clamp averag data subscript denot free averag nnbm distribut deriv use defin gradient ascent learn rule nnbm similar binari boltzmann machin contrast clamp free covari matrix use updat iteract differ clamp free mean use updat local bias mean field approxim major difficulti learn algorithm lie evalu averag xixj xi analyt intract calcul free averag exactli approxim necessari learn mean field approxim previous propos determinist altern learn binari boltzmann machin although contrast view valid investig util mean field theori approxim nnbm distribut mean field equat deriv approxim nnbm distribut eq factor form ii ii qri ci differ margin densiti xi character mean ri fix constant product distribut natur factoriz distribut nonneg random variabl optim mean field paramet ri determin minim kullback leibler diverg nnbm distribut factor distribut qiip dxq log logz find minimum eq set deriv respect mean field paramet ri zero give simpl mean field equat aii bi aijrj nonneg boltzmann machin xi figur slice sampl one dimens given current sampl point height randomli chosen defin slice st new ci chosen multidimension slice new point chosen use ballist dynam specular reflect interior boundari slice equat solv self consist ri free statist nnbm replac statist factor distribut xi ti xixj ij titj fidel approxim determin well factor distribut model nnbm distribut unfortun distribut one shown fig mean field approxim quit differ true multimod nnbm distribut suggest naiv mean field approxim inadequ learn nnbm fact attempt use approxim fail learn exampl given follow section howev mean field approxim still use initi paramet reason valu use sampl techniqu describ mont carlo sampl direct approach calcul free averag eq numer approxim accomplish use mont carlo sampl gener repres set point suffici approxim statist continu distribut particular markov chain mont carlo method employ iter stochast dynam whose equilibrium distribut converg desir distribut binari boltzmann machin sampl dynam involv random spin flip chang valu singl binari compon unfortun singl compon dynam easili caught local energi minima converg slowli larg system make sampl binari distribut difficult special comput techniqu simul anneal cluster updat etc develop tri circumv problem nnbm use continu variabl make possibl investig differ stochast dynam order effici sampl distribut first experi gibb sampl order overrelax found requir invers error function comput expens instead recent develop method slice sampl seem particularli well suit implement nnbm basic idea slice sampl algorithm shown fig given sampl point ci random ci first uniformli chosen slice defin connect set point ap new point chosen down mackay lee io figur contour two dimension competit nnbm distribut overlaid mean field approxim reflect slice sampl randomli slice distribut larg shown converg desir densiti nnbm solv boundari point along particular direct given slice quit simpl sinc involv solv root quadrat equat order effici choos new point within particular slice reflect billiard ball dynam use random initi veloc chosen new point evolv travel certain distanc current point specularli reflect boundari slice intuit revers reflect allow dynam satisfi detail balanc fig mean field approxim reflect slice sampl use model two dimension competit nnbm distribut poor fit mean field approxim appar unimod factor densiti sampl point reflect slice sampl algorithm repres underli nnbm distribut higher dimension data mean field approxim becom progress wors therefor necessari implement numer slice sampl algorithm order accur approxim nnbm distribut translat invari model ben yishai et al propos model orient tune primari visual cortex interpret cooper nnbm distribut absenc visual input fire rate cortic neuron describ minim energi function paramet aij bi co li jl ij distribut use test nnbm learn algorithm first larg set dimension nonneg mine vector gener sampl distribut fi use sampl mine data paramet learn unimod initi evolv mine vector use reflect slice sampl evolv vector use calcul free averag eq estim updat procedur iter evolv averag match train data learn paramet found almost exactli match origin form eq repres sampl learn nnbm distribut shown fig nonneg boltzmann machin figur repres sampl taken nnbm train learn translat invari cooper distribut figur morph face imag success sampl learn nnbm distribut sampl gener normal gaussian gener model face also use nnbm learn gener model imag human face nnbm use model correl coeffici nonneg matrix factor nmf face imag nmf reduc dimension nonneg data decompos face imag part correpond eye nose ear etc sinc differ part coactiv reconstruct face activ part contain signific correl need captur gener model briefli demonstr nnbm abl learn correl sampl nnbm stochast gener coeffici graphic display face imag fig show repres face imag reflect slice sampl dynam evolv coeffici also display figur analog imag gener normal gaussian use model correl instead clear nonneg constraint multimod natur nnbm result sampl cleaner distinct face down mackay lee discuss introduc nnbm recurr neural network model abl describ multimod nonneg data applic made practic effici slice sampl mont carlo method learn algorithm incorpor numer sampl nnbm distribut abl learn observ nonneg data demonstr applic nnbm learn cooper translat invari distribut well real data imag human face extens present work includ incorpor hidden unit recurr network addit hidden unit impli model certain higher order statist data requir calcul averag hidden unit anticip margin distribut unit commonli unimod henc mean field theori valid approxim averag anoth possibl extens involv gener nnbm model continu data confin within certain rang situat slice sampl techniqu would also use effici gener repres sampl case hope work stimul research use type recurr neural network model complex multimod data acknowledg author acknowledg use discuss john hopfield sebastian seung nichola socci gayl wittenberg indebt haim sompolinski point maximum entropi interpret boltzmann machin work fund bell laboratori lucent technolog down grate moral support open ear mind beth brittl gunther lenz sandra scheitz refer hinton ge sejnowski tj optim perceptu learn ieee confer comput vision pattern recognit washington dc ackley dh hinton ge sejnowski tj learn algorithm boltzmann machin cognit scienc socci nd lee dd seung hs rectifi gaussian distribut advanc neural inform process system mackay djc introduct mont carlo method learn graphic model kluwer academ press nato scienc seri galland cc limit determinist boltzmann machin learn network kappen hj rodriguez fb mean field approach learn boltzmann machin pattern recognit practic amsterdam neal rm suppress random walk markov chain mont carlo use order overrelax technic report dept statist univers toronto neal rm markov chain mont carlo method base slice densiti function technic report dept statist univers toronto ben yishai bar rl sompolinski theori orient tune visual cortex proc nat acad sci usa lee dd seung hs learn part object non neg matrix factor natur