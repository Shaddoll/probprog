{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# eng_stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_cleaner(doc):\n",
    "    '''\n",
    "    Clean and preprocess a document.\n",
    "    \n",
    "    1. Use regex to remove all special characters (only keep letters)\n",
    "    2. Make strings to lower case and tokenize / word split reviews\n",
    "    3. Remove English stopwords\n",
    "    '''\n",
    "    doc = re.sub(\"[^a-zA-Z]\", \" \",doc)\n",
    "    doc = doc.lower().split()\n",
    "    eng_stopwords = stopwords.words(\"english\")\n",
    "    for stopword in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "        eng_stopwords.append(stopword)\n",
    "    doc = [w for w in doc if not w in eng_stopwords]\n",
    "    ps = PorterStemmer()\n",
    "    ps_stems = []\n",
    "    for word in doc:\n",
    "        ps_stems.append(ps.stem(word))\n",
    "    doc = ' '.join(doc)\n",
    "    \n",
    "    return(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean words in each document\n",
    "import glob    \n",
    "txt_files = glob.glob(\"nipstxt/nips12/*.txt\")\n",
    "for file in sorted(txt_files):\n",
    "    doc =''\n",
    "    with open(file, 'rt',encoding = \"ISO-8859-1\") as f:\n",
    "        body = False\n",
    "        for line in f:\n",
    "            line.strip()\n",
    "            if line == 'Abstract':\n",
    "                body = True\n",
    "            if line == 'Reference':\n",
    "                body = False\n",
    "            if body:\n",
    "                line.strip()\n",
    "                if line[-1] == '-':\n",
    "                    line = line.strip('-')\n",
    "                    doc += line\n",
    "                else: \n",
    "                    line += ' '\n",
    "                    doc += line\n",
    "        f.close()\n",
    "    doc = doc_cleaner(doc)\n",
    "    with open('nipstxt/nips12/'+'clean_'+file[-8:-4]+'.txt', 'a') as f2:\n",
    "        f2.write(doc)  \n",
    "        f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a vocabulary set that contains uniqe words\n",
    "txt_files_clean = glob.glob(\"nipstxt/nips12/clean_*.txt\")\n",
    "vocabulary = set()\n",
    "for file in sorted(txt_files_clean):\n",
    "    with open(file, 'rt',encoding = \"ISO-8859-1\") as f:\n",
    "        for line in f:\n",
    "            doc_words = line.split()\n",
    "            for word in doc_words:\n",
    "                vocabulary.add(word)\n",
    "id = 0\n",
    "wordToID = {}\n",
    "for key in vocabulary:\n",
    "    wordToID[key] = id\n",
    "    id += 1\n",
    "with open('wordToID', 'a') as f2:\n",
    "    for key, value in wordToID.items():\n",
    "        f2.write(str(key)+' '+str(value)+'\\n')\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13944\n"
     ]
    }
   ],
   "source": [
    "print (len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change document with word ID \n",
    "for file in sorted(txt_files_clean):\n",
    "    with open(file, 'rt',encoding = \"ISO-8859-1\") as f:\n",
    "        doc_wordID = ''\n",
    "        for line in f:\n",
    "            doc_words = line.split()\n",
    "            for word in doc_words:\n",
    "                doc_wordID += str(wordToID[word])\n",
    "                doc_wordID += ' '\n",
    "        with open('nipstxt/nips12/'+'doc_wordID'+file[-8:-4]+'.txt', 'a') as f2:\n",
    "            f2.write(doc_wordID)  \n",
    "            f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0,\n",
       " 'embraces': 1,\n",
       " 'labeled': 2,\n",
       " 'representing': 3,\n",
       " 'finally': 4,\n",
       " 'models': 5,\n",
       " 'executed': 6,\n",
       " 'optimizes': 7,\n",
       " 'replay': 8,\n",
       " 'rewards': 9,\n",
       " 'obtain': 10,\n",
       " 'trivially': 11,\n",
       " 'correctly': 12,\n",
       " 'parameter': 13,\n",
       " 'database': 14,\n",
       " 'current': 15,\n",
       " 'oet': 16,\n",
       " 'right': 17,\n",
       " 'demonstrate': 18,\n",
       " 'value': 19,\n",
       " 'equal': 20,\n",
       " 'solves': 21,\n",
       " 'either': 22,\n",
       " 'functions': 23,\n",
       " 'part': 24,\n",
       " 'top': 25,\n",
       " 'times': 26,\n",
       " 'divergence': 27,\n",
       " 'history': 28,\n",
       " 'realvalued': 29,\n",
       " 'computed': 30,\n",
       " 'knowledge': 31,\n",
       " 'upper': 32,\n",
       " 'normalize': 33,\n",
       " 'grows': 34,\n",
       " 'state': 35,\n",
       " 'illustrate': 36,\n",
       " 'approximated': 37,\n",
       " 'coordinates': 38,\n",
       " 'floor': 39,\n",
       " 'legitimacy': 40,\n",
       " 'abstract': 41,\n",
       " 'vicinity': 42,\n",
       " 'observe': 43,\n",
       " 'approximately': 44,\n",
       " 'finds': 45,\n",
       " 'domains': 46,\n",
       " 'argmaxq': 47,\n",
       " 'trajectories': 48,\n",
       " 'oo': 49,\n",
       " 'allowed': 50,\n",
       " 'recall': 51,\n",
       " 'little': 52,\n",
       " 'already': 53,\n",
       " 'change': 54,\n",
       " 'robotic': 55,\n",
       " 'lllllllllnillllllllllllllllllllll': 56,\n",
       " 'reach': 57,\n",
       " 'employed': 58,\n",
       " 'gray': 59,\n",
       " 'rotational': 60,\n",
       " 'representation': 61,\n",
       " 'schematically': 62,\n",
       " 'let': 63,\n",
       " 'point': 64,\n",
       " 'go': 65,\n",
       " 'initially': 66,\n",
       " 'control': 67,\n",
       " 'uniformly': 68,\n",
       " 'denote': 69,\n",
       " 'exploration': 70,\n",
       " 'planning': 71,\n",
       " 'represent': 72,\n",
       " 'desired': 73,\n",
       " 'sequence': 74,\n",
       " 'ask': 75,\n",
       " 'execute': 76,\n",
       " 'method': 77,\n",
       " 'chosen': 78,\n",
       " 'noise': 79,\n",
       " 'follows': 80,\n",
       " 'implies': 81,\n",
       " 'simplicity': 82,\n",
       " 'notice': 83,\n",
       " 'mapping': 84,\n",
       " 'maps': 85,\n",
       " 'temporal': 86,\n",
       " 'drawn': 87,\n",
       " 'sort': 88,\n",
       " 'conditioning': 89,\n",
       " 'mdps': 90,\n",
       " 'success': 91,\n",
       " 'states': 92,\n",
       " 'popular': 93,\n",
       " 'carded': 94,\n",
       " 'difficulty': 95,\n",
       " 'applicable': 96,\n",
       " 'minor': 97,\n",
       " 'relative': 98,\n",
       " 'averaging': 99,\n",
       " 'makes': 100,\n",
       " 'proposed': 101,\n",
       " 'extension': 102,\n",
       " 'experimental': 103,\n",
       " 'finite': 104,\n",
       " 'thousands': 105,\n",
       " 'derived': 106,\n",
       " 'hence': 107,\n",
       " 'online': 108,\n",
       " 'figures': 109,\n",
       " 'corresponds': 110,\n",
       " 'requires': 111,\n",
       " 'markov': 112,\n",
       " 'however': 113,\n",
       " 'well': 114,\n",
       " 'armed': 115,\n",
       " 'additional': 116,\n",
       " 'stationary': 117,\n",
       " 'importance': 118,\n",
       " 'selection': 119,\n",
       " 'input': 120,\n",
       " 'function': 121,\n",
       " 'large': 122,\n",
       " 'learns': 123,\n",
       " 'converges': 124,\n",
       " 'locate': 125,\n",
       " 'ct': 126,\n",
       " 'information': 127,\n",
       " 'receives': 128,\n",
       " 'scaling': 129,\n",
       " 'black': 130,\n",
       " 'called': 131,\n",
       " 'application': 132,\n",
       " 'step': 133,\n",
       " 'observed': 134,\n",
       " 'cr': 135,\n",
       " 'idea': 136,\n",
       " 'hell': 137,\n",
       " 'angle': 138,\n",
       " 'succeed': 139,\n",
       " 'show': 140,\n",
       " 'infer': 141,\n",
       " 'computer': 142,\n",
       " 'consistently': 143,\n",
       " 'speaking': 144,\n",
       " 'argmax': 145,\n",
       " 'subsequent': 146,\n",
       " 'variables': 147,\n",
       " 'integration': 148,\n",
       " 'seen': 149,\n",
       " 'approximate': 150,\n",
       " 'corner': 151,\n",
       " 'rate': 152,\n",
       " 'entropy': 153,\n",
       " 'histories': 154,\n",
       " 'capable': 155,\n",
       " 'gripper': 156,\n",
       " 'exactly': 157,\n",
       " 'dynamic': 158,\n",
       " 'time': 159,\n",
       " 'processes': 160,\n",
       " 'contains': 161,\n",
       " 'distributed': 162,\n",
       " 'policies': 163,\n",
       " 'error': 164,\n",
       " 'trajectory': 165,\n",
       " 'discussion': 166,\n",
       " 'specified': 167,\n",
       " 'samplebased': 168,\n",
       " 'account': 169,\n",
       " 'grasping': 170,\n",
       " 'according': 171,\n",
       " 'valued': 172,\n",
       " 'mono': 173,\n",
       " 'erroneous': 174,\n",
       " 'agent': 175,\n",
       " 'denoted': 176,\n",
       " 'around': 177,\n",
       " 'results': 178,\n",
       " 'section': 179,\n",
       " 'iteration': 180,\n",
       " 'recursively': 181,\n",
       " 'simulator': 182,\n",
       " 'applying': 183,\n",
       " 'told': 184,\n",
       " 'number': 185,\n",
       " 'directly': 186,\n",
       " 'term': 187,\n",
       " 'chains': 188,\n",
       " 'using': 189,\n",
       " 'side': 190,\n",
       " 'monte': 191,\n",
       " 'spirit': 192,\n",
       " 'grey': 193,\n",
       " 'assumptions': 194,\n",
       " 'annotated': 195,\n",
       " 'towards': 196,\n",
       " 'algorithm': 197,\n",
       " 'looking': 198,\n",
       " 'objective': 199,\n",
       " 'finding': 200,\n",
       " 'arbitrarily': 201,\n",
       " 'moment': 202,\n",
       " 'work': 203,\n",
       " 'fundamental': 204,\n",
       " 'close': 205,\n",
       " 'takes': 206,\n",
       " 'ones': 207,\n",
       " 'must': 208,\n",
       " 'localization': 209,\n",
       " 'refer': 210,\n",
       " 'hand': 211,\n",
       " 'crq': 212,\n",
       " 'lb': 213,\n",
       " 'suggest': 214,\n",
       " 'modifications': 215,\n",
       " 'translations': 216,\n",
       " 'surpasses': 217,\n",
       " 'interested': 218,\n",
       " 'leads': 219,\n",
       " 'pentium': 220,\n",
       " 'special': 221,\n",
       " 'fairly': 222,\n",
       " 'add': 223,\n",
       " 'uses': 224,\n",
       " 'new': 225,\n",
       " 'mobile': 226,\n",
       " 'follow': 227,\n",
       " 'iterations': 228,\n",
       " 'within': 229,\n",
       " 'framework': 230,\n",
       " 'expression': 231,\n",
       " 'determine': 232,\n",
       " 'single': 233,\n",
       " 'proceed': 234,\n",
       " 'neighbors': 235,\n",
       " 'conditionally': 236,\n",
       " 'penalized': 237,\n",
       " 'counter': 238,\n",
       " 'across': 239,\n",
       " 'rwi': 240,\n",
       " 'denotes': 241,\n",
       " 'holding': 242,\n",
       " 'rewarded': 243,\n",
       " 'heights': 244,\n",
       " 'operating': 245,\n",
       " 'prior': 246,\n",
       " 'following': 247,\n",
       " 'insufficient': 248,\n",
       " 'exact': 249,\n",
       " 'mathematical': 250,\n",
       " 'needs': 251,\n",
       " 'suboptimal': 252,\n",
       " 'sight': 253,\n",
       " 'addition': 254,\n",
       " 'penalties': 255,\n",
       " 'factor': 256,\n",
       " 'normalizer': 257,\n",
       " 'particle': 258,\n",
       " 'projected': 259,\n",
       " 'also': 260,\n",
       " 'configurations': 261,\n",
       " 'hits': 262,\n",
       " 'added': 263,\n",
       " 'dot': 264,\n",
       " 'curves': 265,\n",
       " 'space': 266,\n",
       " 'practical': 267,\n",
       " 'observation': 268,\n",
       " 'second': 269,\n",
       " 'learner': 270,\n",
       " 'unobservable': 271,\n",
       " 'distributions': 272,\n",
       " 'learning': 273,\n",
       " 'distance': 274,\n",
       " 'observations': 275,\n",
       " 'optimally': 276,\n",
       " 'basic': 277,\n",
       " 'partially': 278,\n",
       " 'goal': 279,\n",
       " 'backing': 280,\n",
       " 'head': 281,\n",
       " 'evaluating': 282,\n",
       " 'focused': 283,\n",
       " 'far': 284,\n",
       " 'apply': 285,\n",
       " 'denoting': 286,\n",
       " 'proposes': 287,\n",
       " 'empirical': 288,\n",
       " 'kernels': 289,\n",
       " 'applications': 290,\n",
       " 'impossible': 291,\n",
       " 'presented': 292,\n",
       " 'doubled': 293,\n",
       " 'discrete': 294,\n",
       " 'may': 295,\n",
       " 'motion': 296,\n",
       " 'mild': 297,\n",
       " 'spaces': 298,\n",
       " 'probabilities': 299,\n",
       " 'providing': 300,\n",
       " 'per': 301,\n",
       " 'constant': 302,\n",
       " 'known': 303,\n",
       " 'runs': 304,\n",
       " 'model': 305,\n",
       " 'nearest': 306,\n",
       " 'discounted': 307,\n",
       " 'dimensions': 308,\n",
       " 'describes': 309,\n",
       " 'ignored': 310,\n",
       " 'environments': 311,\n",
       " 'somewhere': 312,\n",
       " 'tribute': 313,\n",
       " 'synthetic': 314,\n",
       " 'many': 315,\n",
       " 'mc': 316,\n",
       " 'iiiilll': 317,\n",
       " 'neighbor': 318,\n",
       " 'optimal': 319,\n",
       " 'plotted': 320,\n",
       " 'based': 321,\n",
       " 'cumulative': 322,\n",
       " 'integrating': 323,\n",
       " 'infinitely': 324,\n",
       " 'experience': 325,\n",
       " 'obtained': 326,\n",
       " 'possibly': 327,\n",
       " 'weighted': 328,\n",
       " 'grasps': 329,\n",
       " 'gaussian': 330,\n",
       " 'injected': 331,\n",
       " 'fetch': 332,\n",
       " 'delay': 333,\n",
       " 'know': 334,\n",
       " 'find': 335,\n",
       " 'specifically': 336,\n",
       " 'convex': 337,\n",
       " 'incrementally': 338,\n",
       " 'quadrupling': 339,\n",
       " 'boundary': 340,\n",
       " 'variance': 341,\n",
       " 'exploiting': 342,\n",
       " 'object': 343,\n",
       " 'conventional': 344,\n",
       " 'networks': 345,\n",
       " 'assume': 346,\n",
       " 'toot': 347,\n",
       " 'linear': 348,\n",
       " 'characterized': 349,\n",
       " 'preliminary': 350,\n",
       " 'numerical': 351,\n",
       " 'paper': 352,\n",
       " 'partide': 353,\n",
       " 'applied': 354,\n",
       " 'example': 355,\n",
       " 'paying': 356,\n",
       " 'rise': 357,\n",
       " 'certain': 358,\n",
       " 'agents': 359,\n",
       " 'task': 360,\n",
       " 'diagrams': 361,\n",
       " 'stdctly': 362,\n",
       " 'performance': 363,\n",
       " 'path': 364,\n",
       " 'version': 365,\n",
       " 'density': 366,\n",
       " 'sampling': 367,\n",
       " 'random': 368,\n",
       " 'easy': 369,\n",
       " 'difference': 370,\n",
       " 'solutions': 371,\n",
       " 'furthermore': 372,\n",
       " 'world': 373,\n",
       " 'equation': 374,\n",
       " 'average': 375,\n",
       " 'maximizes': 376,\n",
       " 'samples': 377,\n",
       " 'two': 378,\n",
       " 'expectation': 379,\n",
       " 'represents': 380,\n",
       " 'central': 381,\n",
       " 'larger': 382,\n",
       " 'factors': 383,\n",
       " 'introduction': 384,\n",
       " 'thus': 385,\n",
       " 'approach': 386,\n",
       " 'maintains': 387,\n",
       " 'experiments': 388,\n",
       " 'acting': 389,\n",
       " 'grasp': 390,\n",
       " 'converge': 391,\n",
       " 'action': 392,\n",
       " 'plots': 393,\n",
       " 'possess': 394,\n",
       " 'works': 395,\n",
       " 'xt': 396,\n",
       " 'planner': 397,\n",
       " 'establish': 398,\n",
       " 'sides': 399,\n",
       " 'possible': 400,\n",
       " 'advantage': 401,\n",
       " 'ao': 402,\n",
       " 'result': 403,\n",
       " 'good': 404,\n",
       " 'preclude': 405,\n",
       " 'might': 406,\n",
       " 'updated': 407,\n",
       " 'long': 408,\n",
       " 'illustrates': 409,\n",
       " 'solved': 410,\n",
       " 'pr': 411,\n",
       " 'cases': 412,\n",
       " 'lead': 413,\n",
       " 'target': 414,\n",
       " 'la': 415,\n",
       " 'ot': 416,\n",
       " 'robotics': 417,\n",
       " 'performs': 418,\n",
       " 'comer': 419,\n",
       " 'axis': 420,\n",
       " 'unsuccessful': 421,\n",
       " 'knowing': 422,\n",
       " 'act': 423,\n",
       " 'studied': 424,\n",
       " 'opposite': 425,\n",
       " 'used': 426,\n",
       " 'viewing': 427,\n",
       " 'mixed': 428,\n",
       " 'robot': 429,\n",
       " 'names': 430,\n",
       " 'tums': 431,\n",
       " 'open': 432,\n",
       " 'conditioned': 433,\n",
       " 'noisy': 434,\n",
       " 'move': 435,\n",
       " 'carlo': 436,\n",
       " 'observable': 437,\n",
       " 'bars': 438,\n",
       " 'problems': 439,\n",
       " 'one': 440,\n",
       " 'distribution': 441,\n",
       " 'gives': 442,\n",
       " 'greedy': 443,\n",
       " 'component': 444,\n",
       " 'specifies': 445,\n",
       " 'successfully': 446,\n",
       " 'refers': 447,\n",
       " 'subscript': 448,\n",
       " 'hit': 449,\n",
       " 'kl': 450,\n",
       " 'values': 451,\n",
       " 'implementation': 452,\n",
       " 'size': 453,\n",
       " 'propagation': 454,\n",
       " 'probability': 455,\n",
       " 'ii': 456,\n",
       " 'dr': 457,\n",
       " 'dzt': 458,\n",
       " 'compute': 459,\n",
       " 'induces': 460,\n",
       " 'unbounded': 461,\n",
       " 'belief': 462,\n",
       " 'generic': 463,\n",
       " 'even': 464,\n",
       " 'common': 465,\n",
       " 'discount': 466,\n",
       " 'previous': 467,\n",
       " 'survival': 468,\n",
       " 'away': 469,\n",
       " 'maaxq': 470,\n",
       " 'leading': 471,\n",
       " 'digital': 472,\n",
       " 'episodes': 473,\n",
       " 'generate': 474,\n",
       " 'likelihood': 475,\n",
       " 'notation': 476,\n",
       " 'different': 477,\n",
       " 'represented': 478,\n",
       " 'maximum': 479,\n",
       " 'occasionally': 480,\n",
       " 'address': 481,\n",
       " 'camera': 482,\n",
       " 'sets': 483,\n",
       " 'beliefs': 484,\n",
       " 'notion': 485,\n",
       " 'narrowly': 486,\n",
       " 'throughout': 487,\n",
       " 'total': 488,\n",
       " 'successful': 489,\n",
       " 'found': 490,\n",
       " 'map': 491,\n",
       " 'rt': 492,\n",
       " 'first': 493,\n",
       " 'environment': 494,\n",
       " 'repetitive': 495,\n",
       " 'present': 496,\n",
       " 'investigate': 497,\n",
       " 'unknown': 498,\n",
       " 'stochastic': 499,\n",
       " 'location': 500,\n",
       " 'linearly': 501,\n",
       " 'positive': 502,\n",
       " 'generalize': 503,\n",
       " 'like': 504,\n",
       " 'piecewise': 505,\n",
       " 'rich': 506,\n",
       " 'training': 507,\n",
       " 'past': 508,\n",
       " 'typical': 509,\n",
       " 'vc': 510,\n",
       " 'issue': 511,\n",
       " 'performed': 512,\n",
       " 'decision': 513,\n",
       " 'practice': 514,\n",
       " 'decisions': 515,\n",
       " 'always': 516,\n",
       " 'moving': 517,\n",
       " 'lower': 518,\n",
       " 'steps': 519,\n",
       " 'alternated': 520,\n",
       " 'efficiently': 521,\n",
       " 'continuous': 522,\n",
       " 'located': 523,\n",
       " 'reinforcement': 524,\n",
       " 'making': 525,\n",
       " 'misses': 526,\n",
       " 'yields': 527,\n",
       " 'bag': 528,\n",
       " 'fittest': 529,\n",
       " 'pre': 530,\n",
       " 'specific': 531,\n",
       " 'idt': 532,\n",
       " 'observing': 533,\n",
       " 'figure': 534,\n",
       " 'given': 535,\n",
       " 'vocabulary': 536,\n",
       " 'minutes': 537,\n",
       " 'property': 538,\n",
       " 'thrun': 539,\n",
       " 'left': 540,\n",
       " 'backups': 541,\n",
       " 'pt': 542,\n",
       " 'bottom': 543,\n",
       " 'pomdp': 544,\n",
       " 'return': 545,\n",
       " 'projecting': 546,\n",
       " 'accommodate': 547,\n",
       " 'three': 548,\n",
       " 'reward': 549,\n",
       " 'shown': 550,\n",
       " 'ahead': 551,\n",
       " 'smaller': 552,\n",
       " 'independent': 553,\n",
       " 'learned': 554,\n",
       " 'legal': 555,\n",
       " 'inapplicable': 556,\n",
       " 'actions': 557,\n",
       " 'draw': 558,\n",
       " 'worlds': 559,\n",
       " 'derive': 560,\n",
       " 'order': 561,\n",
       " 'future': 562,\n",
       " 'projection': 563,\n",
       " 'us': 564,\n",
       " 'derivations': 565,\n",
       " 'filters': 566,\n",
       " 'fails': 567,\n",
       " 'along': 568,\n",
       " 'hours': 569,\n",
       " 'fact': 570,\n",
       " 'retrieve': 571,\n",
       " 'variable': 572,\n",
       " 'avoid': 573,\n",
       " 'sufficiently': 574,\n",
       " 'pomdps': 575,\n",
       " 'st': 576,\n",
       " 'defining': 577,\n",
       " 'posterior': 578,\n",
       " 'limitations': 579,\n",
       " 'less': 580,\n",
       " 'approximators': 581,\n",
       " 'preliminaries': 582,\n",
       " 'obviously': 583,\n",
       " 'approximation': 584,\n",
       " 'pv': 585,\n",
       " 'interacts': 586,\n",
       " 'zt': 587,\n",
       " 'heaven': 588,\n",
       " 'oct': 589,\n",
       " 'include': 590,\n",
       " 'nature': 591,\n",
       " 'averaged': 592,\n",
       " 'real': 593,\n",
       " 'solvable': 594,\n",
       " 'initial': 595,\n",
       " 'sample': 596,\n",
       " 'horizon': 597,\n",
       " 'whose': 598,\n",
       " 'learn': 599,\n",
       " 'technically': 600,\n",
       " 'system': 601,\n",
       " 'schemes': 602,\n",
       " 'detection': 603,\n",
       " 'essentially': 604,\n",
       " 'approximations': 605,\n",
       " 'shows': 606,\n",
       " 'predominately': 607,\n",
       " 'priest': 608,\n",
       " 'depicted': 609,\n",
       " 'generalization': 610,\n",
       " 'true': 611,\n",
       " 'problem': 612,\n",
       " 'relatively': 613,\n",
       " 'see': 614,\n",
       " 'zo': 615,\n",
       " 'graph': 616,\n",
       " 'arbitrary': 617,\n",
       " 'literature': 618,\n",
       " 'gathering': 619,\n",
       " 'false': 620,\n",
       " 'extracts': 621,\n",
       " 'simulation': 622,\n",
       " 'centimeters': 623,\n",
       " 'sense': 624,\n",
       " 'operation': 625,\n",
       " 'key': 626,\n",
       " 'case': 627,\n",
       " 'tricks': 628,\n",
       " 'additionally': 629,\n",
       " 'projecfion': 630,\n",
       " 'computes': 631,\n",
       " 'standards': 632,\n",
       " 'solid': 633,\n",
       " 'detected': 634,\n",
       " 'leaving': 635,\n",
       " 'detail': 636,\n",
       " 'instead': 637,\n",
       " 'policy': 638,\n",
       " 'perceptual': 639,\n",
       " 'representations': 640,\n",
       " 'collection': 641,\n",
       " 'curve': 642,\n",
       " 'general': 643,\n",
       " 'existing': 644,\n",
       " 'gradually': 645,\n",
       " 'moreover': 646,\n",
       " 'make': 647,\n",
       " 'accepts': 648,\n",
       " 'height': 649,\n",
       " 'metric': 650,\n",
       " 'theorem': 651,\n",
       " 'searches': 652,\n",
       " 'intentionally': 653,\n",
       " 'densities': 654,\n",
       " 'pc': 655,\n",
       " 'cannot': 656,\n",
       " 'encountered': 657,\n",
       " 'next': 658,\n",
       " 'simplify': 659,\n",
       " 'identified': 660,\n",
       " 'set': 661,\n",
       " 'assuming': 662,\n",
       " 'vct': 663,\n",
       " 'use': 664,\n",
       " 'defined': 665,\n",
       " 'range': 666,\n",
       " 'condensation': 667,\n",
       " 'context': 668,\n",
       " 'table': 669,\n",
       " 'define': 670,\n",
       " 'starts': 671,\n",
       " 'since': 672,\n",
       " 'depicts': 673,\n",
       " 'moves': 674,\n",
       " 'formally': 675,\n",
       " 'devise': 676,\n",
       " 'filter': 677,\n",
       " 'expected': 678,\n",
       " 'require': 679,\n",
       " 'controllable': 680,\n",
       " 'dt': 681,\n",
       " 'negative': 682,\n",
       " 'methods': 683,\n",
       " 'neural': 684,\n",
       " 'chain': 685,\n",
       " 'latter': 686,\n",
       " 'solution': 687,\n",
       " 'sensors': 688,\n",
       " 'look': 689}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
