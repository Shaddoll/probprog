abstract reinforc learn nonstationari environ gener regard import yet difficult problem paper partial address problem formal subclass nonstationari environ environ model call hidden mode markov decis process hm mdp assum environment chang alway confin small number hidden mode mode basic index markov decis process mdp evolv time accord markov chain hm mdp special case partial observ markov decis process pomdp model hm mdp environ via gener pomdp model unnecessarili increas problem complex variant baum welch algorithm develop model learn requir less data time introduct reinforc learn rl learn paradigm base upon framework markov decis process mdp tradit rl research assum environ dynam mdp paramet alway fix stationari assumpt howev realist mani real world applic elev control instanc passeng arriv departur rate vari significanfli one day model fix mdp nonetheless rl nonstationari environ regard difficult problem fact imposs task regular way environ dynam chang henc degre regular must assum typic nonstationari environ presum chang slowli enough onlin rl algorithm employ keep track chang onlin approach memoryless sens even environ ever revert previous learn dynam learn must still need start choi yeung zhang propos model paper propos formal model nonstationari environ repeat dynam certain way model inspir observ real world nonstationari task follow properti properti environment chang confin small number mode stationari environ distinct dynam environ exactli one mode given time concept mode seem applic mani real world task elev control problem exampl system might oper morn rush hour mode even rush hour mode non rush hour mode one also imagin similar mode control task traffic control dynam channel alloc properti unlik state mode cannot directli observ current mode estim accord past state transit analog elev control exampl passeng arriv rate pattern infer occurr pick drop request properti mode transit stochast event independ control system respons elev control problem instanc event chang current mode environ could emerg meet administr offic tea break staff th floor obvious elev respons control occurr event properti mode transit rel infrequ word mode like retain time switch anoth one consid emerg meet exampl employe differ floor take time arriv administr offic thu would gener similar traffic pattern drop request floor period time properti number state often substanti larger number mode common properti mani real world applic elev exampl state space compris possibl combin elev posit pick drop request certainli would huge hand mode space could small instanc elev control system simpli three mode describ approxim realiti base properti environ model propos introduc mode variabl captur environment chang mode specifi mdp henc complet determin current state transit function reward function properti mode howev directli observ properti evolv time accord markov process properti model therefor call hidden mode model note model impos constraint satisfi properti word hidden mode model work environ without two properti nevertheless shown later properti improv learn practic relat work hidden mode model relat nonstationari model propos dayan sejnowski although model restrict term represent power involv much fewer paramet thu easier learn besid number possibl mode assum knowledg environ model nonstationari reinforc learn way environ dynam chang dayan sejnowski hand assum one know precis environ dynam chang hidden mode model also view special case hidden state model partial observ markov decis process pomdp shown later hidden mode model alway repres hidden state model state augment nevertheless model hidden mode environ via hidden state model unnecessarili increas problem complex paper convers former latter also briefli discuss focu two approach rl model base rl first acquir environ model optim polici deriv model free rl contrari learn optim polici directli interact environ paper concern first part model base approach hidden mode model learn experi address polici learn problem separ paper hidden mode markov decis process section present hidden mode model basic hidden mode model defin finit set mdp share state space action space possibl differ transit function reward function mdp correspond differ mode system oper state complet observ transit govern mdp contrast mode directli observ transit control markov chain refer process hidden mode markov decis process hm mdp exampl hm mdp shown figur time es mode ff ff actlol state mode state action hm mdp evolut hm mdp arc indic depend variabl figur hm mdp formal hm mdp tupl repres set mode state action respect mode transit function map mode fix probabl zm state transit function defin transit probabl ym state given mode action stochast reward function return reward mean valu rm ii denot prior probabl mode state respect evolut mode state time depict figur choi yeung zhang hm mdp subclass pomdp word former reformul special case latter specif one may take order pair mode observ state hm mdp hidden state pomdp observ state former observ latter suppos observ state mode rn respect two hmmdp state togeth correspond mode form two hidden state ra pomdp counterpart transit probabl ra simpli mode transit probabl xm multipli state transit probabl ym mode state action hm mdp equival pomdp thu observ mn hidden state sinc state transit probabl collaps mode transit probabl paramet share number paramet hm mdp mk much less correspond pomdp learn hidden mode model two way learn hidden mode model one may learn either hm mdp equival pomdp instead pomdp model learn via variant baum welch algorithm pomdp baum welch algorithm requir time storag learn mode nstate action hm mdp given data item similar idea appli learn hm mdp intuit one estim model paramet base expect count mode transit comput set auxiliari variabl major differ origin algorithm consecut state transit rather observ consid addit effort thu need handl boundari case hm mdp baum welch algorithm describ figur empir studi section empir examin pomdp baum welch hm mdp baumwelch algorithm experi base variou randomli gener model real world environ conduct result quit consist illustr simpl traffic control problem present problem one direct two way traffic block car two differ direct left right forc share remain road coordin traffic two traffic light equip sensor set system two possibl action either signal car left car right pass simplic assum discret time step uniform speed car system possibl state correspond combin whether car wait left right direct stop signal posit previou time step traffic mode first one car wait left right direct probabl respect second mode probabl revers last one probabl addit mode transit probabl cost result xchrisman algorithm also attempt learn minim possibl number state paper concern learn model paramet environ model nonstationari reinforc learn given collect data initi model paramet vector repeat comput forward variabl ri yi al ieq xij yj st st ieq vieq vieq comput backward variabl xo ieq vieq vieq comput auxiliari variabl gt vi jeq comput new model paramet maxi ioi oil figur hm mdp baum welch algorithm car wait either side experi run initi model data set variou size algorithm iter maximum chang model paramet less threshold experi repeat time differ random seed order comput median learn model compar pomdp form use kullback leibler kl distanc total cpu run time sun ultra workstat measur figur report result gener speak algorithm learn accur environ model data size increas figur result expect algorithm statist base henc perform reli larg data size train data size small algorithm perform poorli howev data size increas hm mdp baum welch improv substanti faster pomdp baum welch hm mdp gener consist fewer free choi yeung zhang error transit function requir learn time figur empir result model learn paramet pomdp counterpart hm mdp baum welch also run much faster pomdp baum welch figur hold gener reason discuss note comput time necessarili monoton increas data size total comput depend data size also number iter execut experi notic number iter tend decreas data size increas larger model also test hm mdp baum welch abl learn model sever hundr state mode pomdp baum welch unabl complet learn reason time addit experiment result found discuss futur work use model depend valid assumpt made discuss assumpt hm mdp shed light applic real world nonstationari task possibl extens also discuss model nonstationari environ number distinct mdp mdp flexibl framework wide adopt variou applic model nonstationari environ distinct mdp natur extens task compar pomdp model comprehens mdp natur describ mode environ moreov formul facilit incorpor prior knowledg model initi step state directli observ mode complet observ state help infer current mode also possibl extend mode allow partial observ state case extend model would equival represent power pomdp could prove easili show reformul two model direct environ model nonstationari reinforc learn mode chang independ agent respons properti may alway hold real world task applic agent action might affect state well environ mode case mdp use govern mode transit process mode transit rel infrequ properti gener hold mani applic model howev limit condit tri appli model learn algorithm problem properti hold find model still outperform pomdp although requir data size typic larger model number state substanti larger number mode key properti significantli reduc number paramet hm mdp compar pomdp practic introduct mode suffici boost system perform mode might help littl thu trade perform respons time must decid addit issu need address first effici algorithm polici learn requir although principl achiev indirectli via pomdp algorithm effici algorithm base model base approach possibl address issu separ paper next number mode current assum known investig remov limit final explor exploit issu current ignor futur work address import issu appli model real world nonstationari task