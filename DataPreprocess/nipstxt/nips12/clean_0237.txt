abstract gener recent formal describ dynam supervis learn layer neural network regim data recycl inevit case noisi teacher theori gener reliabl predict evolut time train gener error extend class mathemat solvabl learn process larg neural network situat overfit occur introduct tool statist mechan use success last decad studi dynam learn layer neural network review see simplest theori result upon assum data set much larger number weight updat made rule recycl ensur distribut relev gaussian unfortun term applic term mathemat interest regim relev one complic peculiar dynam learn aris precis due data recycl creat system possibl improv perform memor answer rather learn underli rule dynam learn restrict train set first studi analyt linear learn rule system binari weight latter studi ahead time get attent deserv stage even simpler learn dynam without data recycl yet studi recent attent move back dynam learn recycl regim studi aim develop gener theori find exact solut special case gener theori publish far common yet consid realiz scenario rule learn implement student overfit could yet occur next hurdl restrict train set combin unrealiz rule turn non typic solvabl case involv hebbian rule noisi revers wedg teacher recent caviti method use build gener theori yet batch learn paper gener gener theori launch appli arbitrari learn rule case noisi teacher mirror close present deal simpler case nois free teacher refer background read idea behind formal coolen mace definit restrict simplic perceptron student perceptron oper linear separ parametris weight vector sgn aim emul teacher erat similar rule howev character variabl weight vector drawn random distribut output nois gaussian weight nois ex paramet control amount teacher nois nois free teacher recov limit student modifi iter use exampl input vector drawn random fix randomli compos train set contain vector correspond valu teacher output choos teacher nois consist answer given teacher question remain particular question appear learn process thu sgn teacher weight vector drawn randomli independ gener train set accordingli bp consist teacher nois natur term applic prerequisit overfit phenomena averag train set denot lb averag possibl input vector analyz two class learn rule form aj line aj batch aj line learn one draw step question answer pair random train set batch learn one iter determinist map averag data train set perform measur train gener error defin follow step function et eg introduc macroscop observ taylor present problem gener elimin technic subtleti assum number argument evalu go infin limit cx taken deriv macroscop law upon gener calcul one find line learn xdydz xo xdydz dt xdydz lvr dx dy dz dx dy dz xp dx dy dz supervis learn restrict train set complex problem concentr green function lim oo ill diy involv condit averag form cwr fdj pt jiq pt yz pt jiq dj pt rlxyz pt weight probabl densiti time solut use gener cx perform measur time et dxdydz xz eg arcco expans equat power retain term linear give correspond equat describ batch learn far analysi exact closur macroscop law close macroscop law make two key assumpt underli dynam replica theori cx macroscop observ obey close dynam equat ii equat self averag respect specif realiz impli probabl variat within subshel either absent irrelev macroscop law may thu make simplest choic pt jiq pt jlo hs procedur lead exact law observ inde obey close equat imum engopi approxim ii allow us averag macroscop law train set observ simul proven use formal assumpt result closur sinc green function written term final ingredi dynam replica theo averag fraction replica ident aj jlbl jid lim dj willi problem reduc calcul non trivial integr averag one find zli exp sho hand dy dy dydxdz zli write result macroscop law case output nois follow compact way vez zli dx zli zli ry wy ffx rw solut time follow form xs coolen mace find function replica symmetr ansatz requir solv saddl point problem scalar observ two function zli upon introduc qq fax xli ebxsf dx xli bx fdx xli saddl point equat acquir form xli qq ry qq qq dyd equat determin xli sguctur cogespond singl equat proof appli solut xli given physic rang uniqu function given ds qq zli ad work predict equat gener cpu intens mainli due function saddl point equat solv time step howev one construct use approxim theori increas complex larg approxim give simplest theori without saddl point equat ii condit gaussian approxim depend moment iii anneal approxim function saddl point equat benchmark test limit first show limit theori reduc simpl formal infinit train set work noisi teacher upon make ansatz xli xli ryi one find xli xli ry insert ansatz follow rearrang term usag express show satisfi remain equat involv averag gaussian distribut inde reduc ld ffq ld cttr next turn limit restrict ain set nois free teacher show eow reproduc focal follow ansatz xli xli zli xli insert show solut fo inde solv equat give xli xli leav us exactli formal describ case nois free teacher re ict ain set ap new term due presenc weight decay absent supervis learn restrict train set ot ot figur line hebbian learn condit gaussian approxim versu exact solut left right solid line approxim theori dash line exact result upper curv eg function time two theori agre lower curv et function time benchmark test hebbian learn special case hebbian learn sgn solv exactli time arbitrari provid yet anoth excel benchmark theori batch execut hebbian learn macroscop law obtain upon expand retain term linear integr done equat solv explicitli result vr ro nvt qo nvt nvt nvt ro rt rt xli ry sgnci av cq result turn follow peffom mereurn eg arcco affl lylr et erf comprison exact solut calculamd along line equival obtain upon put show express exact line execut cannot yet solv function saddl point equmion gener howev analyt predict still ex act om qoe nvt fax xli wr rtl aq comparison result show express thu also eg fulli exact time observ involv includ train error easili solv equat instead use condit gaussian approxim found adequ noiseless hebbian case result shown figur agreement reason significantli less appar teacher nois add deform field distribut away gaussian shape coolen mac ooooo figur larg approxim versu numer simul top row perceptron rule bottom row adatron rule left train error et generalis error function time line approxim theori marker simul circl et squar eg right joint distribut student field teacher nois fdi upper lower histogram simul line approxim theori non linear learn rule theori versu simul case non linear learn rule exact solut known test formal leav numer simul yardstick evalu numer larg approxim theori perceptron learn sgn zz adatron learn sgn lzlo zz approxim lead follow fulli explicit equat field distribut xli dx ly xli wy ryl rw dydx xlylg xp xli dydx xli ap iiy oyax xp xli ix supervis learn restrict train set short hand fdx xpe xli result comparison shown figur note et increas monoton eg decreas monoton nois free formal larg approxim appear captur domin term predict power theori mainli limit numer constraint instanc adatron learn rule gener singular distribut especi small although predict theori almost imposs captur numer solut discuss shown recent theori describ dynam supervis learn restrict train set design appli data recycl regim arbitrari onlin batch learn rule larg layer neural network gener success order deal also noisi teacher gener approach joint distribut field student clean teacher noisi teacher taken dynam order paramet addit convent observ order paramet set deriv gener error eg train error et follow prescript dynam replica theori one find diffus equat evalu make replica symmetr ansatz carri sever orthogon benchmark test theori cx data recycl theori exact ii teacher nois theori reduc iii batch hebbian learn theori exact line hebbian learn theori exact regard predict eg depend condit averag fdz zp zli time crude approxim equat alreadi give reason agreement exact result et non linear learn rule perceptron adatron compar numer solut simpl larg aproxim equat numer simul found satisfactori agreement paper preliminari present result obtain second stage research programm aim extend theoret tool arena learn dynam build ongo work aim systemat applic theori approxim variou type non linear learn rule gener theori multi layer network