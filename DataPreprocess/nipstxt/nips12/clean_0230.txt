abstract new function paramet model select support vector machin introduc base concept span support vector rescal featur space shown use function one predict best choic paramet model rel qualiti perform valu paramet introduct support vector machin svm implement follow idea map input vector high dimension featur space maxim margin hyperplan construct shown train data separ error rate svm character radiu smallest sphere contain train data margin distanc hyperplan closest train vector featur space function estim vc dimens hyperplan separ data given margin perform map calcul svm techniqu one use posit definit kernel specifi inner product featur space exampl kernel radial basi function rbf iix kernel free paramet gener kernel requir paramet set treat noisi data svm anoth paramet penal train error also need set problem choos valu paramet minim expect test error call model select problem shown paramet kernel minim function provid good choic model minimum function coincid minimum test error howev shape curv differ articl introduc refin function specifi best choic paramet paramet kernel paramet penal train error also produc curv better reflect actual error rate model select support vector machin paper organ follow section describ basic svm section introduc new function base concept span support vector section consid idea rescal data featur space section discuss experi model select function support vector learn introduc standard notat svm complet descript see let xi yi set train exampl xi belong class label yi decis function given svm coeffici obtain maxim follow function ai aiajyiyjk xi xj constraint eaiyi ando ai constant control tradeoff complex decis function number train exampl misclassifi svm linear maxim margin classifi high dimension featur space data map non linear function xi xj xi xj point xi ai call support vector distinguish ai ai call respect support vector first second categori predict use span support vector result introduc section base leav one cross valid estim procedur usual use estim probabl test error learn algorithm leav one procedur leav one procedur consist remov train data one element construct decis rule basi remain train data test remov element fashion one test element train data use differ decis rule let us denot number error leav one procedur xl known leav one procedur give almost unbias estim probabl test error expect test error machin train exampl equal expect provid analysi number error made leav one procedur purpos introduc new concept call span support vector chapel vapnik span support vector sinc result present section depend featur space consid without loss gener linear svm xi xi xj suppos solut optim problem fix support vector xp defin set ap constrain linear combin support vector first categori xi ap ixi ot yiypotp note hi less also defin quantiti call span support vector xp minimum distanc xp set see figur xp ap min figur three support vector al set ai semi open dash line shown set empti xp ap dsv dsv diamet smallest sphere contain support vector intuit smaller xp less like leav one procedur make error vector xp formal follow theorem hold theorem leav one procedur support vector xp correspond recogn incorrectli follow inequ hold ap max theorem impli separ case number error made leav one procedur bound follow xe ye maxv pd maxv vd av alreadi ep improv compar function sinc dsv depend geometri support vector valu span much less diamet dsv support vector even equal zero go assumpt set support vector chang leav one procedur lead us follow theorem model select support vector machin theorem set support vector first second categori remain leav one procedur support vector xp follow equal hold yp xp fp xp fo fp decis function given svm train respect whole train set point xp remov proof theorem follow one theorem assumpt set support vector chang leav one procedur obvious satisfi case nevertheless proport point violat assumpt usual small compar number support vector case theorem provid good approxim result leav one procedur point experi see section figur alreadi notic larger ap import decis function support vector xp thu surpris remov point xp caus chang decis function proport lagrang multipli ap kind result theorem also deriv svm without threshold follow inequ deriv yp xp fp xp vk xp xp span take account geometri support vector order get precis notion import given point previou theorem enabl us comput number error made leav oneout procedur corollari assumpt theorem test error predict given leav one procedur yl ye card ap ypf xp note point support vector correctli classifi leav one procedur therefor tt defin number error leav one procedur entir train set assumpt theorem box constraint definit ap remov moreov consid hyperplan pass origin constraint hi also remov therefor assumpt comput span unconstrain minim quadrat form done analyt support vector first categori lead close form ksv pp ksv matrix dot product support vector first categori similar result also obtain section use span rule model select separ nonsepar case rescal alreadi mention function bound vc dimens linear margin classifi bound tight data almost fill surfac sphere enclos train data data lie flat ellipsoid bound poor sinc radiu sphere take account compon largest deviat idea present make rescal data featur space radiu sphere stay constant margin increas appli bound rescal data hyperplan chapel vapnik let us first consid linear svm without map high dimension space rescal achiev comput covari matrix data rescal accord eigenvalu suppos data center let qol qo normal eigenvector covari matrix data comput smallest enclos box contain data center origin whose edg parallel qol qo box approxim smallest enclos ellipsoid length edg direct qo max ixi qo rescal consist follow diagon transform dx let us consid xi dw decis function chang transform sinc xi data fill box side length thu function replac sinc rescal data box actual estim radiu enclos ball use oo norm instead classic norm theoret work need done justifi chang norm non linear case note even map data high dimension featur space lie linear subspac span data thu number train data larg work subspac dimens purpos one use tool kernel pca matrix normal eigenvector gram matrix kij xi xj eigenvalu dot product xi qo replac qo becom aikyioti thu still achiev diagon transform final function becom miax aiki experi check new method perform two seri experi one concern choic width rbf kernel linearli separ databas postal databas dataset consist handwritten digit size test set exampl follow split train set subset train exampl task consist separ digit error bar figur standard deviat trial anoth experi tri choos optim valu noisi databas breast cancer databas dataset split randomli time train set contain exampl test set contain exampl section describ experi model select use span rule separ case non separ one section show vc bound model select separ case without rescal model select use span rule section use predict test error deriv span rule model select figur show test error predict given span differ valu width cr rbf kernel postal databas figur plot function differ valu breast cancer databas see method predict correct valu minimum moreov predict accur curv almost ident avail http horn first imd de raetsch data breast cancer model select support vector machin test err span pred ct log sigma choic cr postal databas ttt log st erro span pred ction choic breast cancer databas figur test error predict use span rule comput span rule involv comput span everi support vector note howev interest inequ vf xv rather exact valu span thu minim sv xv av find point av xv vf xv ct stop minim point correctli classifi leav one procedur turn experi time requir comput span prohibit sinc train time noteworthi extens applic span concept denot one hyperparamet kernel deriv ok comput possibl comput analyt deriv upper bound number error made leav one procedur see theorem provid us power techniqu model select inde initi approach choos valu width cr rbf kernel accord minimum span rule case hyperparamt possibl tri differ valu sever hyperparamet exampl one cr per compon possibl exhaust search possibl valu hyperparamet nevertheless previou remark enabl us find optim valu classic gradient descent approach preliminari result seem show use approach previous mention kernel improv test error significant vc dimens rescal section perform model select postal databas use function rescal version figur show valu classic bound differ valu bound predict correct valu minimum reflect actual test error easili understand sinc larg valu data input space tend map flat ellipsoid featur space fact taken account figur show perform rescal data manag much tighter bound curv reflect actual test error given figur chapel vapnik ooo vc dir ensi log sigma without rescal dimens scalincj log sigma rescal figur bound vc dimens differ valu postal databas shape curv rescal similar test error figur conclus paper introduc two new techniqu model select svm one base span base rescal data featur space demonstr use techniqu one predict optim valu paramet model evalu rel perform differ valu paramet function also lead new learn techniqu establish gener abil due margin acknowledg author would like thank jason weston patrick haffner helpful discuss comment