abstract paper propos full bayesian model neural network model treat model dimens number neuron model paramet regularis paramet nois paramet random variabl need estim propos revers jump markov chain mont carlo mcmc method perform necessari comput find result better previous report one also appear robust respect prior specif moreov present geometr converg theorem algorithm introduct earli nineti buntin weigend macl show principl bayesian learn approach neural network lead mani improv particular macl show approxim distribut weight gaussian adopt smooth prior possibl obtain estim weight output varianc automat set regularis coeffici neal cast net much introduc advanc bayesian simul method specif hybrid mont carlo method analysi neural network bayesian sequenti mont carlo method also shown provid good train result especi time vari scenario recent rio insua milllet holm mallick address issu select number hidden neuron grow prune algorithm bayesian perspect particular appli revers jump markov chain mont carlo mcmc algorithm green feed forward sigmoid network radial basi function rbf network obtain joint estim number neuron weight also appli revers jump mcmc simul algorithm rbf network comput joint posterior distribut radial basi paramet number basi function howev advanc area research two import direct firstli propos full hierarch prior rbf network authorship base alphabet order andrieu freita doucet adopt full bayesian model account model order uncertainti regularis show result appear robust respect prior specif secondli present geometr converg theorem algorithm complex problem allow comprehens discuss short paper therefor focus describ object bayesian model converg theorem result reader encourag consult technic report result implement detail problem statement mani physic process may describ follow nonlinear multivari input output map yt xt nt xt ir correspond group input variabl yt target variabl unknown nois process index variabl data context learn problem involv comput approxim function estim characterist nois process given set input output observ xl yl typic exampl includ regress yl continu classif correspond group class nonlinear dynam system identif input target correspond sever delay version signal consider adopt approxim scheme holm mallick consist mixtur rbf linear regress term yet work easili extend regress model precis model yt aj llx tjll ii ii denot distanc metric usual euclidean mahalanobi ird denot th rbf centr model rbf aj ir th rbf amplitud ir ir ir linear regress paramet nois sequenc nt irc assum zero mean white gaussian import mention although explicitli indic depend nt paramet inde affect valu conveni express approxim model vector matrix form yl yl yn yn xl xl xn xn xl xl ak ak nl softwar avail http www cs berkeley edu jfgf yl matrix number data number output adopt notat yl yl denot observ correspond th output th column simplifi notat equival one index appear impli refer possibl valu similarli equival yl favour shorter notat adopt longer notat avoid ambigu emphasis certain depend robust full bayesian method neural network nois process assum normal distribut nt jv cr shorter notat nt assum number rbf paramet th er unknown given data set object estim ok bayesian model aim follow bayesian approach unknown regard drawn appropri prior distribut prior reflect degre belief relev valu quantiti furthermor adopt hierarch prior structur enabl us treat prior paramet hyper paramet random variabl drawn suitabl distribut hyper prior instead fix hyper paramet arbitrarili acknowledg inher uncertainti think valu devis probabilist model deal uncertainti abl implement estim techniqu robust specif hyper prior overal paramet space written finit union subkmax ok ira space uk ok kmax hyper parmet space element discuss end section space radial basi cemr defin compact set includ input data min xl tei xl tei ei xl min xl denot euclidean distanc th dimens input user specifi paramet need consid wish place basi function outsid region input data lie allow includ space input data extend factor proport spread input data hyper volum space ei imum number basi function defin kma also defin sumption independ output given likelihood ylk approxim model describ previou section exp yl al yl al assum follow structur prior distribut al lk scale paramet assum independ hyperparamet la independ distribut accord conjug invers gamma prior distri wo obtain je ey unbut inform prior given prior distribut ln tr xrisilml exp andrieu freita doucet im denot ident matrix size ul indic function set otherwis prior model order distribut kla truncat poisson distribut condit upon rbf centr uniformli distribut final condit upon coeffici ot assum zero mean gaussian varianc ier hyper paramet ir ir respect interpret expect signal nois ratio expect number radial basi assum independ moreov iic scale paramet ascrib vagu conjug prior densiti aa fia aa fia varianc hyper prior aa infinit appli method set uninform conjug prior estim infer aim bayesian infer base joint posterior distribut obtain bay theorem aim estim joint distribut standard probabl marginalis transform techniqu one theoret obtain posterior featur interest propos use revers jump mcmc method perform necessari comput see detail mcmc techniqu introduc mid statist physic start appear field appli statist signal process neural network key idea build ergod markov chain whose equilibrium distribut desir posterior distribut weak addit assumpt sampl gener markov chain asymptot distribut accord posterior distribut thu allow easi evalu posterior featur interest exampl jlx addit obtain predict yn llxi yl integr nuisanc paramet accord bay theorem obtain posterior distribut follow blx ylk case integr respect gaussian distribut invers gamma distribut obtain follow express respect posterior yl ipi kyl im robust full bayesian method neural network worth notic posterior distribut highli non linear rbf centr express klx cannot obtain close form geometr converg theorem easi prove revers jump mcmc algorithm appli model converg markov chain ergod present stronger result name converg requir posterior distribut geometr rate theorem let kernel describ section biliti distribut markov chain whose transit markov chain converg proba furthermor converg occur geometr rate almost everi initi point lt exist function initi state co constant tv xj distribut ii litv total variat norm proof see corollari iter one sampl nuisanc paramet distribut seri ier converg ge ometr toward er rate demonstr robot arm data data often use benchmark compar learn algorithm involv implement model map joint angl robot arm xl posit end arm data gener follow model co co sin xx sin ei af use first observ data set train model last observ test simul chose use cubic basi function figur show plot train data contour train test data contour plot also includ typic approxim obtain use algorithm chose uninform prior paramet hyper paramet tabl demonstr robust algorithm chose differ valu fi critic hyper paramet quantifi mean spread obtain mean squar error probabl cr cr shown figur clearli indic algorithm robust respect prior specif mean squar error magnitud one report research slightli better moreov algorithm lead parsimoni model one previous report ath robot arm data set found david mackay home page http wol ra phi cam ac uk mackay andrieu freita doucet xl xl figur top plot show train data surfac correspond coordin robot arm posit middl bottom plot show train valid data respect rbf network map tabl simul paramet mean squar test error fi ms error conclus present gener methodolog estim jointli nois varianc paramet number paramet rbf model adopt bayesian model revers jump mcmc algorithm perform necessari integr demonstr method accur contrari previou report result experi indic model robust respect specif prior addit obtain parsimoni rbf network better approxim error one previous report literatur mani avenu research includ estim type basi function perform input variabl select consid nois model extend framework sequenti scenario possibl solut first problem formul use revers jump mcmc flamework variabl select scheme also implement via revers jump mcmc algorithm present work sequenti version algorithm allow us perform model select non stationari environ