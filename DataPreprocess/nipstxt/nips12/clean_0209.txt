abstract paper present novel practic framework bayesian model averag model select probabilist graphic model approach approxim full posterior distribut model paramet structur well latent variabl analyt manner posterior fall free form optim procedur natur incorpor conjug prior unlik larg sampl approxim posterior gener nongaussian hessian need comput predict quantiti obtain analyt result algorithm gener standard expect maxim algorithm converg guarante demonstr approach appli larg class model sever domain includ mixtur model sourc separ introduct standard method learn graphic model data maximum likelihood ml given train dataset ml estim singl optim valu model paramet within fix graph structur howev nil well known tendenc overfit data overfit becom sever complex model involv high dimension real world data imag speech text anoth problem nil prefer complex model sinc paramet fit data better henc nil cannot optim model structur bayesian framework provid principl solut problem rather focus singl model bayesian consid whole finit infinit class model model posterior probabl given dataset comput predict test data made averag predict individu model weight posterior thu bayesian framework avoid overfit integr paramet addit complex model automat penal assign lower posterior probabl therefor optim structur identifi unfortun comput bayesian framework intract even use term model refer collect paramet structur attia simpl case factor analysi see exist approxim method fall two class markov chain mont carlo method larg sampl method laplac approxim mcmc method attempt achiev exact result typic requir vast comput resourc becom impract complex model high data dimens larg sampl method tractabl typic make drastic approxim model posterior paramet normal even paramet posit definit covari matric addit requir comput hessian may becom quit intens paper present variat bay vb practic framework bayesian comput graphic model vb draw togeth variat idea intract latent variabl model bayesian infer turn draw work framework facilit analyt calcul posterior distribut hidden variabl paramet structur posterior fall free form optim procedur natur incorpor conjug prior emerg standard form one normal comput via iter algorithm close relat expect maxim em whose converg guarante hessian need comput addit averag model comput predict quantiti perform analyt model select done use posterior structur particular bic mdl criteria emerg limit case gener framework restrict attent paper direct acycl graph dag bayesian network let yl denot visibl data node run data instanc let xx denot hidden node let denot paramet simpli addit hidden node distribut model fix structur fulli defin joint distribut im dag joint factor node ip ui pai oi ui pai set parent ui oi parametr edg direct toward ui addit usual assum independ instanc np yn xn shall also consid set structur control number hidden node function form depend ui pai includ rang valu assum node number compon mixtur model associ set structur structur prior margin likelihood posterior paramet fix structur interest two quantiti first paramet posterior distribut second margin likelihood im also known evid assign structur data follow refer usual omit alway impli quantiti obtain joint model hidden node requir comput often perform analyt howev presenc hidden node quantiti becom comput intract shall approxim use variat approach follow consid joint posterior hidden node paramet sinc intract consid variat posterior restrict factor form xli given data paramet hidden node independ variat baysjan framework graphic model restrict key make approxim tractabl notic requir complet factor paramet hidden node may still correl amongst comput optim cost function rm defin log logp penal complex model see vb object function penal complex use rewrit logp kl ii averag first term taken term correspond averag likelihood second term kl distanc prior posterior paramet number paramet increas kl distanc follow consequ reduc penal likelihood interpret becom transpar larg sampl limit oe paramet posterior sharpli peak probabl valu shown kl penalti reduc log linear number paramet structur rm correspond precis bayesian inform criterion bic minimum descript length criterion mdl see thu popular model select criteria follow limit case vb framework free form optim em like algorithm rather assum specif parametr form posterior let fall free form optim vb object function result iter algorithm directli analog ordinari em step comput posterior hidden node solv sq get ogp xio averag taken step rather optim paramet comput posterior distribut paramet solv get gp xl xp averag taken concept conjug prior becom use denot exponenti term choos prior famili distribut belong famili said conjug procedur allow us select prior fairli larg famili distribut includ non inform one limit case first inequ hold arbitrari follow jensen inequ see becom equal true posterior note alway understood includ condit sinc bound margin likelihood obtain optim posterior maxim shown equival minim kl distanc true posterior thu optim produc best approxim true posterior within space distribut satisfi well tightest lower bound true margin likelihood attia thu compromis gener facilit mathemat simplic eleg particular learn vb framework simpli amount updat hyperparamet transform prior paramet posterior paramet point use conjug prior widespread statist far could appli model node visibl structur posterior comput exploit jensen inequ defin gener object function memq ogp logp comput structur posterior obtain free form optim cr henc prior assumpt likelihood differ structur encod prior affect select optim model structur perform accord predict quantiti ultim goal bayesian infer estim predict quantiti densiti regress function gener quantiti comput averag model weight model posterior vb framework exact model averag approxim replac true posterior variat densiti estim exampl densiti assign new data point given yli fdo oli situat sourc separ estim hidden node valu new data may requir relev quantiti condit like valu hidden node extract vb approxim cr fdo oiy variat bay mixtur model mixtur model investig analyz extens mani year howev well known problem regular likelihood diverg determin requir number mixtur compon still open wherea theori bayesian approach provid solut satisfactori practic algorithm emerg applic involv sampl techniqu approxim method problem present solut provid vb consid model form yn yn sn sn denot nth observ data vector denot hidden compon gener compon label structur paramet denot number compon wherea approach appli arbitrari model simplic consid normal compon distribut yn sn jv rs mean rs precis invers covari matrix mix proport rs hindsight use conjug prior paramet rs rs mix proport jointli dirichlet rs mean condit precis normal rs precis wishart rs find paramet posterior fix variat baysian framework graphic model factor rs posterior obtain follow iter algorithm term vb mog step comput respons instanc use sn yn tf note ri express resembl respons ordinari ml differ stem integr paramet special quantiti log log rs log log ei log dlog dlogf dx digaroma function averag taken paramet describ step comput paramet posterior two stage first comput quantiti es cs nss stage ident step ordinari em produc new paramet vb howev quantiti help character new paramet posterior posterior function ident prior differ paramet valu mix proport jointli dirichlet rs mean normal tq if ps precis wishart fs bs posterior paramet updat second stage use simpl rule ao opo po po final valu posterior paramet form output vb mog remark wherea specif assumpt made paramet posterior emerg suitabl non trivial gener non normal function form comput overhead vb mog compar em minim coverl paramet posterior vbmog reduc em regular prior vb mog diverg problem stabil guarante exist object function final approxim margin likelihood rm requir optim number compon via also obtain close form omit predict densiti use posterior integr paramet show densiti assign model new data vector mixtur student distribut st ylp compon co mean covari co proport reduc nonlinear regress may divid data vector input output part yi yo use model estim regress function yi error sphere may extract condit ps whmh also turn mixtur student distribut mean linear covari mix proport nonlinear given term posterior paramet attia buffalo post offic digit misclassif rate histogram figur vb mog appli handwritten digit recognit vb mog appli boston hous dataset uci machin learn repositori input use predict singl output hous price random divis dataset train test point use result averag mse wherea discrimin method nevertheless competit breiman bag techniqu use regress tree mse comparison em achiev mse classif separ paramet posterior comput class train dataset yc test data vector classifi accord condit yc form ident depend paramet multipli rel size yc vb mog appli buffalo post offic dataset contain exampl digit digit gray level pixel array see exampl fig left use random digit batch train separ batch test averag misclassif rate obtain use compon em achiev misclassif histogram vb solid em dash shown fig right vb intract model blind separ exampl discuss far assum free form optim vb object function feasibl unfortun mani interest model particular model ordinari ml intract case model modifi vb procedur follow specifi parametr function form posterior hidden node optim paramet spirit let paramet posterior fall free form optim illustr approach context blind sourc separ bss problem see problem describ yn hxn un xn unobserv dim sourc vector instanc unknown mix matrix nois un normal distribut unknown precis hi task construct sourc estim observ dim data sourc independ non normal distribut assum high kurtosi distribut oc cosh appropri model speech sourc one import heretofor unresolv problem bss determin number rn sourc data anoth avoid overfit mix matrix problem typic ml algorithm remedi use vb non normal natur sourc render sourc posterior intract even bayesian treatment use normal variat posterior iina xn pn rn instanc depend mean precis mix matrix posterior emerg normal simplic optim rather integr result vb bss algorithm run follow variat baysjan framework graphic model looo log pr sourc reconstruct error snr db figur applic vb blind sourc separ algorithm see text step optim variat mean pn iter converg fix point equat afit yn fipn tanhpn pn sourc covari condit data variat precis matrix turn independ ta step updat mean precis posterior rule omit algorithm appli dim data gener linearli mix mseclong speech music signal obtain commerci cd gaussian nois ad differ snr level uniform structur prior use result posterior number sourc fig left peak correct valu sourc reconstruct test data via log reconstruct error plot vs snr fig right solid ml error includ model averag also shown dash larger reflect overfit conclus vb framework applic larg class graphic model fact may integr junction tree algorithm produc gener infer engin minim overhead compar ml one dirichlet normal wishart posterior special model treat emerg gener featur current research effort includ applic multinomi model learn structur complex dynam probabilist network acknowledg thank matt beal peter dayan david mackay carl rasmussen especi zoubin ghahramani import discuss