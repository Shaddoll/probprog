abstract develop hierarchical generative model study cue combination model maps global shape parameter local cuespecific parameters turn generate intensity image inferring shape images achieved inverting model inference produces probability distribution level using distributions rather single value underlying variables stage preserves information validity local cue given image allows model unlike standard combination models adaptively weight cue based general cue reliability specific image context describe results cue combination psychophysics experiment conducted allows direct comparison model model provides good fit data natural account interesting aspects cue combination understanding cue combination fundamental step developing computational models visual perception many aspects perception naturally involve multiple cues binocular stereo motion texture shading often formulated problem inferring estimating relevant parameter depth shape position combining estimates individual cues important finding psychophysical studies cue combination cues vary degree used different visual environments weights assigned estimates derived particular cue seem reflect estimated reliability current scene viewing conditions example motion stereo weighted approximately equally near distances motion weighted far distances presumably due distance limits binocular disparity experiments also found weightings sensitive image manipulations cue weakened adding noise uncontaminated cue utilized making depth judgments recent study shown observers adjust weighting assign cue based relative utility particular task experiments identify two types information determine relative cue weightings cue reliability relative utility context task general viewing conditions region informativeness cue information available locally given image central question computational models cue combination concerns forms uncertainty combined propose hierarchical generative yang zemel model generative models rich history cue combination underlie models bayesian perception developed area novelty generative model proposed lies hierarchical nature use distributions throughout allows context dependent imagespecific uncertainty combined principled manner aims paper dual develop combination model incorporates cue reliability region informativeness estimated across within images use model account data provide predictions psychophysical experiments another motivation approach stems recent probabilistic framework posits every step processing entails representation entire probability distribution rather single value relevant underlying variable use separate local probability distributions cue estimated directly image combination entails transforming representations integrating distributions across space cues taking across within image uncertainty account image generation paper study case combining shading texture standard shapefrom shading models exclude texture standard shape texture models exclude shading experimental results computational arguments supported strong interaction cues model accounting interaction yet worked shape used experiments simple surface lyl height zy plane shape parameter image formation model hierarchical generative model see figure top layer contains global parameter second layer contains local shading texture parameters si indexes image regions generation local cues global parameter intended allow local uncertainties introduced separately cues models specific conditions realistic images shading uncertainty due shadows specularities texture uncertainty prior assumptions isotropicity violated introduce uncertainty adding independent local noise underlying shape parameter manipulation less realistic easier control local shading local texture image figure left generative model image formation right two sample images generated image formation procedure left rt right rt local cues sampled gaussian distributions silb iv rt describe local cue parameters depend managing uncertainty cue combination shape parameter rr rrt represent degree noise cue paper simplify generation process set two surfaces generated essentially two separate noisy local versions intensity image combines surfaces set intensity texsels sampled uniform distribution mapped onto texture surface projected onto image plane orthogonal projection intensity surface pixels contained within texsels determined generated shading surface using lambertjan shading image composed non overlapping regions contains pixels figure shows two images generated procedure combination model create combination recognition model inverting generative model figure infer shape parameter image important aspect combination model use distributions represent parameter estimates stage preserves uncertainty information level allows play role subsequent inference overall goal combination infer estimate given image derive main inference equation using bayesian integration distributions bi bis ti dsdt ti bls tib tib sib tib simplify two components assumed prior uniform conditionally independent given given image third assumption dubious essential model discussed consider two components turn obtaining local cue specific representations image one component inference equation tii describes local cuedependent information particular image first define intermediate representations dependent shading texture cues respectively shading representation curvature horizontal section texture representation cosine surface slant note variables match used generative model ideally could used cue dependent variables generating images proved difficult image pre processing must take place order estimate values uncertainties particular local variables approach adopt involves simple statistical matching procedure similar nearest neighbors applied local image patches applying gaussian smoothing band pass filtering image two representations patch obtained using separate shading texture filters shading image patches represented forming histogram texture patch represented mean standard deviation amplitude gabor filter responses scales orientations representation shading patch compared database similar gang zemel patch representations entries shading database formed first selecting particular value try generating image patch applying appropriate filters thus fib noise level rr known entry allowing estimate variables new patch formed linear combination entries similar representations analogous procedure utilizing separate database allows uncertainty estimate derived texture databases different rr pairs samples pair based procedure obtain image patch mean values uncertainty values si ti determine approximated gaussians taking account gaussian priors ils exp exp iiti ti exp exp note independence assumption equation necessary matching procedure could use single database indexed shading texture representations patch transforming combining cue specific local representations component inference equation describes relationship intermediate cue specific representations shape parameter sib exp tib exp two parameters equation describe uncertainty relationship intermediate parameters invariant across space two along parameters priors free parameters model note combination model neatly accounts types cue validity identified variance sib describes general uncertainty given cue local variance sii describes finage specific uncertainty cue combining equations completing integral equation bii exp aaf vt vo vff mo cq vo aa vl vg vff vo approximating gaussian obtain mean std deviation log bii log lu ob lu thus model infers image mean variance nonlinear combinations cue estimates taking account vari ous forms uncertainty cue combination psychophysics experiment conducted psychophysical experiments using stimuli generated procedure described experimental trial stimulus image four managing uncertainty cue combination views mesh surface displayed side side computer screen subject task manipulate curvature mesh match stimulus final shape mesh surface describes subject estimate shape parameter trial subject variance computed across repeated trials identical stimulus given block trials stimulus may contain shading information texture elements texture information uniform shading local cue noise trs trt zero blocks non zero others primary experimental findings see figure shape shading alone produces underestimates shape texture alone also leads underestimation lesser degree shape cues leads almost perfect estimation smaller variance shape either cue alone thus cue enhancement accurate robust judgements stimuli containing multiple cues individual cues applies paradigm variance subject estimation increases noise either shading texture systematically biases estimation true values greater noise level greater bias shape cues robust noise shape either cue alone providing evidence another form cue enhancement stimulus stimulus stimulus lu stimulus stimulus figure means standard errors shown shape matching experiment different values different stimulus conditions top noise local shape parameters left shape shading alone middle shape texture alone right shape shading texture bottom shape shading texture left trt right trt modeling results model trained using subset data experiments error criteria mean relative error mite model outputs ang zemel trt data model table data versus model predictions images outside training class first column means variances experimental data second column model experimental data subject mean variance image six free parameters model described sum third order polynomials local noise levels gradient descent used train model model trained tested three different subsets experimental data trained data varied model output accurately predicts unseen experimental data type data varied tr err model outputs agree well subject data trained data three variables vary model fits data masonably well model first type figure compares model predictions data within set table shows model outputs subject responses test examples outside training class stimulus figure model performance data err upper line perfect estimation lower line experimental data dashed line model prediction model accounts important aspects cue combination trained model parameters reveal texture prior considerably weaker shading prior texture reliable relationship consequently equal noise levels texture outweighs shading combination model factors account degree underestimation found single cue experiment greater accuracy enhancement combined cues studies also reveal novel form cue interaction image patches esp high curvature noise levels shading information becomes harmful curvature estimation becomes less reliable shading information taken account note differs cue veto texture veto shading finally primary contribution model lies ability predict effect continuous within image variation cue reliability combination figure shows estimation becomes accurate less variable increasmanaging uncertainty cue combination ing certainty shading information standard cue combination models cannot produce similar behavior estimate within image cue reliabilities figure mean left variance right model output function different values rr rrt model parameters held constant conclusion proposed hierarchical generative model study cue combination inferring parameters images achieved inverting model inference produces probability distributions level set local distributions separately representing cue combined form distribution relevant scene variable model naturally handles variations cue reliability depend spatially local image context general cue characteristics form representation incorporating image specific cue utilities makes model powerful standard combination models model provides good fit psychophysics results shading texture combination account several aspects cue combination also provides predictions varying noise levels within across images effect combination extending work number directions conducting experiments obtain local shape estimates subjects considering better ways extract local representations distributions directly image methods handling natural outliers shadows occlusion