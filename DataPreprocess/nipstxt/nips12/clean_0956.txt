abstract recently number authors proposed treating dialogue systems markov decision processes mdps however practical application mdp algorithms dialogue systems faces number severe technical challenges built general software tool rlds reinforcement learning dialogue systems based mdp framework applied dialogue corpora gathered two dialogue systems built labs experiments demonstrate rlds holds promise tool browsing understanding correlations complex temporally dependent dialogue corpora introduction systems human users speak computer order achieve goal called spoken dialogue systems systems realized examples openended real time goal oriented interaction humans computers therefore important exciting testbed ai machine learning research spoken dialogue systems typically integrate many components speech recognizer database backend since often goal user retrieve information dialogue strategy paper interested challenging problem automatically inferring good dialogue strategy dialogue corpora research dialogue strategy perhaps necessarily ad hoc due open ended nature dialogue system design example common critical design choice system always prompts user select utterance fixed menus system initiative one attempts determine user intentions unrestricted utterances mixed initiative typically system built explores alternative strategies system tested conclusions drawn regarding tested strategies best domain time consuming process difficult rigorously compare evaluate alternative systems fashion much less design improved ones recently number authors proposed treating dialogue design formalism markov decision processes mdps view population users defines stochastic environment dialogue system actions speech synthesized utterances database queries state represented entire dialogue far goal design dialogue system takes actions maximize measure reward viewed manner becomes possible least principle apply framework algorithms reinforcement learning rl find good dialogue strategy however practical application rl algorithms dialogue systems faces number severe technical challenges first representing dialogue state entire dialogue reinforcement learning spoken dialog te systems far often neither feasible conceptually useful called belief state approach possible since even know features required represent belief state second many different choices reward function even among systems providing similar services users previous work largely dealt issues imposing priori limitations features used represent approximate state exploring one potential reward measures paper develop mdp formalism dialogue systems way solve difficulties indeed simple solution allows us attenuate quantify permitting investigation different notions approximate state reward using expanded formalism give one first applications rl algorithms real data collected multiple dialogue systems built general software tool rlds reinforcement learning dialogue systems based framework applied dialogue corpora gathered two dialogue systems built labs toot system voice retrieval train schedule information elvis system voice retrieval electronic mail experiments demonstrate rlds holds promise tool end toend automated synthesis complicated dialogue systems passive corpora holy grail fall far short immediately tool browsing understanding correlations complex temporally dependent dialogue corpora correlations may lead incremental important improvements existing systems toot elvis spoken dialogue systems toot elvis systems implemented using general purpose platform developed combining speaker independent hidden markov model speech recognizer text speech synthesizer telephone interface modules specifying data access functions dialogue strategies toot data source amtrak train schedule web site elvis electronic mail spool user series controlled experiments human users dialogue data collected systems resulting dialogues toot dialogues elvis toot experiments varied strategies information presentation confirmation whether confirm user utterances initiative system vs mixed elvis experiments varied strategies information presentation summarizing email folders initiative resulting dialogue consists series system user utterances augmented observations derived user utterances internal state system system utterances actions give requested information ask clarification provide greetings instructions observations derived user utterance include speech recognizer output corresponding log likelihood score semantic labels assigned recognized utterances desired train departure arrival cities toot whether user prefers hear email ordered date sender elvis indications user barge ins system prompts many observations derived internal state include grammar used speech recognizer turn results obtained query data source addition dialogue associated survey completed user asks variety questions relating user experience see details spoken dialogue systems mdps given preceding discussion natural formally view dialogue sequence however recent work applied methodology described significantly improve performance new dialogue system singh kearns litman walker ai action taken system typically speech synthesized utterance less frequently database query start ith exchange turn shall call consists observations logged system turn discussed last section ri reward received turn example toot typical turn might indicate action ai system utterance requesting departure city might indicate several observations recognized utterance new york log likelihood recognition another unrecognized utterance well use denote prefix ends following ith turn denote one turn extension dialogue turn scope actions ai observations determined implementation systems quantity logged system access data experimental results use rewards derived user satisfaction surveys gathered toot elvis data may view dialogue trajectory well defined true mdp states possible dialogues actions possible actions available spoken dialogue system utterances database queries state dialogue action possible next states dialogues one turn extensions probability transition exactly probability stochastic ensemble users ryand would generated following action dialogue general impractical work directly due unlimited size state dialogue space furthermore known advance would estimated dialogue corpora would thus like permit flexible notion approximate states define state estimator se mapping dialogue space example simple state estimator toot might represent dialogue state boolean variables indicating whether certain pieces information yet obtained user departure arrival cities continuous variable tracking average log likelihood recognized utterances far se would vector representing quantities dialogue chosen state estimator se transform dialogue trajectory starting initial empty state se se se notation sv indicates transition sv following action ai given set dialogues dx construct empirical mdp fi sr state space fi sr actions probability transition action exactly empirical probability transition trajectories obtained dl note build msr dialogue corpora solve optimal policy analyze resulting value function point choosing sv carefully hope empirical mdp st good approximation mean st renders dialogues approximately markovian probability transition dialogue one turn extension approximately probability transition sv sv fi sr hope find state estimators sv render dialogues approximately markovian amount data computation required find good policies sr greatly reduced compared working directly dialogue space conceptually appealing approach subject least three important caveats first approach theoretically justified extent chosen state estimator renders dialogues markovian practice hope approach robust small violations markov property still produce useful results second confused intemal states spoken dialogue system dialogue view merely contribute observations reinforcement learning spoken dialogue systems state estimators violating markov property may lead meaningful insights cannot directly compared instance optimal value function derived one state estimator larger optimal value function another state estimator cannot necessarily conclude first better second demonstrated formally third even markovian state estimator sv data sparse respect se limits conclusions draw large space certain states may infrequently visited dialogue corpora say nothing optimal policy value function rlds system implemented software tool written called rlds realizes formalism rlds users specify input file sample dialogues dialogues include rewards received turn users also specify input files defining state estimator sg system command line options specify discount factor used lower bound number times state must visited order included empirical mdp mss control overfitting sparse data given inputs options rlds converts dialogues trajectories discussed uses trajectories compute empirical mdp mss specified data data used compute next state distributions average reward obvious way states visits pruned rlds uses standard value iteration algorithm compute optimal policy value function using chosen discount factor experimental results goal experiments reported twofold first confirm rlds methodology software produce intuitively sensible policies second use value functions computed rlds software discover understand correlations dialogue properties performance space present many experiments toot elvis data experiment reported involves choosing state estimator running rlds using either toot elvis data analyzing resulting policy value function toot experiments reward function obtained question user satisfaction survey last turn dialogue receives reward user indicated would use system reward user answered maybe reward user indicated would use system turns last receive reward reward received end dialogue elvis experiments used summed several questions user satisfaction score reward last turn dialogue score ranges experiment sensible policy initial sanity check experiment created state estimator toot whose boolean state variables track whether system knows value following five informational attributes arrival city denoted ac departure city dc departure date dd departure hour dh whether hour pm ap thus dialogue far includes turn toot prompts user departure city speech recognizer matches user utterance new york boolean state variable gotdc would assigned value note ignores actual values attributes addition another boolean variable called confirmedall set system took action confirmall prompts user explicitly verify attribute values perceived toot perceived yes utterance response thus state vector simply binary vector aremember toot track perceptions attributes since errors may occurred speech recognition singh kearns litman walker gotac gotap gotdc gotdd gotdh confirmedall among actions system utterances available toot prompts user specify values informational attributes shall denote actions labels askdc askac askdd askdh askap system takes several actions shall mention arise results result running rlds taken state saygreeting askdh askall confirmall following policy indicated action askdc askap askap askap askall askap close thus rlds finds sensible policy always asking user information already received confirming user choices necessary information presenting closest matching train schedule closing dialogue action close note cases chooses ask user values informational attributes even though values important emphasize policy derived purely application rlds dialogue data without knowledge goal system furthermore toot data empirical mdp built rlds state estimator include actions considerably less reasonable chosen many states examples include confirming values specific informational attributes dc since represent whether confirmations successful action would lead infinite loops confirmation requesting values informational attributes already values actions appear empirical mdp due speech recognition errors mere fact rlds driven sensible policy avoided available pitfalls indicates correlation chosen reward measure whether user would use system intuitive system goal obtaining completely specified train trip interesting note rlds finds better confirm values attributes opposed simply closing dialogue without confirmation similar experiment elvis rlds found sensible policy summarizes user inbox beginning dialogue goes read relevant mail messages done closes number information attributes number attributes confirmed number information attributes figure role confirmation role distress features indicators dialogue trouble see description experiments respectively text details experiment role confirmation explore effect confirming user values toot perceives informational attributes whether reinforcement learning spoken dialogue systems trade increased confidence utterance potential annoyance user balances favor confirmation particular reward function using created simple state estimator two state variables first variable counts number informational attributes dc ac etc toot believes obtained second variable counts number confirmed user figure presents optimal value function number attributes confirmed curve plot corresponds different setting first state variable instance curve labeled corresponds states system obtained informational attributes make two interesting observations figure first value function grows roughly linearly number confirmed attributes second perhaps startlingly value function weak dependence first feature value states number attributes confirmed seems independent many attributes system believes obtained evident lack separation plots varying values state variable words simple preliminary analysis suggests reward measure confirmed information influences value function much strongly unconfirmed information also repeated experiment replacing attribute confirmation thresholded speech recognition log likelihood scores obtained qualitatively similar results experiment role distress features dialogues often contain timeouts user silence system expected response resets user asks current context dialogue abandoned system reinitialized user requests help indicators dialogue potentially trouble events correlate low value created state estimator toot addition variable counting informational attributes counted number distress events dialogue figure presents optimal value function number attributes obtained curve corresponds different number distress features figure confirms value dialogue lower states higher number distress features number tums number information attributes task progress number turns divided figure role dialogue length toot role dialogue length elvis see description experiment text details experiment role dialogue length things equal extent task completion users prefer shorter dialogues examine question created state estimator toot counts number informational attributes obtained variable experiment state estimator elvis measures task progress measure analogous variable toot details omitted cases second variable tracks length dialogue singh kearns litman walker figure presents results toot plots optimal value function number informational values curve corresponds different range dialogue lengths immediately apparent longer dialogue lower value within length dialogue better obtained attributes course effect obtaining attributes weak longest dialogue length dialogues user struggling system usually due multiple speech recognition errors figure presents results elvis different perspective dialogue length axis curve corresponds different value task progress immediately apparent value increases task progress interestingly unlike toot seems optimal appropriate dialogue length level task progress seen inverse shaped curves experiment role initiative one important questions dialogue theory choose system mixed initiative strategies cf section using approach toot elvis data able confirm previous results showing system initiative higher value mixed initiative experiment role reward functions test robustness framework repeated experiments toot using new reward function based user perceived task completion found except weaker correlation number tums value function results basically across two reward functions conclusion paper presents new rl based framework spoken dialogue systems using framework developed rlds general purpose software tool used empirical studies two sets real dialogues gathered toot elvis systems results showed rlds able find sensible policies elvis optimal length dialogue toot confirmation attributes highly correlated value system initiative led greater user satisfaction mixed initiative results robust changes reward function acknowledgements give warm thanks esther levin david mcallester roberto pieraccini rich sutton many contributions work