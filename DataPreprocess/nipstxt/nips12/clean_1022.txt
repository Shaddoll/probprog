abstract propos new approach problem search space stochast control markov decis process mdp partial observ markov decis process pomdp follow sever author approach base search parameter famili polici exampl via gradient descent optim solut qualiti howev rather tri estim valu deriv polici directli indirectli use estim probabl densiti polici induc state differ point time enabl algorithm exploit mani techniqu effici robust approxim densiti propag stochast system show techniqu appli determinist propag scheme mdp dynam given explicitli compact form stochast propag scheme access gener model simul mdp present empir result variant complex problem introduct recent year grow interest algorithm approxim plan exponenti even infinit larg markov decis process mdp partial observ mdp pomdp larg domain valu function sometim complic difficult approxim even though may simpl compactli represent polici perform well observ led particular interest direct polici search method attempt choos good polici restrict class ii polici set ii ro class polici smoothli parameter valu ro differenti gradient ascent method may use find local optim howev estim valu ro associ gradient often far trivial one simpl method estim ro valu involv execut one mont carlo trajectori use ro take averag empir return clever algorithm execut singl trajectori also allow gradient estim method becom standard approach polici search sometim work fairli well paper propos somewhat differ approach valu gradient estim problem rather estim quantiti directli estim probabl densiti state system induc ro differ point time time slice polici search via densiti estim densiti complet determin valu polici densiti estim easi problem util exist approach densiti propag allow user specifi prior knowledg densiti also shown theoret empir provid robust estim time slice densiti show direct polici search implement use approach two differ set plan problem first access explicit model system dynam allow us provid explicit algebra oper implement approxim densiti propag process second access gener model dynam allow us sampl provid explicit represent next state distribut show techniqu combin gradient ascent order perform polici search somewhat subtl argument case sampl base approach also present empir result variant complex domain problem descript markov decis process mdp tupl possibl infinit set state start state finit set action reward function trl transit model give probabl land state upon take action state stochast polici map aa probabl take action state mani way defin polici qualiti valu horizon discount factor finit horizon discount valu function vt defin vt ea es infinit state space summat replac integr defin sever optim criteria finit horizon total reward horizon vy vy infinit horizon discount reward discount limr vt infinit horizon averag reward limt vt assum limit exist fix optim criterion goal find polici high valu discuss assum restrict set ii polici wish select good ii assum ii set polici parameter continu differenti simpl exampl may one dimension state two action mdp sigmoid probabl choos action ao state ro ao exp note framework also encompass case famili ii consist polici depend certain aspect state particular pomdp restrict attent polici depend observ restrict result subclass stochast memori free polici introduc artifici memori bit process state also defin stochast limit memori polici valu ro specifi find best polici ii search maxim comput approxim mani algorithm use find local maximum nemer mead simplex search confus simplex algorithm linear program requir abil evalu function optim point comput estim gradient respect also use varieti determinist stochast gradient ascent method write reward rather assum singl start state rather initi state distribut simplifi exposit sever minor extens trivial ng parr koller densiti valu function optim algorithm requir method comput sometim also gradient mani real life mdp howev exactli complet infeas due larg even infinit number state consid approach estim quantiti base densiti base reformul valu function express polici induc probabl distribut state time let initi distribut give probabl defin time slice distribut via recurr easi verifi standard notion valu defin earlier reformul term vr dot product oper equival expect respect somewhat subtli case infinit horizon averag reward vg limit distribut one exist reformul give us altern approach evalu valu polici ro first comput time slice densiti use comput valu unfortun modif resolv difficulti repres comput probabl densiti larg infinit space often easier repres comput valu function howev sever result indic repres comput high qualiti approxim densiti may often quit feasibl gener approach approxim densiti propag algorithm use time slice distribut restrict famili exampl continu space might set multivari gaussian approxim propag algorithm modifi equat maintain time slice densiti precis polici ro view defin oper take one distribut return anoth current polici roo rewrit case close approxim densiti propag algorithm use altern oper properti also hope close use denot approxim denot select care often case close inde standard contract analysi stochast process use show proposit assum exist constant case might arbitrarili small case proposit meaningless howev mani system reason independ furthermor empir result also show approxim densiti propag often track exact time slice distribut quit accur approxim track appli plan task given optim criterion express defin approxim replac accuraci guarante approxim track induc compar guarante valu approxim guarante perform polici found optim also possibl proposit assum fix ivt polici search via densiti estim proposit let argmaxo viol argmaxo maxo iv differenti approxim densiti section discuss two differ techniqu maintain approxim densiti use approxim propag oper show combin gradient ascent perform polici search gener assum famili distribut parameter exampl set dimension multivari gaussian diagon covari matric would dimension vector specifi mean vector covari matrix diagon consid task gradient ascent space polici use optim criterion say rt differenti rel get rr avoid introduc new notat also use denot aset sociat vector paramet paramet function henc intern gradient term repres jacobian matrix entri repres deriv paramet rel paramet oj gradient comput use simpl recurr base chain rule deriv oo first summand jacobian deriv transit oper rel polici paramet second product two term deriv rel distribut paramet result previou step recurr determinist densiti propag consid transit oper simplic omit depend idea approach tri get close possibl subject constraint specif defin project oper take distribut return distribut closest sens defin order ensur gradient descent appli set need ensur differenti function clearli mani instanti idea assumpt hold provid two exampl consid continu state process nonlinear dynam mixtur condit linear gaussian defin set multivari gaussian oper take distribut mixtur gaussian comput mean covari matrix easili comput paramet use simpl differenti algebra oper differ exampl algorithm approxim densiti propag dynam bayesian network dbn dbn structur represent stochast process exploit condit independ properti distribut allow compact represent dbn state space defin set possibl assign set random variabl xn transit model describ use bayesian network fragment node xi node xi repres repres node xi network forc root parent associ condit probabl distribut node associ condit probabl distribut cpd specifi parent transit probabl xt defin ng parr koller parent dbn support compact represent complex transit model mdp extend dbn encod behavior mdp stochast polici introduc new random variabl repres action taken current time parent variabl state action allow depend cpd may compactli repres function approxim distribut action defin differ context discret dbn number state grow exponenti number state variabl make explicit represent joint distribut impract algorithm defin set distribut defin compactli set margin smaller cluster variabl simplest exampl set distribut independ paramet defin distribut paramet multinomi project oper simpli margin distribut onto individu variabl differenti one use corollari analysi decay rate structur often much higher decay rate multipl applic converg rapidli stationari distribut properti use approxim optim rel stochast densiti propag mani set assumpt direct access strong weaker assumpt access gener model black box gener sampl appropri distribut gener sampl case use differ approxim scheme base oper stochast oper take distribut gener number random state sampl si si action gener sampl transit distribut si sampl si ai assign weight wi ro ai si compens fact action would select ro equal probabl result set sampl weight wi given input statist densiti estim use estim new densiti assum densiti estim procedur differenti function weight often reason assumpt clearli use comput therebi approxim ro valu howev gradient comput far trivial particular comput deriv must consid behavior perturb one say appli origin case entir differ set sampl would probabl gener possibl lead differ densiti hard see one could differenti result perturb propos altern solut base import sampl rather chang sampl modifi weight reflect chang probabl would gener specif fit defin sampl si ai weight comput deriv respect paramet requir let vector paramet use chain rule first term deriv estim densiti rel sampl weight matrix second deriv weight rel paramet vector jacobian easili comput polici search via densiti estim actual avg cost estimatedavg cost function evalu figur drive task dbn model polici search optim result experiment result test approach two differ domain first averag reward dbn mdp problem shown figur task find polici chang lane drive moder busi two lane highway slow lane fast lane model base bat dbn result separ effort build good model driver behavior simplic assum car speed control automat concern choos later action chang lane drive straight observ shown figur lclr rclr clearanc next car lane close medium far agent pay cost step block mean drive close car front pay penalti per step stay fast lane polici specifi action probabl possibl observ combin sinc reason small number paramet use simplex search algorithm describ earlier optim process mix quit quickli fairli good approxim use fulli factor represent joint distribut except singl cluster three observ evalu averag mont carlo trial step figur show estim actual averag reward polici paramet evolv time algorithm improv quickli converg natur polici car gener stay slow lane switch fast lane necessari overtak second experi use bicycl simul action correspond lean leftycent right appli neg zero posit torqu handlebar six dimension state use includ variabl bicycl tilt angl orient handlebar angl bicycl tilt exce fall enter absorb state use polici search follow space select twelv simpl manual chosen fine tune featur state action chosen softmax probabl take action ai exp wi exp problem come gener model complic nonlinear noisi bicycl dynam use stochast densiti propag version algorithm stochast gradient ascent distribut mixtur singleton point consist absorb state multivari gaussian ng parr koller first task domain balanc reliabl bicycl use horizon discount si sampl per densiti propag step quickli achiev next tri learn ride goal radiu away also succeed find polici reliabl formal evalu difficult suffici hard problem even find solut consid success also slight paramet sensit best result obtain pick fit care use part data earlier less success trial repres fairli good rider state distribut use algorithm abl obtain solut median ride distanc km goal significantli better result obtain learn rather plan set use valu function approxim solut report much larger ride distanc goal km singl best ever trial km conclus present two new variant algorithm perform direct polici search determinist stochast densiti propag set empir result also shown method work well two larg problem acknowledg warmli thank kevin murphi use help bay net toolbox jett rand preben alstr use bicycl simul ng support berkeley fellowship work koller parr support aro muri program integr approach intellig system darpa contract daca subcontract iet inc onr contract darpa hpkb program sloan foundat powel foundat