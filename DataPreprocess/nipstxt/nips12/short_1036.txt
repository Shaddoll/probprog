abstract problem developing good policies partially observable markov decision problems pomdps remains one challenging areas research stochastic planning one line research area involves use reinforcement learning belief states probability distributions underlying model states promising method small problems application limited intractability computing representing full belief state large problems recent work shows many settings maintain approximate belief state fairly close true belief state particular great success shown approximate belief states marginalize correlations state variables paper investigate two methods full belief state reinforcement learning one novel method reinforcement learning using factored approximate belief states compare performance algorithms several well known problem literature results demonstrate importance approximate belief state representations large problems