abstract describe silicon network consisting group excitatory neurons global inhibitory neuron output inhibitory neuron normalized respect input strengths output models normalization property wide field directionselective cells fly visual system normalizing property also useful system wish output signal code strength inputs dependent number inputs circuitry neuron equivalent lazzaro winner take wta circuit one additional transistor voltage reference lazzaro circuit outputs excitatory neurons code neuron largest input difference multiple winners chosen varying voltage reference neuron network transition soft max behavior hard wta behavior show results fabricated chip neurons pm cmos technology introduction lazzaro colleagues lazzaro first implement hardware model winner take wta network network consists excitatory cells inhibited global signal improvements network addition positive feedback lateral connections described morris indiveri dynamics stability properties networks coupled excitatory inhibitory neurons analyzed many amari grossberg grossberg described conditions networks exhibit wta behavior lazzaro network computes single winner reflected outputs excitatory cells several winners chosen using localized inhibition work describe two variants similar architecture outputs excitatory neurons code relative input strengths soft max computation relative values outputs depend number inputs relative strengths two parameter settings network global inhibitory liu ei ei ei yi wi yi wi figure network model recurrent inhibitory network signal also used output output saturates increasing number active inputs saturation level depends input strengths parameter settings normalization property similar normalization behavior wide field direction selective cells fly visual system cells code temporal frequency visual inputs largely independent stimulation size circuitry neuron silicon network equivalent lazzaro et al hard wta network additional transistor voltage reference varying voltage reference network transition soft max computation hard wta computation two variants outputs excitatory neurons either code strength inputs normalized respect constant bias current results fabricated network neurons zm ami cmos show different regimes operation network global inhibition generic architecture recurrent network excitatory neurons single inhibitory neuron shown figure excitatory neurons receive external input synapse onto global inhibitory neuron inhibitory neuron turn inhibits excitatory neurons dynamics network described follows dyi dt yi ei wjyj wj weight synapse jth excitatory neuron inhibitory neuron yj state jth neuron steady state condin tions yi ei yt yt wjyj assume linear relationship yt yj letting wj ej yt yj wn increases yt inputs level yt yrinner take circuit controllable soft max property iol vt vr figure first variant architecture show circuit two excitatory neurons global inhibition neuron circuit excitatory neuron consists input current source transistors inhibitory transistor fixed current source ib inputs inhibitory transistor io normalized respect ib first variant network fixed current source sections describe two variants architecture shown figure two variants differ way inhibition signal generated first network figure shows circuitry two excitatory neurons inhibition neuron excitatory neuron linear threshold unit consists input current transistors state neuron represented current ir diode connected transistor introduces rectifying nonlinearity system since cannot negative inhibition current sunk determined gate voltage vt inhibition neuron consists current source ib vt determined corresponding current corresponding transistor ms neuron notice cannot greater largest input network inputs network excitatory input currents transistor defined io lo normalized respect current source ib hard wta condition output current winning neuron equal bias current network exhibits either soft maximum behavior hard wta behavior depending value external bias va inhibition current derived nii nil number active excitatory neurons neurons whose ii ii input current neuron ioe deriving equation assumed inhibition current linear combination states neurons figure shows response common node voltage vt function number inputs different input values measured fabricated silicon network neurons input current neuron provided pfet transistor driven gate voltage input currents equal figure saturation behavior network function number number inpu number inputs figure common node voltage vt function number input stimuli va common node voltage vt function number inputs input voltage vb curves correspond different values va inputs seen different traces saturation level increases decreases seen equation point response saturates dependent ratio ia figure show curve saturates different points different values va fixed ib figure set inputs zero except two inputs vin set value measured io io function va shown figure four curves correspond four values initially currents io io equal expected soft max condition va increases network starts exhibiting wta behavior one output currents finally goes zero critical value va critical value increases higher input currents transistor backgate effects figure show output currents respond function differential voltage two inputs shown figure fixed one input swept second input differentially around different curves correspond different values va low value va linear differential input range mv linear range decreases va increased corresponding wta condition second variant diode connected inhibition transistor second variant shown figure current source replaced diode connected transistor output currents ioi follow magnitude input currents inhibition current expressed follows irilioi ia ia defined section sum equation neurons assuming equal inputs get iri ia equation shows feedback signal square root dependence neuron states see causes feedback signal saturate quickly number inputs qnner take circuit controllable soft max property vin va va va vin vin figure output currents io io function subthreshold bias current outputs io io function differential input voltage av irl ir figure second variant network schematic shows two excitatory neurons diode connected inhibition transistor substituting iri ii equation solve eii measurements fabricated circuit neurons show dependence vt natural logarithm number inputs figure output saturates quickly number inputs level saturation increases increased input strengths inputs value network also act wta changing inputs set zero except two inputs whose gate voltages set shown figure output currents io ion initially equal increases output currents split apart eventually io final value lol depends maximum input current data shows network acts wta circuit set instead output currents split lower value liu vin vin vin number inputs vinl vin vin vin va figure common node voltage vt function number inputs input voltages outputs ioi lo function hi curves asterisks nl curves circles inhibition wta property arises variants network gain parameter increased diode connected transistor ignored variants reduce lazzaro network first variant feedback current linear combination neuron states however gain parameter increased ignored feedback current nonlinear combination input states wta behavior exhibited reduced networks hard wta conditions initially smaller input currents capacitances nodes vrl vr charged difference individual input current av since inhibition current dt linear combination iri iri exponential vr see sum exponentials input currents hence feedback current nonlinear input currents another way viewing condition electronic terms soft wta condition output node neuron softimpedance node low gain node hard wta case output node high impedance node high gain node input differences immediately amplified circuit discussion hahnloser hahnloser recently implemented silicon network linear threshold excitatory neurons coupled global inhibitory neuron inhibitory signal linear combination output states excitatory neurons network exhibit wta behavior unless excitatory neurons include self excitatory term inhibition current network also generated via diode connected transistor circuitry two variants described compact circuitry network recurrent networks architecture described paper proposed reichardt colleagues reichardt modelling aggregation property qnner take circuit controllable soft max property wide field direction selective cells flies synaptic inputs inhibited wide field cell pools synaptic inputs similar networks also used model cortical processing example orientation selectivity douglas network implemented model aggregation property directionselective cells fly varying voltage reference network implements either soft max computation hard wta computation circuitry useful hardware models cortical processing motion processing invertebrates acknowledgments thank rodney douglas supporting work mosis foundation fabricating circuit also thank tobias delbrfick proofreading document work supported part swiss national foundation research spp grant office naval research