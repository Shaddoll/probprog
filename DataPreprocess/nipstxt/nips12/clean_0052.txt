abstract introduc novel method construct languag model avoid problem associ recurr neural network method creat predict fractal machin pfm briefli describ experi present demonstr suitabl pfm languag model pfm distinguish reliabl minim pair behavior consist hypothesi wellformed grade absolut discuss potenti offer fresh insight languag acquisit process follow introduct cognit linguist seen develop recent year two import relat trend firstli widespread renew interest statist grade natur languag show tradit noth notion well formed may present accur pictur congruiti utter repres intern secondli analysi state space trajectori artifici neural network ann provid new insight type process may account abil learn devic acquir repres languag without appeal tradit linguist concept despit remark advanc come connectionist research common use recurr network simpl recurr network srn especi studi languag recurr neural network suffer particular problem make imperfectli suit languag task vast major work field employ small network dataset usual artifici although mani interest linguist issu may thu tackl real progress evalu potenti state trajectori grade grammat uncov underli process respons overt linguist phenomena must inevit limit whilst experiment task remain small nevertheless certain obstacl scale network train back propag bp network tend toward ever grade grammaticalif predict fractal machin longer train time size input set network increas although real time recurr learn rtrl back propag time potenti better model tempor depend train time longer still scale also difficult due potenti catastroph interfer lack adapt stabil problem includ rapid loss inform past event distanc present increas depend learn state trajectori train data also upon vagari initi weight vector make analysi difficult type learn devic also suffer problem standard markov model requir alloc memori everi gram larg valu impract variabl length markov model memori effici becom unmanag train larg data set two import relat concern cognit linguist thu find method allow languag model scale similar spirit recurr neural network encount problem scale use method evinc new insight grade grammat state trajectori aris given genuin larg natur occur data set accordingli present new method gener state trajectori avoid problem previous studi financi predict task method creat fractal map train data state machin built result model known predict fractal machin pfm use properti state trajectori fractal represent fast comput effici gener accur well understood may infer even larg vocabulari train set catastroph interfer lack adapt stabil problem given way represent built demonstr topic futur work train time significantli less recurr network experi describ smallest model took minut build largest one took around three hour comparison ann took longer day train littl loss inform cours input sequenc allow finit precis comput scalabl pfm taken advantag train larg corpu natur occur text enabl assess potenti new insight might aris use method truli larg scale languag task predict fractal machin pfm brief descript method creat pfm given interest reader consult sinc space constraint preclud detail examin key idea behind predict model transform symbol sequenc alphabet tagset point hypercub dimension hypercub larg enough symbol identifi umqu vertex particular assign symbol vertic arbitrari transform crucial properti symbol sequenc share suffix context map close specif longer common suffix share two sequenc smaller euclidean distanc point represent transform use studi correspond iter function system parfitt dorffner consist affin map ti tie ti tjfori given sequenc symbol alphabet construct point represent sl sl hypercub note common center iter function system literatur refer either symbol map depend upon context pfm construct point represent subsequ appear train sequenc first slide window length train sequenc posit transform sequenc length appear window point set point obtain slide whole train sequenc partit sever class mean vector quamiz euclidean space class repres particular codebook vector number codebook vector requir chosen experiment sinc quantiz class group point lie close togeth sequenc point represent class potenti share long suffix quantiz class may treat predict context correspond predict symbol probabl comput slide window train sequenc count quantiz class often sequenc map class follow particular symbol test mode upon see new sequenc symbol transform perform closest quantiz center found correspond predict probabl use predict next symbol experiment comparison pfm recurr network perform pfm compar rtrl train recurr network next tag predict task sixteen grammat tag sentenc start charact use model train concaten sequenc tag top three quarter sub corpora univers pennsylvania brown corpu remaind use creat test data follow larg train corpu natur occur data context case one possibl correct continu simpli count correctli predict symbol insuffici assess perform sinc fail count correct respons target extent model distinguish grammat axe ungrammat utter therefor addit measur gener minim pair compar neg log likelihood nll per symbol respect model likelihood comput slide test sequenc window posit determin probabl symbol appear immedi beyond process progress probabl multipli neg natur logarithm taken divid number symbol signific differ nll http www ldc upenn edu grade grammat predict fractal machin much harder achiev member minim pair grammat random sequenc therefor good measur model valid minim pair gener theoret motiv manipul tend longer ungrammat given small tagset remov grammat sub class necessarili also remov larg amount inform manipul therefor perform switch posit two symbol sentenc test set symbol switch could distanc apart within sentenc long result sentenc ungrammat surfac instanti chang littl possibl make sentenc ungrammat goal retain task distinguish grammat ungrammat sequenc difficult possibl test data consist pair grammat ungrammat test set around tag plu ungrammat meaningless test set contain code list sever time use measur baselin perform ten st order randomli initialis network train epoch use rtrl network consist input output layer unit correspond tag hidden layer unit context layer unit connect first hidden layer second hidden layer use increas flexibl map hidden represent recurr portion tag activ output layer logist sigmoid activ function use learn rate momentum set train sequenc present rate one tag per clock tick pfm deriv cluster fractal represent train data ten time variou number codebook vector experi perform use pfm neural network former case experi choos appropri number codebook vector initi lack type data result follow given averag either neural network els pfm deriv given number codebook vector network correctli predict next tag grammat ungrammat test set respect pfm match perform around codebook vector respect exceed higher number vector respect vector network gener mean nll per symbol grammat ungrammat test set respect differ meaningless test set differ nll grammat meaningless data pfm match differ nll codebook vector nll grammat nll ungrammat differ nll meaningless data codebook vector differ nll grammat meaningless data differ nll grammat ungrammat grammat meaningless data set becam even larger increas number codebook vector differ perform grammat ungrammat test set thu highli signific case model distinguish grammat conclus support fact mean nll meaningless test set alway notic higher minim pair set parfitt tiho dorffner discuss pfm exceed perform network larger number codebook vector possibl network hidden node would also better term eas use howev well scale potenti pfm certainli superior great advantag represent creat depend see section make hypothesi creation test rapid also straightforward speed pfm may train made possibl make statist signific observ larg number cluster run introduct grade wellformed spoken product new hypothes natur languag use minim pair design make clear cut distinct grammat ungrammat utter appear leav issu one side realiti result rather pertin use likelihood measur might inde impli brown corpu consist subcorpora repres differ discours type fiction govern document wherea tradit notion gramrnat would lead us treat ungramrnat sentenc minim pair test set equal ungrammat nll experi tell differ stori grammat version consist lower associ nll higher probabl ungrammat version differ much smaller meaningless data either grammat ungramrnat data support concept grade grammat nll meaningless data might seen sort benchmark measur lesser degre ungrammat note incident pfm appear associ meaningless data significantli higher nll network even though differ nll grammat ungrammat data suggest pfm greater power discrimin grade wellformed recurr network use research need ascertain valid moreov nll vari grammat ungrammat test set also sentenc sentenc word word discours style discours style increas often dramat manipul portion ungrammat sentenc encount word grammat sentenc exhibit similar effect thu subsequ well form utter occur rare never train set high associ nll way ungrammat one like happen even larg corpora sinc grammat structur rare consist recent find human sentenc process well formed link conform expect measur gloze score interest also remark variat nll discours style although mean nll across discours style test set lower grammat ungrammat version cannot guarante grammat version one test set lower nll ungrammat version anoth inde grammat ungrammat nll interleav may observ figur show nll three discours style lie bottom middl top rang even interestingli nll grammat version discours style order accord lie within rang becom clear nll predictor discours style style linguist class formal grade grammaticalif predict fractal machin nil ociat grammat ungrammat version discours type learn text grammat learn text ungrammat romanfi liction gramma cal romant fiction ungrammat scienc liction grammat scienc fiction ungrammat codebook vector figur nll minim pair test set contain differ discours style suggest grade wellformed base upon prototyp learn govern document test set lowest nll three press test set cluster fiction test set exemplifi creativ languag use cluster high end similarli learn govern test set lowest nll conform intuit usag lie closest grammat prototyp even though train set test set fiction thu might expect contribut prototyp suggest usag vari significantli across fiction test set conclus work use pfm languag model earli stage result date show lot offer much larger project plan examin allen seidenberg hypothesi grade grammat wellformed appli syntax also languag subdomain semant integr part use larger corpora tagset identif vertic semant syntact featur rather atom symbol identifi possibl combin pfm ann exampl mean bypass normal method creat state space trajectori subject current studi acknowledg work support austrian scienc fund fwf within research project adapt inform system model econom manag scienc sfb austrian research institut artifici intellig support austrian feder ministri scienc transport parfitt tit dorffner