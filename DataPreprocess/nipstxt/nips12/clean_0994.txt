abstract mani research explor method hierarch reinforc learn rl tempor abstract abstract action defin perform mani primit action termin howev littl known learn state abstract aspect state space ignor previou work develop maxq method hierarch rl paper defin five condit state abstract combin maxq valu function decomposit prove maxq learn algorithm converg condit show experiment state abstract import success applic maxq learn introduct work hierarch reinforc learn focus tempor abstract exampl option framework programm defin set macro action option provid polici learn algorithm semi markov learn treat tempor abstract action primit learn polici select among close relat ham framework programm construct hierarchi finitest control control includ non determinist state programm sure action perform hamq learn algorithm appli learn polici make choic non determinist state approach studi hierarch rl option finit state control must access entir state space one except feudal method dayan hinton introduc state abstract unsaf way result learn problem partial observ henc could provid formal result converg perform method even brief consider human level intellig show method cannot scale decid walk bedroom kitchen need think locat car without state abstract rl method learn valu function must learn separ valu state state abstract maxq hierarch reinforc learn world argu solv clever valu function approxim method merit view paper howev explor differ approach identifi aspect mdp permit state abstract safe incorpor hierarch reinforc learn method without introduc function approxim permit us obtain first proof converg hierarch rl optim polici presenc state abstract introduc state abstract within maxq flamework basic idea gener previou work maxq briefli discuss state abstract employ experi howev could prove algorithm maxq converg state abstract usabl character situat state abstract could safe employ paper solv problem addit compar effect maxq learn without state abstract result show state abstract import case essenti effect applic maxq learn maxq framework let markov decis problem state action reward function probabl transit function ls result appli finit horizon undiscount case infinit horizon discount case let mn set subtask subtask mi defin termin predic ti set action ai may subtask primit action goal subtask mi move environ state ti satisfi refin use local reward function express prefer among differ state satisfi ti omit refin paper subtask must form dag singl root node subtask may invok directli indirectli hierarch polici set polici rn one subtask hierarch polici execut use standard procedur call return semant start root task unfold recurs primit action execut polici mi invok state let ni probabl termin state execut primit action hierarch polici recurs optim polici ri optim given polici descend dag let valu function subtask state valu follow polici start reach state satisfi ti similarli let valu subtask execut child action state execut current polici termin maxq valu function decomposit base observ subtask mi view semi markov decis problem reward perform action state equal valu function subtask state see consid sequenc reward rt receiv execut child action continu subsequ action accord hierarch polici rt rt rt st macro action execut number step return henc partit sum two term rt st dietterich first term discount sum reward subtask termin second term cost finish subtask execut discount time initi call second term complet function denot write bellman equat maxq termin recurs defin primit action expect reward perform action state maxq learn algorithm simpl variat learn subtask mi state choos child action invok current polici return observ result state number elaps time step updat accord ax prove converg requir explor polici execut learn order glie polici order polici polici break valu tie among action prefer action come first fix order glie polici polici execut action infinit often everi state visit infinit often converg probabl greedi polici order condit requir ensur recurs optim polici uniqu without condit potenti mani differ recurs optim polici differ valu depend tie broken within subtask subsubtask theorem let either episod mdp determinist polici proper discount infinit horizon mdp discount factor let dag defin subtask mo mk let sequenc constant subtask mi lim lim oe let rx order glie polici subtask mi state assum vt ict bound probabl algorithm maxq converg uniqu recurs optim polici consist rx proof sketch proof base proposit bertseka tsitsikli follow standard stochast approxim argument due gener case non stationari nois two key point proof defin pt nl probabl transit function describ behavior execut current polici subtask time induct argument show probabl transit function converg probabl transit function recurs optim polici second show convert usual weight max norm contract weight max norm contract straightforward complet proof notabl maxq learn valu function subtask simultan need wait valu function subtask converg begin learn valu function parent task give complet onlin learn algorithm wide applic state abstract maxq hierarch reinforc learn figur left taxi domain taxi row column right task graph condit safe state abstract motiv state abstract consid simpl taxi task shown figur four special locat world mark ed lue reen ellow episod taxi start randomli chosen squar passeng one four locat chosen randomli passeng wish transport one four locat also chosen randomli taxi must go passeng locat sourc pick passeng go destin locat destin put passeng episod end passeng deposit destin locat six primit action domain four navig action move taxi one squar north south east west pickup action putdown action action determinist reward action addit reward success deliv passeng reward taxi attempt execut putdown pickup action illeg navig action would caus taxi hit wall action op usual reward task hierarch structur see fig two main sub task get passeng get deliv passeng put subtask turn involv subtask navig one four locat navig bound desir target locat perform pickup putdown action task illustr need support tempor abstract state abstract tempor abstract obviou exampl get tempor extend action take differ number step complet depend distanc target top level polici get passeng deliv passeng express simpli abstract need state abstract perhap less obviou consid get subtask subtask solv destin passeng complet irrelev cannot affect nagiv pickup decis perhap importantli navig target locat either sourc destin locat passeng taxi locat ident target locat import fact case taxi carri passeng case irrelev introduc five condit state abstract assum state mdp repres vector state variabl state abstract defin combin subtask mi child action identifi subset state variabl relev defin valu function polici use relev variabl valu function polici dietterich said abstract first two condit involv elimin irrelev variabl within subtask maxq decomposit condit subtask irrelev let mi subtask mdp set state variabl irrelev subtask state variabl partit two set stationari abstract hierarch polici execut descend mi follow two properti hold state transit probabl distribut ni child action mi factor product two distribut nlx nix lx give valu variabl give valu variabl pair state sl yl child action taxi problem sourc destin passeng irrelev navig subtask target current taxi posit relev advantag form abstract similar obtain boutili dearden goldszmidt belief network model action exploit simplifi valu iter stochast plan condit leaf irrelev set state variabl irrelev primit action pair state differ valu variabl condit satisfi primit action north south east west taxi task state variabl irrelev constant next two condit involv funnel action macro action move environ larg number possibl state small number result state complet function subtask repres use number valu proport number result state condit result distribut irrelev undiscount case set state variabl yj irrelev result distribut action abstract polici execut mj descend maxq hierarchi follow hold pair state differ valu state variabl yj lsl ls consid exampl get subroutin optim polici taxi task regardless taxi posit state taxi passeng start locat get finish execut taxi complet pick passeng henc taxi initi posit irrelev result posit note true undiscount settingwith discount result distribut number step requir get finish depend much start locat taxi henc form state abstract rare use cumul discount reward condit termin let mj child task mi properti whenev mj termin caus mi termin complet state abstract maxq hierarch reinforc learn cost need repres particular kind funnel action funnel state termin state mi exampl taxi task state taxi hold passeng put subroutin succeed result termin state root termin predic put passeng destin locat impli termin condit root mean root put uniformli zero state put termin condit shield consid subtask mi let state path root dag mi exist subtask termin valu need repres subtask mi state never execut taxi task simpl exampl aris put task termin state passeng taxi mean need repres root put state result combin termin condit need explicitli repres complet function put appli abstract condit taxi task valu function repres use valu much less valu requir fiat learn without state abstract maxq requir valu theorem converg state abstract let maxq task graph incorpor five kind state abstract defin let rx order glie explor polici abstract condit theorem maxq converg probabl uniqu recurs optim polici defin rx proof sketch consid subtask mi relev variabl two arbitrari state first show five abstract condit valu function repres use ignor valu learn valu learn algorithm need sampl drawn accord nix second part proof involv show regardless whether execut state result distribut henc give correct expect analog argument appli leaf irrelev termin shield case easi experiment result implement maxq noisi version taxi domain kaelbl hdg navig task use boltzmann explor figur show perform flat maxq without state abstract task learn rate boltzmann cool rate separ tune optim perform method result show without state abstract maxq learn slower converg flat learn state abstract much faster conclus paper shown understand reason state variabl irrelev obtain simpl proof converg maxq learn dietterich maxq ab mction flat primit action maxq ab tracfion goooo le primit action figur comparison maxq without state abstract fiat learn noisi taxi domain left kaelbl hdg task right horizont axi give number primit action execut method vertic axi plot averag separ run state abstract much fruit previou effort base weak notion state aggreg suggest futur research focu identifi condit permit safe state abstract