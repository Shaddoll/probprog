abstract order compare learning algorithms experimental results reported machine learning litterature often use statistical tests significance unfortunately tests take account variability due choice training set perform theoretical investigation variance cross validation estimate generalization error takes account variability due choice training sets allows us propose two new ways estimate variance show via simulations new statistics perform well relative statistics considered dietterich dietterich introduction applying learning algorithm comparing several algorithms one typically interested estimating generalization error point estimation rather trivial cross validation providing variance estimate estimation hypothesis testing confidence intervals possible difficult especially pointed hinton et al one wants take account variability due choice training sets breiman notable effort direction dietterich work dietterich careful investigation variance estimated allows us provide new variance estimates turn perform well let us first lay framework shall work assume data available form zn example case supervised learning zi xi yi denote dimensions xi inputs outputs also assume zi independent zi let represents subset size nl taken function tm instance function could loss incurred decision learning algorithm trained makes new example interested estimating ntz zn zn independent subscript stands size training set expectation taken zn meaning interested performance algorithm rather performance specific decision function yields data hand according dietterich taxonomy dietterich deal problems type evaluating learning algorithms rather type evaluating decision functions call generalization error even though also represent error difference generalization error may take nadeau bengio lrv lrq decision function obtained training algorithm loss function measuring inaccuracy decision instance could indicator function classification problems ii ii ii euclidean norm regression problems case people call generalization error comparison generalization errors sometimes interested performance algorithms per se instead two algorithms compare case may want consider fa fb fa fb decision functions obtained training two algorithms loss function case would difference generalization errors outlined previous example generalization error often estimated via form cross validation since various versions latter lay specific form use paper let sj random set nx distinct integers nx represents size training set shall let nx size test set let independent random sets let denote complement sj let zli training set obtained subsampling according random index set sj corresponding test set zili let zi according could error algorithm trained training set makes example zi according could difference errors two different algorithms let randomly independently drawn draw examples test set replacement compute average error committed notation convey fact depends denote bj becomes increases let ttf lim oo without bounds indeed sampling infinitely often zs zi yielding usual average test egor use chosen relative frequency mathematical device make test exmples sampled independently cross validation estimate generalization egor consider paper gk note unbiased estimator zn paper estimation ance first study theoretically vmiance section leading two new vmiance estimators developped section tion shows simulation study peffomed see proposed statistics behave compared statistics already use analysis vat study vat important understand inference procen dures tt presently use inadequate shall underline section investigation also enables us develop estimators vat section proceed state following useful lemma proved nadeau bengio inference generalization error lemma let uk random variables common mean fi common variance cov ui uj vi let rr correlation ui uj let ei ui ui sample mean sample variance respectively sb var study vat need define following covariances let ao nl var randomly drawn let rr cov randomly independently drawn let rr randomly independently drawn respectively letaa aa fori fact may shown cov ao let us look mean iance concerning expectations obviously thus lemma implies var fif vat lim fi lim var fij also shown cov fi fly therefore using lemma shall often encounter aa future knowl ge quantities valuable say proposition given al ao proof see nadeau bengio natural question estimator hi affect iance proposition variance non increasing proof see nadeau bengio clearly increasing leads smaller variance noise introduced sampling replacement test set disappears done also averaging many train test increasing improves estimation finally things equal elsewhere fixed among things larger size test sets better estimation behavior vat respect unclear conjecture situations decrease argument goes like variability fi comes two sources sampling decision rules training process sampling testing examples holding fixed freezes second source variation solely depends three quantities problem solve becomes affect first source variation unreasonable say decision function yielded learning algorithm less variable training set large conclude first source variation thus total variation vat kll decreasing advocate use estimator nadeau bengio easier compute smaller variance var nll lim vat oo estimation vat held constant interested estimating vat defined nl provide two different estimators vat oo first simple may positive negative bias actual variance second meant conservative conjecture previous section correct expected value exceeds actual variance st method corrected resampled test let us recall sample variance according lemma unbiased estimator vat hoo let vg problem correlation unknown difficult estimate use naive surrogate follows let us recall la zs zi purpose building estimator let us make approximation zi depends zi hard show see nadeau bengio correlation becomes theren fore first estimator vat nl po wherepo po nl accordn tend overestimate underestimate var ing whether po po note first method basically require computations already performed estimate generalization error cross validation nd method conservative second method aims overestimating vat lead conservative inference tests hypothesis actual size less nominal size important techniques currently use opposite defect tend liberal tests actual size exceeding nominal size typically regarded less desirable conservative tests estimating unbiasedly trivial hinted however may estimate nl unbiasedly vat jlwheren let unbiased estimator developed variance argued previous section vat vat oo therefore oj tend overestimate rr nl rr may estimate without bias simplicity assume even randomly split data two distinct data sets size let statistic interest computed involves among things drawing train test subsets let statistic computed independent since independent data sets unbiased estimate splitting process may repeat times yields dm injbrence generalization error dm cl split yields pair fi unbiased oj allows us use following unbiased estimator note according lemma vat al var corr simulations suggest usually close variance decreases roughly like say second method therefore bit computation intensive since requires perform cross validation times expected conservative simulation study consider five different test statistics hypothesis first three methods already use machine learning community last two new methods put forward following form rejecthoif table describes performed simulation study investigate size probability rejecting null hypothesis true power probability rejecting null hypothesis false five test statistics shown table consider problem estimating generalization errors letter recognition classification problem available www ics uci edu pub machine learnin databases learning algorithms classification tree used function tree splus version windows default arguments used pruning performed function predict option type class used retrieve decision function tree fa classification loss function la fa xi equal whenever algorithm misclassifies example training set otherwise first nearest neighbor apply first nearest neighbor rule distorted distance metric pull performance algorithm level classification tree dietterich lb equal whenever algorithm misclassifies example training set otherwise addition inference generalization errors za associated two algorithms also consider inference iza iza izb la la la ls sample without replacement examples examples available letter recognition data base repeating times obtain sets data form za data set za generated may comparing two classifiers nadeau bengio show test closely related mcnemar test described dietterich cv procedure developed dietterich solely comparison classifiers mind may trivially extended problems shown nadeau bengio nadeau bengio test mcnemar tn nl resampl tj nl dietterich cv see diettefich conservative zl corn resampled ts table description five test statistics relation rejection criteria shown tk refer quarttile student tk distribution respectively defined sv sample variance involved ratio comes proper application lemma except dietterich cv conservative indicates test tend conservative ratio less liberal ratio greater perform hypothesis testing based statistics shown table difficulty arises however given methods aim inference generalization error instance dietterich cv test aims others aim nl would usually different different methods resampled test statistic instance order test statistic nl compare different techniques given shall always aim use normal usage would call however statistics involving nl therefore statistics nl times larger nl also use nl obtain simply throw data conservative variance calculation would normally instance obtain os however numerator compute instead explained note rationale led conservative statistics maintained overestimates var nn var nns ml vat vat figure shows estimated power different statistics interested estimate powers computing proportion rejections see tests based test resampled test liberal reject null hypothesis probability greater prescribed null hypothesis true tests appear sizes either significantly larger barely note dietterich cv powerful note curve lowest power extreme values rnu make fair comparison power two curves one mentally align size bottom curve two curves indeed even resampled test conservative throw data powerful course due fact cv method uses instead glimpse much larger simulation study studying corrected resampled test conservative natural habitat nl see usually either right money term size slightly conservative powers appear equivalent simulations performed found taking greater improve much power brence generalization error figure powers tests left panel ho right panel level varying dotted vertical lines correspond confidence interval actual therefore actual size tests may read solid horizontal line displays nominal size tests estimated probabilities rejection laying dotted horizontal line significatively greater significance level solid curves either correspond resampled test corrected resampled test resampled test one ridiculously high size curves circled points versions ordinary corrected resampled test conservative data thrown away matters used statistics taking instead lead noticeable difference distribution conservative taking makes statistic slightly less conservative see nadeau bengio details conclusion paper addresses important practical issue empirical validation new machine learning algorithms decide whether one algorithm significantly better another one argue important take account variability due choice training set dietterich already proposed statistic purpose constructed two new variance estimates cross validation estimator generalization error enable one construct tests hypothesis confidence intervals seldom liberal furthermore tests based powers unmatched known techniques comparable size one corrected resampled test computed without additional cost usual fold crossvalidation estimates one conservative requires times computation found sufficiently good values