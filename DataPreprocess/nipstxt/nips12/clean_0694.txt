abstract propose new markov chain monte carlo algorithm generalization stochastic dynamics method algorithm performs exploration state space using intrinsic geometric structure facilitating efficient sampling complex distributions applied bayesian learning neural networks algorithm found perform least well best state art method consuming considerably less time introduction bayesian framework predictions made integrating function interest posterior parameter distribution latter normalized product prior distribution likelihood since problems integrals complex calculated analytically approximations needed early works bayesian learning nonlinear models buntineand weigend mackay used gaussian approximations posterior parameter distribution however gaussian approximation may poor especially complex models multi modal character posterior distribution hybrid monte carlo hmc duane et al introduced neural network community neal deals successfully multi modal distributions time consuming one main causes hmc inefficiency anisotropic character posterior distribution density changes rapidly directions remaining almost constant others present novel algorithm overcomes problem using intrinsic geometrical structure model space hybrid monte carlo markov chain monte carlo mcmc gilks et al approximates value manifold stochastic dynamics bayesian learning mean successive states ergodic markov chain invariant distribution addition ergodicity invariance another quality would like markov chain rapid exploration state space first two qualities rather easily attained achieving rapid exploration state space often nontrivial state art mcmc method capable sampling complex distributions hybrid monte carlo duane et al algorithm expressed terms sampling canonical distribution state physical system defined terms energy function oc exp allow use dynamical methods momentum variable introduced dimensionality canonical distribution phase space defined oc exp hamiltonian represents total energy kinetic energy due momentum defined mi momentum components mi mass associated th component different components given different weight sampling canonical distribution done using stochastic dynamics method andersen task split two subtasks sampling uniformly values fixed total energy sampling states different values first task done simulating hamiltonian dynamics system dqi pi dr opi dpi oh oe dr oqi qi different energy levels obtained occasional stochastic gibbs sampling geman geman momentum since independent may updated without reference drawing value probability density proportional exp case easily done since pi independent gaussian distributions practice hamiltonian dynamics cannot simulated exactly approximated discretization using finite time steps one common approximation leapfrog discretization neal hybrid monte carlo method stochastic dynamic transitions used generate candidate states metropolis algorithm metropolis et al eliminates certain note probability density nowhere zero put form simply defining log log convenient zlochin baram drawbacks stochastic dynamics systematic errors due leapfrog discretization since metropolis algorithm ensures every transition keeps canonical distribution invariant however empirical comparison uncorrected stochastic dynamics hmc application bayesian learning neural networks neal showed appropriate discretization stepsize notable difference two methods modification proposed horowitz instead gibbs sampling momentum replace time cos sin small angle distributed according keeping canonical distribution invariant scheme called momentum persistence improves rate exploration riemannian geometry riemannian manifold amari set equipped metric tensor positive semidefinite matrix defining inner product infinitesimal increments let us denote entries gi entries inner product naturally gives us norm ii jeffrey prior defined density function denotes determinant hamiitonian dynamics manifold riemannian manifold dynamics take general form one described section metric tensor masses set one hamiltonjan given dynamics governed following set differential equations chavel oe qi gi oqj fj qiqj dr christoffel symbols given og ogs gi oq oq dq rr related lp manifold stochastic dynamics bayesian learning riemannian geometry functions regression log likelihood proportional empirical error simply euclidean distance target point candidate function evaluated sample therefore natural distance measure models euclidean seminorm ii fox fo ii xi xi resulting metric tensor vof zi xi jr denotes gradient jacobian matrix bayesian geometry bayesian approach would suggest inclusion prior assumptions parameters manifold geometry example priori log posterior written logp oix xi ok inverse noise variance therefore natural metric model space xi zi metric tensor gb jt extended jacobian kroneker delta note gb hence prior becomes vaguer approach nonbayesian paradigm hand bayesian geometry approaches euclidean geometry parameter space qualities would like bayesian geometry prior strong comparison likelihood exact form little importance definitions applied log concave prior distribution inverse hessian log prior logp replacing framework restricted regression general distribution class natural use fisher information matrix metric tensor amari bayesian metric tensor becomes gb logp zlochin baram manifold stochastic dynamics mentioned energy landscape many regression problems anisotropic degrades performance hmc two aspects dynamics may optimal efficient exploration posterior distribution suggested studies gaussian diffusions hwang et al resulting differential equations stiff gear leading large discretization errors turn necessitates small time steps implying computational burden high problems disappear instead euclidean hamiltonian dynamics used hmc simulate dynamics manifold equipped metric tensor gb proposed previous section context regression definition gb jt obtain alternative deq equation matrix form deq roj dr rrq canonical distribution oc exp conditional distribution given zero mean gaussian covariance matrix marginal distribution proportional exp equivalent multiplying prior jeffrey prior sampling canonical distribution two fold simulate hamiltonian dynamics one time step using leapfrog discretisation replace using momentum persistence unlike hmc case momentum perturbation distributed according actual weights multiplying matrices may chosen different specified improve numerical stability empirical comparison robot arm problem compared performance manifold stochastic dynamics msd algorithm standard hmc comparison carried using mackay robot arm problem common benchmark bayesian methods neural networks mackay neal robot arm problem concerned mapping yl cos cos el sin sin el independent gaussian noise variables standard deviation dataset used neal mackay contained examples training set test set fact since actual prior weights unknown truly bayesian approach would use non informative prior rr paper kept modified prior product rr zero mean gaussian manifold stochastic dynamics bayesian learning msd figure average runs autocorrelation input hidden left hiddento output right weights hmc leapfrog steps per iteration msd single leapfrog step per iteration horizontal axis gives lags measured number iterations used neural network two input units one hidden layer containing tanh units two linear output units hyperparameter set correct value chosen algorithms compared msd two versions hmc leapfrog steps per iteration henceforth referred hmc hmc msd run single leapfrog step per iteration three algorithms momentum resampled using persistence cos single iteration hmc required floating point operations flops hmc required flops msd required flops hence computational load msd one third hmc times lower hmc discretization stepsize hmc chosen keep rejection rate equivalent criterion average error hamiltonian around used msd three sampling algorithms run times time iteration first samples discarded order allow algorithms reach regions high probability results one appropriate measure rate state space exploration weights autocorrelation neal shown figure behavior msd clearly superior hmc another value interest total squared error test set predictions test set made follows subsample parameter vectors wag generated taking every twentieth sample vector starting predicted value zlochin baram average empirical function distribution subsample total squared errors normalized respect variance test cases following statistics runs average standard deviation hmc hmc msd average error hmc high indicating algorithm failed reach region high probability errors hmc msd comparable standard deviation msd twice low hmc meaning estimate obtained using msd reliable conclusion described new algorithm efficient sampling complex distributions appearing bayesian learning non linear models empirical comparison shows algorithm achieves results superior best achieved existing algorithms considerably smaller computation time