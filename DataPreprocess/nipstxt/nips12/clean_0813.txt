abstract psychophysical physiological evidence shows sound localization acoustic signals strongly influenced synchrony visual signals effect known ventriloquism work sound coming side tv set feels coming mouth actors ventriloquism effect suggests important information sound location encoded synchrony audio video signals spite evidence audiovisual synchrony rarely used source information computer vision tasks paper explore use audio visual synchrony locate sound sources developed system searches regions visual landscape correlate highly acoustic signals tags likely contain acoustic source discuss experience implementing system present results speaker localization task discuss potential applications approach introduction present method locating sound sources sampling regions image correlate time auditory signal approach inspired psychophysical physiological evidence suggesting audio visual contingencies play important role localization sound sources sounds seem emanate visual stimuli synchronized sound effect becomes particularly noticeable perceived source sound known false case ventriloquist dummy television screen phenomenon known psychophysical community ventriloquism effect defined mislocation sounds toward apparent visual source effect robust wide variety conditions found strongly dependent degree synchrony auditory visual signals driver bertelson vroomen wiegeraad de gelder correspondence addressed hershey movellan ventriloquism effect fact less speech specific first thought example effect disrupted upside lip signal bertelson vroomen wiegeraad de gelder strong lip signals replaced light flashes synchronized amplitude peaks audio signal radeau bertelson crucial aspect correlation visual auditory intensity time light flashes synchronized effect disappears ventriloquism effect strong enough produce enduring localization bias known ventriloquism aftereffect time experience spatially offset auditory visual stimuli causes persistent shift subsequent auditory localization exposure audio visual stimuli offset degrees azimuth minutes sufficient shift auditory localization amount corresponding shift neural processing detected macaque monkeys early primary auditory cortex recanzone barn owls misalignment visual auditory stimuli development causes realignment auditory visual maps optic tectum zheng knudsen stryker feldman knudsen strength psychophysical physiological evidence suggests audiovisual contingency may used important source information currently underutilized computer vision tasks visual auditory sensor systems carry information events world information must combined correctly order useful interaction two modalities audiovisual contingency exploited help determine signals different modalities share common origin benefits two fold two signals help localize paired help interpret effect developed system localize speakers using input camera single microphone approach based searching regions image synchronized acoustic signal measuring synchrony concept audio visual synchrony well formalized psychophysical literature working definition interpret synchrony degree mutual information audio spatially localized video signals ultimately causal relationship often interested causes inferred effects synchrony let vector describing acoustic signal time components could cepstral coefficients pitch measurements outputs filter bank let vector describing visual signal time pixel components could represent gabor energy coefficients rgb color values etc consider set audio visual vectors tt tt sampled times tk tk spatial coordinates given set vectors goal provide number describes temporal contingency audio video time approach take consider vector independent sample joint multivariate gaussian process define audio visual synchrony time estimate mutual information audio visual components process let tk laa ea lav ev represents means covariance matrices let tk jointly gaussian af ea tk audio sion using audio sual synchrony locate sounds mutual information tk tk shown follows log lea log rre mlev log mlea ea tk llev og special case log tk tk pearson correlation coefficient triple estimate mutual information tk considering element independent sample random vector amounts computing estimates joint covariance matrix ea example estimate covariance th audio component jth video component would follows sa vj tk ai tk tk vj tk oj ai tk vj simple covariance estimates computed recursively constant time respect number timepoints independent treatment pixels would lend well parallel implementation measure performance secondary system produces single estimate auditory location use database labeled solitary audiovisual sources unfortunately many ways producing estimates becomes difficult separate performance measure underlying system model used centroid computation mutual information estimates enhancements aid tracking reduce background noise implementation issues real time system prototyped using quickcam linux operating system ported nt directshow filter platform provides input real time audio video capture hardware well static movie files video output could also rendered live compressed saved movie file implementation challenging turns rather difficult hershey andj movellan talking talking figure normalized audio visual intensity across sequences frames sequence four numbers spoken top trace contour acoustic energy one two speakers bottom trace contour intensity values single pixel near mouth process precisely time synchronized audio video serial machine real time multiple threads required read peripheral audio visual devices time audio visual streams reach av filter module quite separate asynchronous separately threaded auditory visual packet streams must synchronized buffered finally matched aligned time stamps finally processed interesting successful biologial audiovisual systems employ parallel architecture thus avoid problem results obtain performance baseline first tried simplest possible approach single audio visual feature per location ra intensity pixel time average acoustic energy interval msec sampling period ntsc video signal figure illustrates time course signals non synchronous synchronous pair acoustic energy pixel intensity notice particular synchonous pair sound pixel values come speaker relationship signals changes time regions positive negative covariance strung together succession clearly relationship entire sequence far linear however shorter time periods linear relationship looks like better approximation window size samples coincides approximately time scale perhaps averaging many small windows capture larger scale would lost method applied larger window course trade time scale sensitivity spurious transients response time system applied mutual information measure pixels movie spirit perceptual maps brain result changing topographic map audiovisual mutual information figure illustrates two snapshots audio ision using audio iqsual synchrony locate sounds frame left talking frame right talking figure estimated mutual information pixel intensity audio intensity bright areas indicate greater mutual information overlaid stills video one person mid utterance different parts face synchronous possibly different sign sound take part producing interesting synchrony shared parts eyes directly contribute sound contribute communication nonetheless estimate position speaker computed centroid point weighted estimated mutual information correpsonding pixel audio signal time step mutual information estimated using past frames order reduce intrusion spurious correlations competing targets target found employ gaussian influence function goodall influence function reduces weight given mutual information locations far current centroid computing next centroid allow speedy disengagement dwindling source mutual information set threshold mutual information measurements threshold treated zero threshold also reduces effects unwanted background noise camera microphone jitter log log represents estimate coordinate position speaker time thresholding function influence function depends upon position pixel sampled prior estimate estimate correlation intensity pixel acoustic enery using past video log corresponding estimate mutual information frames cancels quotient adjusting threshold function factor accordingly tried approach movie two people taking turns saying random digits figure shows estimates actual positions speaker hershey andy movellan function time estimates clearly provide information could used localize speaker especially combination approaches flesh detection frame number figure estimated actual position speaker frame six hundred flames sources took turns uttering series four digits three turns actual positions alternation times measured hand video recording conclusions presented exploratory work system localizing sound sources video signal tagging regions image correlated time auditory signal approach motivated wealth evidence psychophysical physiological literature showing sound localization strongly influenced synchrony visual signal presented measure local synchrony based modeling audio visual signal non stationary gaussian process developed general software tool accepts inputs major video audio file formats well direct input video camera tested tool speaker localization task encouraging results approach could practical applications localizing sound sources situations acoustic stereo cues inexistent unreliable example approach could used help localize actor talking video scene put closed captioned text near audio source approach could also used guide camera teleconferencing applications results reported encouraging work needs done practical applications developed example need investigate sophisticated methods processing audio video signals point use average energy represent video thus changes fundamental frequency affect average energy would captured model similarly local video decompositions like spatio temporal gabor filtering approaches designed enhance lip regions may helpful audio vision usingaudio visual synchrony locate sounds changing symmetry observed audio video signals might addressed rectifying squaring normalized signals derivatives finally relaxing gaussian constraints measure audio visual contingency may help improve performance work shown exploratory point approach promising emphasizes idea machine perception multimodal process backed psychophysical evidence combined approaches may help improve robustness tasks localization separation sound sources