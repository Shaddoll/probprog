abstract reliability accuracy spike trains shown depend nature stimulus neuron encodes adding ion channel stochasticity neuronal models results macroscopic behavior replicates input dependent reliability precision real neurons calculate amount information ion channel based stochastic hodgkin huxley hh neuron model encode wide set stimuli show information rate information per spike stochastic model similar values reported experimentally moreover amount information neuron encodes correlated amplitude fluctuations input less average firing rate neuron also show hh ion channel density information capacity robust changes density ion channels membrane whereas changing ratio na ion channels considerable effect information neuron encode finally suggest neurons may maximize information capacity appropriately balancing density different ion channels underlie neuronal excitability introduction capacity neurons encode information directly connected nature spike trains code namely whether fine temporal structure spike train carries information whether fine structure train mainly noise see experimental studies show neurons vitro vivo respond fluctuating inputs repeatable accurate spike trains whereas slowly varying inputs result lower repeatability jitter spike timing hence seems nature code utilized neuron depends input encodes recently suggested biophysical origin behavior stochascapacity robustness stochastic neuron models ticity single ion channels replacing average conductance dynamics hodgkin huxley hh model stochastic channel population dynamics yields stochastic neuron model replicates rather well spike trains reliability precision real neurons stochastic model also shows subthreshold oscillations spontaneous missing spikes observed experimentally direct measurement membranal noise also replicated successfully stochastic models neurons use many tens thousands ion channels encode synaptic current reaches soma trains spikes number ion channels underlies spike generation mechanism types depend activity neuron yet unclear changes may affect amount nature information neurons encode ask information encoding capacity stochastic hh model neuron capacity depend densities different ion channel types membrane show information rate information per spike stochastic hh model similar values reported experimentally neurons encode information highly fluctuating inputs information encoding capacity rather robust changes channel densities hh model interestingly show optimal channel population size around natural channel density hh model encoding capacity rather sensitive changes distribution channel types suggesting changes population ratios adaptation channel inactivation may change information content neurons stochastic hh model stochastic hh shh model expands classic hh model incorporating stochastic nature single ion channels specifically membrane voltage dynamics given hh description namely dv dt vl vk na vna membrane potential vl vk reversal potentials leakage potassium sodium currents respectively gl gk gn corresponding ion conductances cm membrane capacitance injected current ion channel stochasticity introduced replacing equations describing ion channel conductances explicit voltage dependent markovian kinetic models single ion channels based activation inactivation variables deterministic hh model channel one five different states rates transition states given following diagram nl nj refers number channels currently state nj labels single open state potassium channel voltage dependent rate functions hh formalism similar model used na channel na kinetic model states one open state see details potassium sodium membrane conductances given ilk gna mahx conductances ion channel na respectively take conductance single channel ps schneidman segev tishby na channel types ion channels thus respond stochastically closing opening gates according kinetic model fluctuating around average expected behavior figure demonstrates effect ion time sec time sec oo dc input cm dc input cm figure reliability firing patterns model isopotential hodgkin huxley membrane patch response different current inputs injecting slowly changing current input low pass gaussian white noise mean laa cm standard deviation laa cm convolved alpha function time constant msec top frame results high jitter timing spikes raster plots spike responses bottom frame patch stimulated repeatedly highly fluctuating stimulus laa cm er laa cm msec top frame jitter spike timing significantly smaller increased reliability fluctuating current input patch area used channels na channels compare fig see average firing rate response dc current input hh stochastic hh model coe cient variation inter spike interval shh model response dc inputs giving values comparable observed real neurons channel stochasticity showing response shh isopotential membrane patch standard shh channel densities repeated presentation suprathreshold current input slowly varying input repeatedly presented fig spike trains different spike firing time unreliable hand input highly fluctuating fig lb reliability spike timing relatively high stochastic model thus replicates input dependent reliability precision spike trains observed pyramidal cortical neurons cortical neurons repeatability precision spike trains stochastic model defined strongly correlated fluctuations current input may get sub millisecond precision curve stochastic model fig coefficient variation cv inter spike intervals isi distribution dc inputs fig similar behavior cortical neurons vivo clear contrast deterministic model number channels thus ratio total conductance single type ion channels single channel conductance standard shh densities na na channels per although total number channels model large microscopic level ion channel noise macroscopic effect spike train reliability since number capacity robustness stochastic neuron models information capacity shh neuron expanding repeatability precision measures turn quantify much information neuron model encodes stimuli receives thus present model set representative input current traces amount information respective spike trains encode calculated following mainen sejnowski use set input current traces imitate synaptic current reaches soma dendritic tree convolve gaussian white noise trace mean current standard deviation alpha function ra msec six different mean current values used cm five different std values cm yielding set input current traces seconds long set inputs representative wide variety current traces neurons might encounter vivo conditions sense average firing rates set inputs range hz shown present input traces model calculate amount information resulting spike trains convey input following input presented repeatedly resulting spike trains discretized ar bins using sliding window size along discretized sequence train spikes thus transformed sequence letter words consisting spike spike estimate probability word appear spike trains compute entropy rate total word distribution htot log bits word measures capacity information neuron spike trains hold examine set words neuron model used particular time repeated presentations stimulus estimate wit time dependent word probability distribution time calculate time dependent entropy rate take average entropies wlt log wlt bits word denotes average times oise noise entropy rate measures much fine structure spike trains neuron noise performing calculation inputs using different word sizes estimate limit total entropy noise entropy rates entropies converge real values see details figure shows total entropy rate responses set stimuli ranging bits sec total entropy rate correlated firing rates neuron shown noise entropy rate however depends different way input parameters figure shows noise entropy rate responses set stimuli may get bits sec specifically inputs high mean current values low fluctuation amplitude many spikes ion channels open near spike firing threshold rather small fluctuations small number open channels near firing threshold give rise input dependent reliability spike timing athe bin size msec set small enough keep fine temporal structure spike train within word sizes used yet large enough avoid undersampling problems schneidman segev hby noise even mean firing rate high difference neuron entropy rate total capacity information neuron spike train noise entropy rate exactly average rate information neuron spike trains encode input stimuius spike train htotat hnoise shown figure information rate sensitive size cm ij cm cm pa cm cm cm figure information capacity shh model total spike train entropy rate shh model function current input mean standard deviation see text details error bar values surface well frames range shown noise entropy rate function current input parameters information rate stimulus spike trains function input parameters calculated subtracting noise entropy total entropy note change grayscale information per spike function input parameters calculated normalizing results shown average firing rate responses inputs fluctuations input mean value current trace expected reliability precision spike timing observed vitro vivo well simulations dependence neural code input parameters better reflected calculating average amount information per spike model gives inputs fig see comparison values fly hi neuron effect changing neuron parameters information capacity increasing density ion channels membrane compared standard shh densities keeping ratio na channels fixed diminishes amount information neuron encodes inputs set however change rather small doubling channel density decreases amount information fig depending specific input decreasing channel densities types results encoding information certain stimuli less others figure shows half channel densities would result changes information directions thus information rates conveyed stochastic model robust changes ion channel density similar robustness shown observed changes membrane area keeping channel capacity robustness stochastic neuron models density fixed temperature effects channel kinetics however cm cm rl ha cm cm ha cm pa cm figure effect changing ion channel densities information capacity ratio information rate shh model twice density standard shh densities divided information rate mode standard shh densities shh model half standard densities ratio info rate shh model twice many na channels divided info rate standard shh na channel density channel density remains untouched note change graycale shh model number na channels reduced half changing density na channels alone larger impact amount information neuron conveys stimuli increasing na channel density factor two results less information stimuli gain others fig however reducing number na channels half results drastic loss information inputs fig discussion shown amount information stochastic hh model encodes current input highly correlated amplitude fluctuations input less mean value input stochastic hh model incorporates ion channel noise closely replicates input dependent reliability precision spike trains observed cortical neurons information rates information per spike also similar real neurons biological systems demonstrate robustness macroscopic performance changes cellular properties information coding rates shh model robust changes ion channels densities well area excitable membrane patch temperature kinetics channel dynamics however information coding rates rather sensitive changes ratio densities different ion channel types suggests ratio density channels na channels standard shh model may optimal terms information capacity may important implications nature neural code adaptation learning suggest notions optimality robustness may key biophysical principle operation real neurons investigations take account activity dependent nature channels schneidman segev ilshby neuron notion local learning rules could modify neuronal suggest local learning rules acknowledgements research supported grant ministry science israel references rieke warland de ruyter van steveninck bialek spike exploring neural code mit press shadlen newsome noise neural codes cortical organization curt opin neurobiol mainen sejnowski reliability spike timing neocortical neurons science nowak sanches vives mccormick influence low high frequency inputs spike timing visual cortical neurons cerebral cortex bair koch temporal precision spike trains extrastriate cortex behaving macaque monkey neural comp de ruyter van steveninck lewen strong koberle bialek reproducibility variability neural spike trains science reich victor knight ozaki kaplan response variability timing precision neuronal spike trains vivo neurophysiol hodgkin huxley quantitative description membrane current application conduction excitation nerve physiol fitzhugh kinetic model conductance changes nerve membrane cell comp physiol defelice introduction membrane noise perseus books skaugen walloe firing behavior stochastic nerve membrane model based upon hodgkin huxley equations acta physiol scand schneidman freedman segev ion channel stochasticity may critical determining reliability precision spike timing neural comp white klink alonso kay noise voltage gated channels may influence neuronal dynamics entorhinal cortex neurophysiol hille ionic channels excitable membrane sinauer associates nd ed marder abbott turrigiano liu golowasch memory dynamics intrinsic membrane currents proc natl acad sci toib lyakhov marom interaction duration activity rate recovery slow inactivation mammalian brain na channels neurosci strassberg defelice limits hh formalism effects single channel kinetics transmembrane voltage dynamics neural comp softky koch highly irregular firing cortical cells inconsistent temporal integration random epsps neurosci strong koberle de ruyter van steveninck bialek entropy information neural spike trains phys rev left cover thomas elements information theory wiley barkai leibler robustness simple biochemical networks nature stemruler koch voltage dependent conductances adapt maximize information encoded neuronal firing rate nat neurosci