abstract articl studi effect introduc structur input distribut data learnt simpl perceptron determin learn curv within framework statist mechan stepwis gener occur function number exampl distribut pattern highli anisotrop although extrem simpl model seem captur relev featur class support vector machin recent shown present behavior introduct new approach learn recent propos altern feedforward neural network support vector machin svm instead tri learn non linear map input pattern intern represent like multilay perceptron svm choos priori non linear kernel transform input space high dimension featur space binari classif task like consid present paper svm look linear separ optim margin featur space main advantag svm learn becom convex optim problem difficulti mani local minima hinder process train multilay neural network thu avoid one question rais approach svm overfit data spite extrem larg dimens featur space consid two recent theoret paper studi famili svm tool statist mechan predict typic properti limit larg dimension space paper consid map gener polynomi kernel specif quadrat one input vector transform dimension featur vector precis map xlx xkx studi function number quadrat featur xlx xnx consid lead differ result map particular case quadrat kernel particular case learn quadrat separ task map gener error decreas lower bound number exampl proport follow decreas number exampl increas proport dimens featur risau gusman gordon space fact behavior specif svm also aris typic case gibb learn defin quadrat featur space increas train set size quadrat compon discrimin surfac learnt linear one case learn linearli separ task quadrat featur space effect overfit harmless slow decreas gener error train set size case map overfit dramat gener error given train set size increas number featur aim present paper understand influenc map scalingfactor gener perform svm end worth remark featur may obtain compress quadrat subspac fix factor order mimic contract consid linearli separ task input pattern highli anisotrop distribut varianc one subspac much smaller orthogon direct show simpl toy model gener error function train set size exhibit cross two differ behavior rapid decreas correspond learn compon uncompress space follow slow improv mainli compon compress space learnt latter would correspond highli styliz model learn scale quadrat featur svm map paper organ follow short present model describ main step statist mechan calcul order paramet caracter properti learn process defin evolut function train set size analyz two regim gener error describ determin train set size per input dimens crossov function pertin paramet final discuss result relev understand gener properti svm model consid problem learn binari classif task exampl train data set contain dimension pattern sign given teacher weight wn without loss gener consid normal teacher assum compon input pattern independ ident distribut random variabl drawn zero mean gaussian distribut varianc along nc direct unit varianc nu remain one nc nu ra exp ff exp take without loss gener case may deduc former straightforward rescal nc nu hereaft subspac dimens nc varianc call compress subspac correspond orthogon subspac dimens nu nc call uncompress subspac studi typic gener error student perceptron learn classif task use tool statist mechan pertin cost function understand stepwis gener svm toy model number misclassifi pattern weight vector version space correspond vanish cost choos random posteriori distribut po exp limit call gibb learn eq equival invers temperatur statist mechan formul cost energi function assum priori distribut weight uniform hyperspher radiu po normal constant lead order term hyperspher surfac dimension space partit function ensur correct normal wl dw po exp gener properti student relat free energi lnz limit train set size per input dimens pin constant properti student weight becom independ particular train set deduc averag free energi per degre freedom calcul use replica trick lnz va lim lnzn va overlin repres averag compos pattern select accord case gibb learn typic behavior intens quantiti obtain zero temperatur limit oc limit errorfre solut vanish cost non vanish posterior probabl thu gibb learn correspond pick random student version space vector classifi correctli train set probabl proport case isotrop pattern distribut correspond properti cost function extens studi case pattern drawn two gaussian cluster symmetri axi cluster differ teacher axi recent address consid problem instead singl direct along pattern distribut contract expand finit fraction compress dimens case properti student perceptron may express term follow order paramet satisfi correspond extremum condit free energi ua aw risau gusman gordon waw nc aw wi indic averag posterior replica indic subcript stand compress uncompress respect notic impos typic squar norm student compon compress subspac equal correspond teacher norm ien order paramet learn curv assum order paramet invari permut replica drop replica indic equat expect hypothesi replica symmetri consist like case perceptron learn realiz task problem thu reduc determin five order paramet mean becom clearer consid follow combin qc qu rc ru kc qx wi qc qu typic overlap compon two student vector compress uncompress subspac respect similarli rc ru correspond overlap typic student teacher term set paramet typic gener error eg arcco rc ruv given gener solut extremum condit depend three paramet problem name nc nc interest case one teacher anisotropi consist pattern distribut nc case easi show qc rc qu thu nuru ncrc ff nu nu ru rc given follow equat rc exp rt nc nu tv understand stepwis gener svm toy model rg figur order paramet gener error case nc curv case spheric distribut pattern shown comparison inset show first step learn plateau see text ac au rc ru dt recov equat correspond gibb learn isotrop pattern distribut order paramet repres function figur particular choic nc ru grow much faster rc mean easier learn compon uncompress space result therefor gener error present cross two behavior small ru ra nu nc nu nc ra overlap gibb learn isotrop distribut learn anisotrop distribut faster learn isotrop one anisotropi larg increas like ra effect train set size per input dimens increas intermedi regim ru increas rc nu nc correspond gener error seem reach plateau correspond rc asymptot behavior independ detail distribut like crossov two regim occur nu nc nc case also interest correspond teacher weight compon compress subspac wherea risau gusman gordon figur gener error function differ teacher case nc curv spheric distribut pattern includ comparison inset show larg alpha behavior correspond teacher orthogon compress subspac compon uncompress subspac correspond respect task either uncompress compress compon irrelev pattern classif figur show gener error curv includ gener error egg uniform distribut comparison behaviour eg sensit valu teacher compress subspac learn difficult consequ egg expect contrari compon uncompress space relev classif task subspac learn easi eg egg crossov regim alreadi discuss curv merg asymptot regim may seen inset figur discuss analyz typic learn behavior toy perceptton model allow clarifi aspect gener high dimension featur space particular captur element essenti obtain stepwis learn shown stem compress high order featur compon compress space difficult learn compress thu understand stepwis gener svm toy model train set larg enough mainli latter learnt result allow understand import scale high order featur svm kernel fact svm one choos priori kernel map input space featur space high order featur conveni compress hierarch learn occur low order featur learnt first higher order featur learnt train set larg enough case higher order featur irrelev like hinder learn process interest behavior allow avoid overfit comput simul current progress svm gener quadrat kernel without scale show behavior consist theoret predict may understood present toy model