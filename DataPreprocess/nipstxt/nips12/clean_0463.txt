abstract describe class probabilistic models call credibility networks using parse trees internal representations images credibility networks able perform segmentation recognition simultaneously removing need ad hoc segmentation heuristics promising results problem segmenting handwritten digits obtained introduction task recognition main focus attention statistical pattern recognition past years paradigm problem classify object vector features extracted image advent backpropagation choice features choice weights put features became part single overall optimization impressive performance obtained restricted important tasks handwritten character identification significant weakness many current recognition systems reliance separate preprocessing stage segments one object scene approximately normalizes systems segmentation precedes recognition suffer fact segmenter know shape object segmenting cannot use shape information help also segmenting image remove object recognized context arises although helps removing clutter present rest image might also reduce ability recognize object correctly context object arises gives great deal information nature object finally object described terms parts also viewed objects right raises question fine grained segmentations words david marr nose object head one man horseback hinton ghahramani teh successes structural linguistics inspired alternative approach pattern recognition paradigm problem parse image using hierarchical grammar scenes objects within linguistics structural approach seen advance earlier statistical approaches many years linguists eschewed probabilities even though known since version em algorithm could used fit stochastic context free grammars structural pattern recognition inherited linguists aversion probabilities result never worked well real data advent graphical models become clear structure probabilities coexist moreover explaining away phenomenon central inference directed acyclic graphical models exactly needed performing inferences possible segmentations image paper describe image interpretation system combines segmentation recognition inference process central idea use parse trees images graphical models called credibility networks describe joint distribution latent variables possible parse trees used section describe current statistical models image interpretation section develop credibility networks section derive useful learning inference rules binary credibility networks section demonstrate binary credibility networks useful solving problem classifying segmenting binary handwritten digits finally section end discussion directions future research related work neal introduced generative models composed multiple layers stochastic logistic units connected directed acyclic graph general unit multiple parents intractable compute posterior distribution hidden variables certain variables observed however neal showed gibbs sampling used effectively inference efficient methods approximating posterior distribution introduced later approaches shown yield good density models binary images handwritten digits problem models make inappropriate modeling images fail respect single parent constraint correct interpretation image opaque objects object part belongs one object images need parse trees parse dags multiscale models interesting generative models images use fixed tree structure nodes high tree control large blocks image bottom level leaves correspond individual pixels tree structure used easy compute exact posterior distribution latent non terminal nodes given image result approach worked much better markov random fields generally involve intractable partition function disadvantage serious block boundary artifacts though overlapping trees used smooth transition one block another serious disadvantage tree cannot possibly correspond parse tree every image zemel mozer hinton proposed neural network model activities neurons used represent instantiation parameters objects parts viewpoint dependent coordinate transformation object intrinsic coordinate system image coordinate system weights connections used represent viewpoint invariant relationship instantiation parameters whole rigid object instantiation paramelearning parse images ters parts model captures viewpoint invariance nicely corresponds way viewpoint effects handled computer graphics good inference procedure hierarchical models systematic way sharing modules recognize parts objects among multiple competing object models simard et al noted small changes object instantiati parameters result approximately linear changes real valued pixel intensities captured successfully linear models model larger changes many locally linear models pieced together hinton dayan revow proposed mixture factor analyzers tipping bishop recently shown make approach much computationally efficient make approach really efficient however necessary multiple levels factor analyzers allow analyzer one level shared several competing analyzers next level deciding subset analyzers one level controlled one analyzer level equivalent image segmentation construction part parse tree literature linear models contains proposals achieve new approach image interpretation developed class graphical models called credibility networks possible interpretations image parse trees nodes representing objectparts containing latent variables given dag possible parse trees image constrained individual collections trees unit satisfies single parent constraint leaves pixels image credibility networks describe joint distribution latent variables possible tree structures em algorithm used fit credibility networks data let node graph three random variables associated first multinomial variate hi ij pa describes parent among potential parents pa ij parent parent second binary variate si determines whether object present si si third latent variables xi describe pose deformation object let si connection three parameters also first cij unnormalized prior probability parent given object present actual prior probability cijsj rij ek pa iksk assume always unit pa acts default parent potential parent present makes sure denominator never second parameter pij conditional probability object present given parent aij third parameter tij characterizes distribution xi given aij xj let cij pij tij pa using bayes rule joint distribution given xi sio xia note together define parse tree image given parse tree distribution latent variables xia technically object represented node hinton ghahrarnani teh efficiently inferred image actual form xia unimportant joint distribution sio ri ii rijpisj pij pa binary credibility networks simulation results section based simplified version credibility networks latent variables ignored notice sum joint distribution rijpisj pij pa using bayes rule dividing cijsjpisj pij ek pa cikskp pik pa pij view vij unnormalized posterior probalet rij ijpij bility parent given object present actual posterior fraction rqs ij ekepa riksk given observations let hidden variables approximate posterior distribution using factored distribution ri si variational free energy eq logp sl log eq log cijsj log cijsjpisj pij pa pa ailogai ai log ai negative free energy lower bound log likelihood generating observations variational em algorithm improves bound iteratively improving respect step step let ch possible children inference rules derived ai sigmoid let training set qa mean field approximation posterior distribution given training data observation ed learning learning parse images figure sample images test set classes two digits image row given left rules er wij rij co log cij te eqd js ij zqa ij efficient implementation credibility networks using mean field approximations still need evaluate terms form logx ell weighted sum binary random variates implementation used simplest approximations logx log ell lie although bi ed implementation works well enough general segmenting handwritten digits hinton revow used mixture factor analyzers model segment estimate pose digit strings digits overlap model able identify digits present segment image easily hard cases two digits overlap significantly assess ability credibility networks segmenting handwritten digits used superpositions digits exactly location problem much harder segmenting digit strings digits partially overlap data used set images single digits classes derived cedar cdrom database image size size credibility network middle layer units meant encode low level features top level units meant encode digit class used images single digits class train network trained segment images training clamped activation top layer unit corresponding class digit current image fixing rest training network first tested images single digits training set predicted class image taken hinton ghahramani teh figure segmentations pairs digits make comparisons easier show overlapping image columns class corresponding top layer unit highest activation error rate showed network images two overlapping digits distinct classes images per combination two classes examples given figure predicted classes two digits chosen corresponding classes top layer units highest activations human subject namely third author tested test set network achieved error rate author erred images fact produce segmentation image image class present recall given values posterior probability unit pixel parent ij posterior probability pixel belonging digit class ej eq coijc jk gives simple way segment image figure shows number segmentations note pixel sum probabilities pixel belonging digit class make picture clearer white pixel means probability belonging class black means probability intensity gray pixel describes size probability figures shows successful segmentations figure shows unsuccessful segmentations discussion using parse trees internal representations images credibility networks avoid usual problems associated bottom approach image interpretation segmentation carried statistically sound manner removing need hand crafted ad hoc segmentation heuristics granularity problem segmentation also resolved since credibility networks use parse trees internal representations images parse trees describe segmentations image every level granularity individual pixels whole image plan develop implement credibility networks latent variable xi multivariate gaussian node represent position orientation scale object conditional probability models links represent relationship moderately deformable object parts learning parse images acknowledgments thank chris williams stuart russell phil dawid helpful discussions nserc itrc funding