abstract paper use mutual information characterize distributions phonetic speaker channel information timefrequency space mutual information mi phonetic label one feature joint mutual information jmi phonetic label two three features estimated miller bias formulas entropy mutual information estimates extended include higher order terms mi jmi speaker channel recognition also estimated results complementary phonetic classification results show phonetic information locally spread speaker channel information globally spread time frequency introduction speech signals typically carry information number target sources linguistic message speaker identity environment speech produced realistic applications speech technology one information targets important example one may interested identifying message signal regardless speaker environments speech produced identification speaker needed regardless words targeted speaker saying thus components signal may equally relevant decoding targeted information signal speech research community disposal rather large speech databases mainly used training testing automatic speech recognition asr systems relatively efforts date use databases deriving reusable knowledge speech speech communication processes could used improvements asr technology paper apply information theoretic approaches study large hand labeled data set fluent speech learn information structure speech signal including distribution speech information frequency time based labeled data set analyze relevancy features phonetic yang hermansky classifications speaker channel variability features data set labeled respect underlying phonetic classes files features come phoneme labels relate linguistic message signal file labels carry information speakers communication channels file contains speech single speaker transmitted one telephone channel thus phoneme file labels two target variables statistical inference phoneme labels take different values corresponding broad phoneme categories ogi stories database file labels take different values representing different speakers ogi stories database relevancy set features measured joint mutual information jmi features target variable phoneme target variable represents case linguistic message file target variable represents different speakers different telephone channels joint mutual information target variable features quantifies relevancy features target variable mutual information measure statistical dependence random variables morris et al used mutual information find critical points information classifying french vowel plosive vowel utterances bilmes showed recently information appears spread relatively long temporal spans bilmes used mutual information two variables nonlabeled data reveal mutual dependencies components spectral energies time frequency focused joint mutual information phoneme labels file labels one two three feature variables time frequency planet used concept gain insight information phonemes speaker channel variability distributed time frequency plane data set preprocessing data set used paper hour phonetically labeled telephone speech subset english portion stories ogi multi lingual database containing approximately seconds extemporaneous speech different speakers speech data labeled variable taking values representing often occurring phoneme categories average phoneme duration ms number phoneme instances acoustic features fk experiments derived short time analysis speech signal ms analysis window hamming frame advanced ms steps logarithmic energy frequency fk computed squared magnitude fft using critical band spaced log like frequency variable weighting function manner similar computation perceptual linear prediction coefficients particular th th th bands centered around khz respectively feature labeled phoneme label yp file label yf use mutual information measure relevancy across frequencies context window phoneme classification speaker channel identification estimation mi bias correction paper consider mutual information mi discrete random variables phoneme label file label discrete random variables search information bearing components speech however feature variables bounded continuous variables obtain quantized features divide maximum range observed features cells equal volume use histogram estimate mutual information defined ep log jointly gaussian correlation coefficient however speech data feature variables generally non gaussian target variables categorical type variables correlations involving categorical variable meaningless mi also written vlx xlv yix conditional entropy defined yix yl log ylx two equations mean mi uncertainty reduction give uncertainty reduction give based histogram estimated ni ni og ni number data points th cell data size estimated miller shown underestimate overestimate biases nfi ln number cells respectively interestingly first order terms depend probability distribution using formulas correct estimates new estimates variances old estimates reduced biases however formulas break order extending miller approach find high order correction bias let pi probability distribution pi pi yang hermansky last two terms bias depend unknown probabilities pi practice approximated relative frequency estimates similarly find bias formulas high order terms mi estimate evenly distributed pi pi ln ln theoretically pi upper bound one probabilities close zero however practice hard collect sample estimate small probability reason assume pi either zero greater small constant depend assumption pi amplitude last term less mi speech phonetic classification three hour telephone speech ogi database gives us sample size greater million estimate mutual information three features target variable need estimate entropy take number bins feature variable number phoneme categories total number cells constant adjustment assuming bias ln bits shown fig relevant features phonetic classification fig bark mi spread around current frame ms given one feature information gain due second feature difference xx lxx called information gain given conditional mutual information defined yix xl yp ylx log xl ylx lxx ylxx shown rig given across different bands maximum information gain achieved within bark band maximum information gain achieved fs mutual informations fk information gain second feature vicinity first one shown fig asymmetric distribution mi around neighborhood rs indicates phonetic information spread asymmetrically time localized ms around current frame based data set bits jmi three frequency features three temporal features shown fig based estimates three frequency features give reduction uncertainty three temporal features give reduction search information bearing components speech bark bark time shift ms time shift ms bark time shift ms figure mis individual features different bands mis individual feature bark different ms frame shifts jmis two features bark bands jmis two features current frame shifted frames bark jmis three features bark bark bands dashed line jmi level achieved two features fs jmls three features current frame th frame current frame shifted frames bark dashed line jmi level achieved fs fs size data set therefore reliably estimate joint yang hermansky mi three features phoneme label however estimate jmi features problem curse dimensionality since features exponential increasing example second order bias bits high ignored extend approach beyond current three feature level need either enlarge data set find alternative histogram based mi estimation ba frame shift ms figure plot joint mutual information around asymmetric distribution apparent especially around bark bark bark th band oo figure mi one frequency feature file label jmi two features file identity labels mi speech speaker channel recognition linguistic variability expressed phoneme labels variability present speech use mutual information evaluate relevance search information bearing components speech sources variabilities speaker channel variability taking file label target variable estimated mutual information one two features shown fig relevant features low frequency channels case telephone speech carry little speech information fig shows second relevant feature speaker channel recognition least ms apart first relevant feature results suggest information speaker communication channel localized time results complementary results phonetic classification shown rig conclusions results shown information theoretic analysis labeled speech data feasible useful obtaining reusable knowledge speech channel variabilities joint mutual information two features phonetic classification asymmetric around current frame also estimated joint mutual information phoneme labels three feature variables uncertainty phonetic classification reduced adding features maximum uncertainty reductions due three frequency features three temporal features respectively mutual informations one two features speaker channel recognition estimated results show relevant features low frequency bands bark bark second relevant temporal feature speaker channel recognition least ms apart first relevant feature results suggest information speaker communication channel localized time results complementary results phonetic classification mutual information generally localized time spread