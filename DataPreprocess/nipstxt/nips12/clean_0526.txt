abstract incorpor prior knowledg construct nonlinear algorithm invari featur extract discrimin employ unifi framework term nonlinear variant rayleigh coeffici propos non linear gener fisher discrimin orient pca use support vector kernel function extens simul show util approach introduct common practic preprocess data extract linear nonlinear featur well known featur extract techniqu princip compon analysi pca aim find orthonorm order basi th direct describ much varianc possibl maintain orthogon direct howev sinc pca linear techniqu limit captur interest nonlinear structur data set nonlinear gener propos among kernel pca comput princip compon data set map nonlinearli high dimension featur space often one prior inform instanc might know sampl corrupt nois invari classif chang featur extract concept known nois transform invari certain degre equival interpret caus chang featur ought minim clearli invari alon suffici condit good featur could simpli take constant function one would like obtain featur invari possibl still cover much inform necessari describ particular data consid one linear featur vector restrict first second order statist data one arriv maxim call rayleigh coeffici wtsw wv vw invari featur extract classif kernel space featur vector matric describ desir undesir properti featur respect inform nois data covari nois covari obtain orient pca leav field data descript perform supervis classif common choos separ class center class varianc within class varianc case recov well known fisher discrimin ratio maxim cover much inform code avoid one code problem known solv analog pca gener symmetr eigenproblem vw correspond biggest eigenvalu paper gener set nonlinear one analog first map data via nonlinear map high dimension featur space optim avoid work map data explicitli might imposs infinit dimension introduc support vector kernel function well known kernel trick kernel function comput dot product featur space formul algorithm use dot product replac occurr dot product kernel function possibl choic proven use support vector machin kernel pca gaussian rbf exp llx yll polynomi kernel posit constant respect remaind paper organ follow next section show formul optim problem induc featur space section consid variou way find fisher discrimin conclud extens experi section discuss find kernel rayleigh coeffici optim kernel featur space need find formul use dot product imag numer denomin scalar done independ furthermor matric basic covari thu sum outer product imag therefor due linear natur everi solut written expans term map train data defin common choic let train sampl appropri cl two subclass ixil get full covari sb sw oper finit dimension subspac span xi possibl infinit space let span xi span xi symmetr vl lie span ci oper subspac exist expans maxim mika riitsch weston sch lkopf smola miiller could use st orient kernel pca sn could use estim nois covari analog definit map pattern sampl assum nois distribut standard formul fisher discrimin yield kernel fisher discrimin kfd given sw mi mi sb afl within class scatter sw sn class scatter si st mi sampl mean pattern class incorpor known invari orient kernel pca one could use tangent covari matrix small local paramet transform finit differ approxim covari tangent point detail use st orient kernel pca impos invari local transform crucial matrix construct train pattern therefor argument use find expans slightli incorrect neverthless assum reason approxim describ varianc induc multipli either matric left right expans find formul use dot product sake breviti give explicit formul kfd cf detail defin ea exi xj write kfd ru ffna dna kk eil il kij xi xj result choic sn case orient kernel pca transform invari obtain along line note still maxim rayleigh coeffici howev quotient term expans coeffici term potenti infinit dimensionai space furthermor well known solut special eigenproblem direct solv use choleski factor project new pattern onto comput ai xi algorithm estim covari matrix rank sampl ill pose furthermor perform explicit center covari matrix lose one dimens rank even wors kfd matrix rank thu ratio well defin anymor denomin might becom zero follow propos sever way deal problem kfd furthermor tackl question solv optim problem kfd effici far eigenproblem size becom larg numer demand reformul origin problem allow overcom limit final describ connect kfd rbf network invari featur extract classif kernel space regular solut subspac note matrix rank besid numer problem caus matrix even posit could think impos regular control capac end simpli add multipl ident matrix replac nu view differ way make problem feasibl numer stabl becom posit ii seen decreas bia sampl base estim eigenvalu cf iii impos regular lieill favor solut small expans coeffici furthermor one could use regular type addit penal iiw analog svm ad kernel matrix kij xi xj optim need solv eigenproblem might intract larg solut spars one directli use effici algorithm like chunk support vector machin cf end might restrict solut lie subspac instead expand write pattern zi could either subset train pattern estim cluster algorithm deriv chang end matric anoth advantag increas rank rel size although still might need regular quadrat optim sparsif even full rank maxim underdetermin optim multipl thereof sinc rmc tz rank one thu seek vector anna minim fix rtz solut uniqu find optim solv quadrat optim problem min anna subject tz although quadrat optim problem easier solv eigenproblem appeal interpret constraint ensur averag class distanc project onto direct discrimin constant intra class varianc minim maxim averag margin contrarili svm approach optim larg minim margin consid abl overcom anoth shortcom kfd solut spars thu evalu expens solv add regular aiic object function regular paramet allow us adjust degre spars connect rbf network interestingli exist close connect rbf network kfd add regular expand train pattern find optim given symmetr posit matrix kernel element xi xj label vector rbf network see note written kdk rank yi vector pattern class zero otherwis mika rtitsch weston sch kopf smola andk miiller banana cancer diabet german heart imag ringnorm sonar splice thyroid titan twonorm waveform rbf ab abr oj svm kfd tabl com parison kfd singl rbf classifi adaboost ab regul ada boost abr svm see text best suit bold face second best ital kernel sampl fix kernel width give solut mean squar error label output minim also case restrict expans exist connect rbf network smaller number center cf experi kernel fisher discrimin figur show illustr comparison featur found kfd kernel pca kfd featur discrimin two class first kernel pca featur pick import nonlinear structur evalu perform kfd real data set perform extens comparison state art classifi whose detail report compar kernel fisher discrimin support vector machin gaussian kernel adaboost regular adaboost cf tabl kfd use regular within class scatter comput project onto optim direct mean use classif estim threshold done tri threshold two output train set select median smallest empir error comput threshold maxim margin output analog support vector machin deal error trainig set use svm soft margin approach disadvantag howev control regular constant slack variabl result tabl show averag test error standard full rank null space span yl null space ly get free fix constraint posit constant also feasibl sthe breast cancer domain obtain univers medic center inst oncolog ljubljana yugoslavia thank zwitter soklic data data set use experi obtain via http www first gmd de raetsch figur comparison featur found kfd left first kernel pca featur right depict two class inform use kfd dot cross level featur valu polynomi kernel degre two kfd regular within class scatter invari featur extract classif kernel space deviat averag estim run differ realiz dataset estim necessari paramet ran fold cross valid first five realiz train set took model paramet median five estim see detail experiment setup use prior knowledg toy exampl figur show comparison kernel pca orient kernel pca use full covari nois matrix tangent covari rotat pattern ii along axi translat pattern toy exampl show impos desir invari yield meaning invari featur anoth experi incorpor prior knowledg kfd use usp databas handwritten digit consist train test pattern dimension gray scale imag digit use regular within class scatter ad multipl tangent covari nu invari transform chosen horizont vertic translat rotat thicken cf simpli averag matric correspond transform featur extract use restrict expans pattern zi first train sampl kernel chosen gaussian width optim svm class train one kfd classifi class rest comput class error winnertak scheme threshold estim minim empir risk normal output kfd without invari achiev test error slightli better plain svm kernel use tangent covari matrix led slight improv result significantli better correspond one kfd attribut fact use expans coeffici case tangent covari matrix howev live slightli differ subspac inde subsequ experi use vector obtain cluster larger dataset includ virtual exampl gener appropri invari transform led compar svm use prior knowledg best svm result local kernel virtual support vector conclus task learn data equival prior knowledg invari specif sourc nois case featur extract seek featur suffici nois invari still describ interest structur orient pca close relat fisher discrimin use particularli simpl featur sinc consid first second order statist maxim rayleigh coeffici sinc linear method restrict mani real world applic use support vector kernel function obtain nonlinear version algorithm name orient kernel pca kernel fisher discrimin analysi experi show kernel fisher discrimin competit figur comparison first featur found kernel pca orient kernel pca see text left right kpca okpca rotat translat invari gaussian kernel mika riitsch weston scholkopf smola mailer case even superior state art algorithm test interestingli svm kfd construct hyperplan sens optim mani case one given solut kfd superior one svm encourag preliminari result digit recognit believ report result improv incorpor differ invari use local kernel futur research focu improv algorithm complex new algorithm far larger one svm algorithm connect kfd support vector machin cf acknowledg work partial support grant dfg ja ec storm project number carri bs gmd first