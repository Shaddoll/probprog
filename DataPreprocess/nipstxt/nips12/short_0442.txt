abstract ever sinc pearl probabl propag algorithm graph cycl shown produc excel result error correct decod year ago curiou whether local probabl propag could use success machin learn one simplest adapt model factor analyz two layer network model bottom layer sensori input linear combin top layer factor plu independ gaussian sensor nois show local probabl propag factor analyz network usual take iter perform accur infer even network sensor factor deriv express algorithm fix point show fix point match exact solut varieti network even fix point unstabl also show method use success perform infer approxim em give result onlin face recognit task factor analysi simpl way encod input pattern suppos input wellapproxim linear combin compon vector amplitud vector modul match input given train set appropri set compon vector depend expect modul level behav emd measur distanc input approxim effect captur gener probabl model specifi distribut modul level zk distribut xlz sensor given modul level princip compon analysi independ compon analysi factor analysi view maximum likelihood learn model type assum train set appropri modul level independ overal distort given sum individu sensor distort factor analysi modul level call factor distribut follow form xnlz xn ek nkzk lp zk xlz az paramet model factor load matrix element emd diagon sensor nois covari matrix diagon element pn belief network factor analyz shown fig la likelihood hf hf az dz hf aa local probabl propag factor analysi figur belief network factor analysi high dimension data onlin factor analysi consist adapt increas likelihood current input vector pixel imag fig lb probabilist infer comput estim zlx need dimension reduct fill unobserv factor onlin em type learn paper focu method infer independ factor zlx gaussian turn posterior mean varianc factor zlx ia iat ix diag cov zlx diag la given comput valu exactli take comput mainli time need comput ia sinc kn connect network exact infer take least bottom top iter cours network go appli time infer batch em matric comput reus howev directli applic onlin learn biolog model one way circumv comput matric keep separ recognit network approxim zlx rx dayan et al optim recognit network approxim jointli estim gener network recognit network use onlin wakesleep learn hinton et al probabl propag factor analyz network recent result error correct code show case pearl probabl propag algorithm exact probabilist infer graph tree give excel perform even network contain mani cycl minim cut set exponenti prey mackay prey mackay fact probabl propag algorithm decod lowdens pariti check code mackay turbocod berrou glavieux wide consid major breakthrough inform theori commun network contain cycl local comput give rise iter algorithm hope converg good answer littl known converg properti algorithm network contain singl cycl success analyz weiss smyth et al result network contain mani cycl much less reveal probabl messag produc probabl propag factor analyz network fig la gaussian iter propag consist pass mean varianc along edg bottom pass follow pass mean varianc along edg top pass instant fre bottom mean varianc combin form estim mean varianc modul level given input initi varianc mean sent kth top layer unit nth sensor set bottom pass begin comput nois lkn level error signal sensor use top varianc mean previou iter nk kn xn nk kn use comput bottom varianc mean follow ni knk nk bottom varianc mean combin form current estim modul rianc mean zn bnk nk pnk top pass proce comput top varianc mean follow bn lv lkn kn notic varianc updat independ mean updat wherea mean updat depend varianc updat perform local probabl propag creat total factor analysi network differ size rang size network measur infer error function number iter propag network given size produc draw standard normal distribut draw sensor varianc exponenti distribut similar procedur use neal dayan mean random network pattern simul network probabl propag appli use simul pattern input measur error estim correct valu zlx comput differ code cost exact posterior distribut normal get averag number nat per top layer unit fig show infer error logarithm scale versu number iter maximum differ network size case median error reduc hat within iter rate converg error improv larger indic gener trend error curv drop increas contrast rate converg error appear worsen larger shown gener slight trend error curv rise increas network actual diverg better understand diverg case studi mean varianc diverg network case varianc converg within iter wherea mean oscil diverg network diverg shown fig observ suggest gener dynam determin dynam mean updat fix point condit global converg varianc updat converg dynam probabl propag factor analysi network becom linear allow us deriv fix point propag close form write eigenvalu condit global converg local probabl propag factor analysi lo ii lo lo figur perform probabl propag median infer error bold curv logarithm scale function number iter differ size network parameter two curv adjac bold curv show rang within error lie error fourth topmost curv error bottom varianc top mean function number iter maximum diverg network size analyz system mean updat defin follow length kn vector mean input ik xl xl xl xn xn xn repeat time last vector network paramet repres use kn kn diagon matric diagon aik diagon ident matrix converg bottom varianc repres use diagon matrix diagon elk nk summat oper propag formul repres kn kn matrix sum mean sent top layer kn kn matrix sum mean sent sensori input matric block block one ident matrix use represent bottom pass given top pass given diag substitut get linear updat diag lg fre figur error log scale versu number iter log scale max vergent network mean initi fix point solut machin round errof caus diverg fix point whose effof shown horizontam line fix point dynam system exist di fix point exist determin express larg brace nonzero found simplifi express determin term determin smaller matric reinterpret dynmic dynam stabil fix point determin gest eigenvalu updat matrix diag modulu largest eigenvalu less fix point stabl sinc system linear stabl fix point exist system global converg point network explor network converg diverg network use iter probabl propag comput steadi state varianc comput modulu largest eigenvalu system comput fix point initi bottom mean fix point valu perform iter see numer error due machin precis would caus diverg fix point fig show error versu number iter logarithm scale network error fix point modulu largest eigenvalu case network diverg fix point reach dynam equilibrium lower averag error fix point onlin factor analysi perform imum likelihood factor analysi onlin fashion paramet modifi slightli increas log probabl current sensori input logp howev sinc factor hidden must probabilist fill use infer increment lean step perform estim mean varianc kth factor turn neal dayan paramet updat follow lv learn rate onlin learn consist perform number iter probabl propag current input iter modifi amet process next input result simul data produc train set case input size rang sensor sensor size factor analyz randomli select set paramet describ gener tr ning set factor analyz size local probabl propag factor analysi figur achiev error number epoch learn use iter versu iter horizont axi give log probabl error log scale learn iter vertic axi give error number epoch learn iter achiev error learn use iter propag versu wake sleep learn use iter factor analyz simul data set estim optim log probabl data use iter em learn size model train set equal size model use gener data avoid issu schedul learn rate search achiev learn curv regardless whether simpl schedul learn rate exist given method randomli initi paramet perform one separ epoch learn use learn rate pick learn rate improv log probabl success learn rate determin compar perform use old learn rate one time smaller mainli interest compar achiev curv differ method differ scale two method train data plot log probabl error optim logprob minu log probabl learn model one method log probabl error method fig show achiev error use iter versu use iter usual use iter produc network lower error learn use iter differ signific network larg sec found converg infer error slower fig show achiev error learn use iter probabl propag versu wake sleep learn use iter gener probabl propag achiev much smaller error wake sleep learn although small wake sleep perform better close optimum log probabl signific differ method occur larg asid local optima probabl propag achiev nearli optim log probabl log probabl wake sleep learn still close valu start learn onlin face recognit fig lb show exampl set greyscal face imag differ peopl contrast data set use test face recognit method face includ wide variat express pose make classif difficult normal imag person pixel frey mean varianc use probabl propag recognit network factor analyz reduc dimension data onlin dimens dimens probabl propag rather arbitrarili chose learn rate wake sleep learn tri learn rate rang multilay perceptron one hidden layer tanh unit one output layer softmax unit simultan train use gradient descent predict face ident mean factor learn rate multilay perceptron set valu use method imag predict made paramet modifi fig show onlin error curv obtain filter loss curv probabl propag gener curv wake sleep learn figur also show error curv two form onlin nearest neighbor recent case use make predict form nearest neighbor perform worst set storag requir factor analysi multilay perceptron method better form nearest neighbor set number comput factor analysi multilay perceptron method number pattern present figur onlin error curv probabl propag solid wake sleep learn dash nearest neighbor dot dash summari guess dot turn iter probabl propag fruit use learn graphic model cycl even model dens connect although interest extend work complex model exact infer take exponenti time studi iter probabl propag factor analyz allow us compar result exact infer allow us deriv fix point algorithm current appli iter propag multipl caus network vision problem 