abstract paper examines role biological constraints human auditory localization process psychophysical neural system modeling approach undertaken performance comparisons competing models human subject explore relevant biologically plausible realism constraints directional acoustical cues upon sound localization based derived human subject head related transfer functions hrtfs sound stimuli generated convolving bandpass noise hrtfs presented subject model input stimuli model processed using auditory image model cochlear processing cochlear data analyzed time delay neural network integrated temporal spectral information determine spatial location sound source combined cochlear model neural network provided system model sound localization process human like localization performance qualitatively achieved broadband bandpass stimuli model architecture incorporated frequency division tonotopicity trained using variable bandwidth center frequency sounds introduction ability accurately estimate location sound source obvious evolutionary advantages terms avoiding predators finding prey indeed humans accurate ability localize broadband sounds considerable amount psychoacoustical research auditory processes involved human sound localization recent review furthermore numerous models human animal sound localization process proposed recent reviews however still remains large gap psychophysical model explanations principal congruence two approaches exists localization performance restricted conditions narrowband sounds spectral integration required restricted regions space unfortunately existing computational model accounts well human sound localization performance wide range sounds varying bandwidth center frequency furthermore biological consmints pertinent sound localization generally explored models include spectral resolution auditory system terms number bandwidth jin carlile frequency channels role tonotopic processing addition performance requirements system substantial involve example accomodation spectrally complex sounds robustness irregularity sound source spectrum channel based structure spatial coding evidenced auditory spatial effects crux matter notion biologically likely realism built model provides better understanding underlying processes work attempts bridge part gap modeling psychophysics describes development use first time authors knowledge timedelay neural network model integrates spectral temporal cues auditory sound localization compares performance model corresponding human psychophysical evidence sound localization sound localization performance normal hearing human subject tested using stimuli consisting three different band passed sounds low passed sound hz high passed sound hz broadband sound hz frequency bands respectively cover conditions either temporal cues spectral cues dominate localization process see subject performed five localization trials sound condition test locations evenly distributed subject head detailed methods used free field sound localization found short summary presented sound localization task human sound localization experiments carried darkened anechoic chamber free field sound stimuli presented loudspeaker carried semicircular robotic arm stimuli consisted fresh white gaussian noise appropriately bandpassed trial robotic ann allowed placement speaker almost location surface imaginary sphere one meter radius centered subject head subject indicated location sound source pointing nose perceived direction sound subject head orientation monitored using electromagnetic sensor system polhemus inc measurement validation outer ear acoustical filtering cues sound localization depend upon spectral temporal properties sound stimulus also acoustical properties individual outer ears generally accepted relevant acoustical cues interaural time difference itd interaural level difference ild spectral cues sound location free field described head related transfer function hrtf typically represented finite length impulse response fir filter sounds filtered hrtf localizable played ear phones bypass acoustical filtering outer ear illusion free field sounds using head phones known virtual auditory space vas thus order incorporate outer ear filtering modelling process measurements subject hrtfs carried anechoic chamber measurements made ears simultaneously using blocked ear technique measurements made locations evenly distributed sphere order establish hrtfs appropriately indicated direction sound source subject repeated localization task stimulus presented vas neural system model human sound localization human sound localization performance sound localization performance human subject three different stimulus conditions broadband high pass low pass examined free field virtual auditory space comparisons two using correlational statistics data shown see across sound conditions demonstrated equivalence thus measured hrtfs highly effective localization data across three sound conditions single trial vas data shown fig la shows subject performed well broadband high pass sound conditions rather poorly low pass condition consistent studies data illustrated using spherical localization plots well demonstrates global distribution localization responses given large qualitative differences data sets presented visual method analysis sufficient evaluating competing models condition target response locations shown left right hemispheres space clear low pass condition subject demonstrated gross mislocalizations responses clustering toward lower frontal hemispheres gross mislocalizations correspond mainly traditional cone confusion errors localization model sound localization model consisted two basic system components modified version physiological auditory image model simulates spectrotemporal characteristics peripheral auditory processing computational architecture time delay neural network sounds presented model filtered using subject hrtfs exactly manner used producing vas therefore modeling results compared human localization performance individual basis modeling process broken four stages first stage sound stimulus generated specific band pass characteristics sound stimulus filtered subject right left ear hrtfs render auditory stimulus originating particular location space auditory stimulus processed auditory image model aim generate neural activity profile simulates output inner hair cells organ corti indicates spiking probability auditory nerve fibers finally fourth last stage time delay neural network tdnn computed spatial direction sound input based distribution neural activity calculated aim detailed presentation modeling process found although brief summary presented distribution cochlear filters across frequency aim chosen minimum center frequency hz maximum center frequency khz filters essentially equally spaced logarithmic scale order fully describe computational layer tdnn four characteristic numbers must specified number neurons kernel length number determines size current layer time window terms number time steps previous layer kernel width number specifies many neurons previous layer actual connections undersampling factor number describing multiplicative factor current layer time step interval increased previous layer using nomenclature architecture different layers one tdnn summarized table smailest time step ms exact connection arrangement network described next section jin carlde layer table architecture tdnn neurons kernel length kernel width undersampling input hidden hidden output spatial location sound source encoded network distributed response peak occurring output neuron representing target location input sound output response would decay away form two dimensional gaussian one moves neurons fiarther away target location derives well established paradigm nervous system uses overlapping receptive fields encode properties physical world networks frequency division tonotopicity major auditory brainstem nuclei demonstrate substantial frequency division within structure tonotopic organization primary auditory nerve fibers innervate cochlea carries forward brainstem auditory nuclei arrangement described tonotopic organization despite fact knowledge previous network model sound localization incorporates frequency division within architecture typically neurons first computational layer fully connected input cochlear frequency channels work different architectures examined varying amounts frequency division imposed upon network structure network architecture described network connections constrained frequency tonotopic like arrangement input cochlear frequency channels ear split ten overlapping groups consisting generally six contiguous frequency channels five neurons first hidden layer group input channels kernel widths neurons set total number frequency channels input layer six contiguous frequency channels defining group information across different groups frequency channels progressively integrated higher layers network network training sounds different center frequency bandwidth used training networks one particular training paradigm center frequency bandwidth noise chosen randomly center frequency chosen using uniform probability distribution logarithmic scale similar physiological distribution output frequency channels aim manner frequency region trained equally based density neurons frequency region training error backpropagation algorithm used summed squared error measure natural feature learning rule given neuron weights updated activity respective cochlear channels example training sound containing low frequencies train high frequency neurons vice versa modeling results correspond single tonotopically organized tdnn trained using random sounds unless explicitly stated otherwise neural system model human sound localization localization performance tonotopic network experimentation different network architectures clearly demonstrated network frequency division vastly improved localization performance tdnns figure case frequency division essential producing reasonable neural system model would localize similarly human subject across different band pass conditions single band pass condition found tdnn require frequency division within architecture produce quality solutions trained band passed sounds mentioned observed tonotopic network one divides input frequency channels different groups progressively interconnects neurons higher layers across frequency robust localization performance across sounds variable center frequency bandwidth simple fully connected network two likely explanations observation one line reasoning argues easier tonotopic network prevent narrow band frequency channels dominating localization computation across entire set sound stimuli expressed slightly differently may easier incorporate relevant information across different frequency channels second line reasoning argues tonotopic network structure along training variable sounds encouraged network develop meaningful connections frequencies subject vas broadband low pass tonotopic network network without frequency division dot response location figure comparison subject vas localization performance model localization performance without frequency division viewpoint outside observer target location shown cross response location shown black dot din carlile matched filtering sound localization number previous sound localization models used relatively straight forward matched filter template matching analysis cases itd spectrum given input sound commonly cross correlated itd spectrum entire database sounds location known location highest correlation chosen optimal source location matched filtering analysis compared localization performance human subject neural system model using bandpass sound restricted highfrequencies figure matched filtering localizes sounds much better subject tdnn model matched filtering model used number cochlear channels tdnns therefore contained inherent spectral resolution spectral resolution cochlear channels certainly less spectral resolution human cochlea shows although sufficient information localize sounds point view matched filtering neither human tdnn demonstrated ability performance order tdnn localize similarly matched filtering model network weights corresponding given location need assume form filter template location training sounds flat spectrum tdnn received ambiguity far source spectrum concerned thus likely difference distribution localization responses figure compared figure encouraged using training sounds random center frequency bandwidth providing partial explanation human localization performance optimal matched filtering standpoint band pass khz subiect matched filter model figure comparison localization performances subject tdnn model matched filtering model details fig varying sound levels ild cue training tdnns performed fashion particular location space sound level db spl vary db spl repeated presentations sound localization performance neural system model examined using broadband sound source across range sound levels varying db spl db spl spherical correlation coefficient target response locations values indicate high correlation remained db spl demonstrating graceful degradation localization performance range sound level db network also tested broadband sounds db louder one ear results tests shown figure clearly illustrate localization responses pulled toward side louder sound magnitude effect certainly human like behaviour suggests interaural level difference neural system model human sound localization cues prominent constant feature data conferred measure robustness sound level variations left ear db level ease right ear db level increase ears db level figure model localization performance db increase sound level monaurally binaurally conclusions neural system model developed physiological constraints imposed upon modeling process tdnn model used incorporate important role spectral temporal processing auditory nervous system tonotopic structure added network training sounds contained randomly varying centerfrequencies bandwidths biologically plausible model provided increased understanding role constraints play determining localization performance acknowledgments authors thank markus schenkel andr van schaik valuable comments research supported nhmrc arc dora lush scholarship cj