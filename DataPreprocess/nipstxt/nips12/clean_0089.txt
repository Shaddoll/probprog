abstract investigate short term dynamics recurrent competition neural activity primary visual cortex terms information processing context orientation selectivity propose stimulus onset strength recurrent excitation decreases due fast synaptic depression consequence network shifts initially highly nonlinear linear operating regime sharp orientation tuning established first highly competitive phase second less competitive phase precise signaling multiple orientations long range modulation intra inter areal connections becomes possible surround effects thus network first extracts salient features stimulus starts process details show signal processing strategy optimal neurons limited bandwidth objective transmit maximum amount information time interval beginning stimulus onset introduction last four decades vivid highly polarized discussion role recurrent competition primary visual cortex see review main question whether recurrent excitation sharpens weakly orientation tuned feedforward input feed forward input already sharply tuned hence massive recurrent circuitry different function strong cortical recurrency implements highly nonlinear mapping feed forward input obtains robust sharply tuned cortical response even weak feed forward orientation bias present however competitive network cases fails process multiple orientations within classical receptive field may signal spurious orientations motivates concept primary visual cortex maps already sharply orientation tuned feed forward input less competitive linear fashion although models orientation selectivity vary wide scale one common feature assumes synaptic strength constant short time scale network operates given phenomenon fast synaptic current address epigenomics gmbh kastanienallee berlin germany adorjtin schwabe piepenbrock oberrnayer dynamics however need case short term synaptic dynamics recurrent excitatory synapses would allow cortical network operate bothcompetitive linear regimes show section dynamic cortical amplifier network establish sharp contrast invariant orientation tuning broadly tuned feed forward input still able respond correctly multiple orientations show section decreasing recurrent competition time naturally follows functional considerations requirement mutual information stimuli representations maximal time interval beginning stimulus onset consider free viewing scenario cortical layer represents series static images flashed onto retina fixation period ms saccades also assume spike count increasing time windows stimulus onset carries information key observations signal noise ratio cortical representation increases time spikes available optimal strength recurrent connections information transfer decreases decreasing output noise consequently model predicts information content per spike snr afixed sliding time window decreases time flashed static stimulus accordance recent experimental studies neural system thus adapts internal changes modifying coding strategy phenomenon one may refer dynamic coding cortical amplifier fast synaptic plasticity investigate first hypothesis set model orientation hypercolumn primary visual cortex similar structure parameters important novel feature model fast synaptic depression present recurrent excitatory connections neurons cortical layer receive orientation tuned feed forward input lgn connected via mexican hat shaped recurrent kernel orientation space addition recurrent feed forward excitatory synapses exhibit fast depression due activity dependent depletion synaptic transmitter compare response cortical amplifier models without fast synaptic plasticity recurrent excitatory connections single multiple bars within classical receptive field membrane potential cortical cell tuned orientation decreases due leakage recurrent inhibition increases due recurrent excitation tv ilgn iexc iinh ms membrane time constant ii input received lgn recurrent excitatory inhibitory cortical inputs given exp arr periodic circular difference preferred orientations excitatory inhibitory connection strengths exc inh dr mv hz mv hz presynaptic firing rate excitatory synaptic efficacy jexc time dependent due fast synaptic depression efficacy inhibitory synapses jinh assumed constant recurrent excitation sharply tuned exc inhibition broad tuning mapping membrane potential firing rate approximated linear function threshold max hz mv gaussian noise variances recurrent cortical competition strengthen weaken feedforward input orientation deg static orientation deg depressing orientation deg figure feed forward input response cortical amplifier model static recurrent synaptic strength network fast synaptic depression stimulus single bar different stimulus contrasts dotted dashed solid line cortical response averaged first ms stimulus onset hz hz added input intensities output cortical neurons orientation tuning curves feed forward input lan gaussians rrlan resting strong additive orientation independent component would correspond geniculo cortical connectivity pattern approximate aspect ratio orientation dependent independent components increase contrast considering free viewing scenario environment scanned saccading around fixating short periods ms model stationary stimuli present ms stimuli one bars different orientations feed forward recurrent excitatory synapses exhibit fast depression fast synaptic dep ression modeled dynamics expected synaptic transmitter resource synapse amount available transmitter decreases proportionally release probability presynaptic firing rate recovers exponentially lgn ctx plgn pctx rec ms rrec ms fr trec change membrane potential postsynaptic cell time proportional released transmitter pr excitatory connectivity strength neurons tuned orientations expressed xc xproo similarly applies feed forward synapses fast synaptic plasticity feed forward synapses investigated detail previous studies following compare predictions cortical amplifier model without fast synaptic depression recurrent excitatory connections cases fast synaptic depression present feed forward connections limiting duration effective feed forward input ms figure shows orientation tuning curves different stimulus contrasts feed forward input noisy broadly tuned fig la models exhibit contrast invariant tuning fig lb fast synaptic depression present recurrent excitation cortical network sharpens broadly tuned feedforward input initial response phase sharply tuned input established tuning width change response amplitude decreases time predictions two models differ substantially multiple orientations present fig first test cortical response two bars separated different intensities figs recurrent synaptic weights static strong enough fig one orientation signaled cortical network selects orientation adorjdn schwabe piepenbrock obermayer feedforward input orientation deg wlo zo orientation deg average cortical response orientation deg io activity profile time ms figure response cortical amplifier model static fast depressing recurrent synapses models feed forward synapses fast depressing left column feed forward input shown models two types stimuli applied first stimulus consists stronger weaker bar second stimulus consists three equal intensity bars orientations separated middle column cortical response shown averaged different time windows dotted dashed solid line right column cortical activity profile plotted function time gray values indicate activity bright denoting high activities highest amplitude winner take fashion contrast synaptic depression present recurrent excitatory synapses bars signaled parallel low release probability fig high release probability data shown first cells fire tuned orientation bar stronger intensity sharply tuned response emerges single orientation network operates winner take regime synapses highly active cells become strongly depressed cortical competition decreases network shifted linear operation regime second orientation signaled note phenomenontogether observed contrast invariant tuning cannot reproduced simply decreasing static synaptic weights cortical amplifier model recurrent synaptic efficacy changes inhomogeneously network depending activity synapses highly active cells depress strongly therefore sharply tuned response evoked bar weak intensity fast synaptic depression thus behaves local self regulation modulates competition certain delay delay therefore delay rise response second bar depends eff tive time constant free pf rrec synaptic depression recurrent connections depression becomes faster due increase release probability delay decreases delay also scales difference bar intensities closer shorter delay figs cortical response three bars equal intensities presented cells tuned presented three orientations respond parallel fast synaptic depression recurrent excitation present figs cortical network strong static recurrent synapses fails signal faithfully feed forward input additive noise recurrent cortical competition strengthen weaken feed forward input introduces slight symmetry breaking network static recurrent weights responds strongly orientation one presented bars fig summary simulations revealed recurrent network fast synaptic depression capable obtaining robust sharpening feed forward input also responds correctly multiple orientations note local activity dependent adaptation mechanisms slow potassium current would similar effects synaptic depression highly orientation specific excitatory connections experimentally testable prediction model response flashed bar lower contrast delayed masking second bar higher contrast fig right also suggest long range integration outside classical receptive field could emerge similar delay initial phase cortical response strong local features amplified longer second phase recurrent competition decreases weak modulatory recurrent feed forward input stronger relative effect following investigate whether strategy favorable point view cortical encoding dynamic coding previous section proposed cortical processing highly nonlinear phase followed linear mode consider short stimulus presentation fixation period simulations demonstrated unless recurrent competition modulated time network fails account one feature input strictly functional point view question arises use weak recurrent competition whole processing period investigate problem abstract signal encoder framework input cortical network nonlinear mapping sake simplicity additive gaussian noise naturally real recurrent network output noise becomes input noise feedback use simplifying assumption output noise present transformed input signal input noise would lead different predictions investigated output noise interpreted noisy channel projects primary visual cortex nonlinear transformation considered functional description cortical amplifier network without analyzing actually implemented considering orientation selectivity signal interpreted vector intensities contrasts edges different orientations edges present zero intensity coding capacity realistic neural network limited among several noise sources limitation could arise imprecision spike timing constraint maximal average firing rate input output mapping cortical amplifier network approximated soft max function exp flxi gi exp flxi fi parameter interpreted level recurrent competition fi network operates linear mode oo puts highly nonlinear winner take mode cases average activity network constrained suggested minimize metabolic costs let us consider factorizing input distribution ii exp forx adorjdn schwabe piepenbrock obermayer noise stdev figure optimal competition parameter function standard deviation gaussian output noise optimal calculated highly super gaussian gaussian sub gaussian stimulus densities sparsity parameter indicated legend exponent determines sparsity probability density function normalizing constant determines variance input density positive half multivariate gaussian distribution signal distribution becomes sub gaussian becomes super gaussian optimal processing time one needs gain maximal information signal increasing time window let us assume stimulus static presented limited time time goes ahead stimulus onset time window encoding read mechanism increases longer period samples noisy network output available thus output noise level decreases time suggest optimal competition parameter pt mutual information input output ff eq maximized depends noise level noise decreases time recurrent cortical competition also change cortical processing demonstrate idea mutual information calculated numerically three dimensional state space one might expect higher noise levels highest information transfer obtained typical salient features strongly amplified note true standard deviation noise scales sub linearly activity true additive noise process well poisson firing noise decreases increasing time window estimation level competition decrease distributing available resources spikes among units letting network respond finer details input investigating level optimal competition function standard deviation output noise fig intuition indeed justified optimal scales standard deviation additive noise process comparing signal distributions variance different sparsity exponents find sparser signal distribution higher optimal competition becomes multiple features unlikely present time input distribution sparse enforcing competition optimal encoding strategy also generates activity distribution units fire presented stimulus since edges different orientations form sparse distributed representation natural scenes work suggests strongly competitive visual cortical network could achieve better performance visual environment simple linear network would interpret simulation results presented section functional point view give prediction dynamics recurrent cortical competition noting output noise decreasing increasing time window encoding cortical competition also decrease following similar trajectory presented fig competition low static cumulative mutual information input output would converge slowly towards overall information available stimulus competition high whole observation period fast rise cumulative mutual information would saturate well possible recurrent cortical competition strengthen weaken maximum level competition dynamic decreases initially highly competitive state network obtains maximal information transfer time one may argue valuable information signals mainly depends interest observer considering encoding system one variable suggested highly attentive state recurrent competition increases view results would refine statement suggesting competition increases decreases depending level visual detail observer pays attention whenever representation small details also required reducing competition optimal strategy given enough bandwidth summary using detailed model orientation hypercolumn demonstrated sharp contrast invariant tuning faithful representation multiple features achieved recurrent network recurrent competition decreases time stimulus onset model predicts cortical response weak details stimulus emerges delay second stronger feature also present modulation outside classical receptive field also delayed effect cortical activity study within abstract framework revealed weakening recurrent cortical competition fast time scale functionally advantageous maximal amount information transmitted time window stimulus onset acknowledgments supported boehringer ingelheim fonds german science foundation dfg grant gk wellcome trust